# Lab 8 - proxy part II

TODO [Lab 8 Assignment page on Canvas](https://canvas.uw.edu/courses/1373089/assignments/5369625)

## Python concepts

* Slicing lists / strings
* Converting strings to/from numbers
* Creating and using enumerations
* Format strings, e.g., `"{}: {}\r\n".format(header_name, header_value)`

## Instructions

### Getting Started 

As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in `http-proxy.py`.

In the previous lab, we started to build the server component of your proxy. This component is designed to receive incoming requests from web clients and then eventually forward responses that were received from an upstream web server. The core of the server is established on a request parser, which we also started to develop in the last assignment.

In this lab, we'll extend our proxy to recognize more complex HTTP requests and build the logic to forward these requests to the intended target. This will require us to: a) create a new function that can rebuild an HTTP request in byte form based on the dictionary representation generated by your parsing code and b) open a new client socket to a dynamic location each time we receive a request.

### Parsing Requests (cont.)

Extend your parsing function built in the previous lab to handle more complex HTTP requests, such as the POST or PUT type. You'll recall that the GET request structure allows a variable number of CRLF terminated header lines followed by an empty CRLF line. The full HTTP specification allows for an additional message body following the HTTP headers, however there are some important points you need to observe as you handle this part of the HTTP request:

1. While the header portion of the message is ISO-8859-1 encoded per specification, the body/payload should be treated as raw, binary data (even when it looks like standard text-based HTML). Always handle this portion of the request in Python byte form. DO NOT DECODE THE PAYLOAD TO STRING. This will have side effects that can make it impossible to recognize the end of the message.

2. Unlike the header portion of the message, line-endings occuring in the data/payload portion of the HTTP request are coincidental. They do not imply anything about the structure of the message from an HTTP point-of-view. DO NOT SPLIT/STRIP NEWLINES IN THE PAYLOAD. As before, any changes you make to this portion of the message will impact your ability to recognize the message boundary.

The structure of a POST, PUT, and other HTTP requests expands on the GET request, allowing a chunk of raw data to be appended after the CRLF that signals the end of the HTTP headers. Unlike the lines that came before, this data is raw, i.e., unstructured, and it will require a different approach based on the expected length of the data. As such, we need to find out the length of the body component before we can determine whether it's been received completely.

In HTTP 1.0, the body length is defined by an HTTP header called `Content-Length`.[^oversimplification] The value of `Content-Length` will be a numeric string that defines the length of the body payload. If you see this field while you are parsing your headers, you should record it's value within a variable and add it to your message dictionary, e.g.,

```python
if header['name'] == 'Content-Length':
    message['Content-Length'] = int(header['value'])
```

Taking into account that a message may contain a payload, we need to make sure that `parse_message` waits for the complete payload before returning a valid message back to the main recv() loop. You will need to check for several possible edge cases in order to handle this correctly.

1. If content-length is defined and greater than zero, you need to look at the unparsed portion of the buffer for the message body.
2. If the unparsed portion of the buffer is shorter (see `len()`) than content-length, you should return to the recv() loop and wait for the remaining data.
3. If the unparsed portion of the buffer is longer than content-length, the extra bytes should remain in the buffer. 

If you succeed in parsing a complete message, save the bytes into the message dictionary that contains the other fields you've parsed. Remove all of the correctly parsed bytes from the buffer and return to your main function. As in the previous lab, you should leave the buffer untouched if parsing fails. Return control to your connection handling loop in main and continue to wait for the rest of the message.

[^oversimplification]: This is an oversimplification of the RFC for HTTP/1.0, but it will be sufficient for our purposes.

<!-- ### Parsing Responses
Structurally, there is almost no difference between an HTTP request with a message body and an HTTP response. In fact, the only difference from your parser's perspective is the order of fields in the first line of the message.[^http-syntax]

Extend your parser to handle both types of messages based on an additional `message_type` argument to your parser function. Modify the behavior of the function to parse the first line properly based on this argument, include the `message_type` in the parsed message.

A standard way to represent a value representing a message type is using an enumeration, e.g.:

```python
# Required imports
from enum import Enum, auto

# Enumeration to represent message types 
class MessageType(Enum):
    REQUEST = auto()
    RESPONSE = auto()

# Use the is operator rather than == to test an enumeration …
# if message[‘type’] is MessageType.REQUEST:
```

[^http-syntax]: More information available at [HTTP syntax overview](/assignments/proxy-labs)  -->

### Get Destination URL

Our HTTP/1.0 proxy will expect exactly one HTTP request to be delivered per connection. After our parsing logic determines that we have received a complete/valid message, we can break out of our receiving loop and continue processing the request. Our next step in processing a request is to determine where the browser intended to send the message. We'll use this information in order to open a client socket to the destination server.

The information we need to locate the destination is contained in the URI of the request. If you followed the sample code from the previous lab, this value should have been saved as the `'uri'` element of the message dictionary. Parsing this field with the Python `urllib` library will provide us with a host name/address and port that you can use to establish a client socket with the target (see echo-client.py for syntax to open a client socket).

Since Python provides a URL parsing module, this is theoretically an easy task. However, it turns out that real browsers produce a variety of edge cases that will cause `urllib` to choke. In order to constrain the difficulty of this lab, we are providing you with the following function to complete this section.

```python
# Be sure to add the import to the top of your code
from urllib.parse import urlparse

# returns the host and port
# run by doing:  h, p = parse_uri(dest)
def parse_uri(uri):
    uri_parts = urlparse(uri)
    scheme = uri_parts.scheme
    host = uri_parts.hostname
    # urlparse can't deal with partial URI's that don't include the 
    # protocol, e.g., push.services.mozilla.com:443
    if host: # correctly parsed
        if uri_parts.port:
            port = uri_parts.port
        else:
            port = socket.getservbyname(scheme)
    else: # incorrectly parsed
        uri_parts = uri.split(':')
        host = uri_parts[0]
        if len(uri) > 1:
            port = int(uri_parts[1])
        else:
            port = 80
    return host, port
```

### Build Message

At this point, we have a request, and we know it's destination. The last objective for this week is to create a new function that takes a decomposed message (the dictionary returned from your parser) and generates a new message in byte form. This function is the inverse of the parsing logic you wrote in the last two labs (with one modification for now).[^really?] 

The easiest way to rebuild a message from it's parts is to use Python3 format strings, as shown in the example below. At this point, we would like you to make one change to the original request. Regardless of which HTTP version is defined, rebuild the message as an HTTP/1.0 request.

```python
def build_message(message):
    # Please note that we are replacing the original version (this is intentional)
    message_header = '{} {} {}\r\n'.format(message['method'], message['uri'], 'HTTP/1.0')
    for header in message['headers']:
        data = data + '{}\r\n'.format('TODO') # Format each header properly

    # Don't forget to add a terminating CRLF
    # Encode the header portion of the message as bytes
    # Do you have a message body? Add it back now

```

<!-- Replace the HTTP version you received with `HTTP/1.0`
-   Add or update a `Via` header (per RFC 7230) for the proxied connection, e.g.,
    -   `Via: 1.0 127.0.0.1:9999`
    -   If a `Via` already exists, append your entry as a comma separated value to the end of the existing header -->

[^really?]: I realize it seems strange to rebuild the message you just spent time tearing apart, but this approach gives you more leverage in terms of what functions your proxy can provide. For example, notice how easily we can modify the HTTP version and add new headers.

### Client Socket

We'll conclude this sequence of tasks by establishing our outbound client socket and sending the request to it's destination. The most important point to remember at this point is how the end-to-end connection flow works. Your main code block should contain a loop to accept connections from browsers. 

Each connection that you accept will be used to service one outbound request and a corresponding inbound response. The request is received over the server socket you've already established. You used a second loop to call Socket.recv() until you could parse a valid request. 

Using the `parse_uri(request['uri'])` function from above, determine the host and port for the outbound client socket. Follow the pattern established in the echo_client to open the connection to this destination. 

Use `build_message(request)` to convert the parsed request back into byte form and send it with the `Socket.sendall(data)` function demonstrated in the echo_client and RealPython guides. Finally, attempt one call to `Socket.recv()` to try and receive the first part of the response.

If you have been successful in receiving and rebuilding the request, you should receive a response immediately from the server. Errors in the preceeding step may result in your proxy hanging (while waiting for a response) or the server resetting the connection due to bad data.

We have two more weeks to debug your code. If it breaks here, comment out the final recv() and print a summary of the request you've received as shown below.

### Output

Once all parts of your code are working, print the following summary (replace the output from the previous lab) and close the connection. This will return to the start of your loop to listen for new connections.

**Request summary**  

* Connection Source: < IP address returned from the call to Socket.accept() >  
* HTTP Method: < Name of method, e.g., GET, OPTION, or POST  >  
* Destination: < URI extracted from the request >  
* Headers: < Comma delimited list of header names >
* Target: < Hostname of server obtained from request >
* Message: < Raw bytes of the rebuilt request >
* Reponse: < First 50 bytes of the response (if working) >

??? note " What are these diamonds "<   >" ?"
    These are placeholders. When you see these it means you should fill in information that is between them and then delete the symbols. It's a quick way of saying "hey something needs to be filled in" for the developer world.

### Testing your code with test.py

The resources directory of the project repository contains a simple
python script called test.py that you can use to send HTTP requests from
a file into your proxy code.

```
# Send the request from sample-request.txt on port 9999 250 bytes at a time with a short delay between

python3 test.py 9999 get_request.http 250
```

Note: Testing at this stage can be more challenging. Please ask for help via the course Slack if you need it.

### Capturing proxied requests for testing

Use the following method to capture valid requests that you can use for
testing:

-   Open ncat to listen for incoming connections, e.g., `ncat -o <FILENAME> -l <PORT>`
-   Configure Firefox with an HTTP proxy on `127.0.0.1 <PORT>`
-   Enter the URL of an HTTP-only site into the FF address bar (the request will hang)
-   Manually stop the request from the browser
-   Verify that the request was captured in ncat (ncat will close automatically)
