{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Computer Networks And Distributed Applications \u00b6 This site provides documentation and resources for students participating in INFO 314 : \"Computer Networks And Distributed Applications\" . 1 If you notice a problem with the content presented here, please file an issue on the GitHub project repository . Course Site vs. Canvas \u00b6 Class documentation and troubleshooting will be slowly added to this course website in order to better support students with their assignments. If you are looking for the class schedule, information on what to read for the next class, and information on assignments, their due dates \ud83d\udcc6, and their deliverables, please visit the course Canvas page @ INFO 314 Canvas Homepage Asking for Help \u00b6 If you ever need help with an assignment, please refer to this page to know where to ask: Contact Us Curious on how to develop something similar to this? Follow instructions on how to setup your own MkDocs here . \u21a9","title":"Home"},{"location":"#computer-networks-and-distributed-applications","text":"This site provides documentation and resources for students participating in INFO 314 : \"Computer Networks And Distributed Applications\" . 1 If you notice a problem with the content presented here, please file an issue on the GitHub project repository .","title":"Computer Networks And Distributed Applications"},{"location":"#course-site-vs-canvas","text":"Class documentation and troubleshooting will be slowly added to this course website in order to better support students with their assignments. If you are looking for the class schedule, information on what to read for the next class, and information on assignments, their due dates \ud83d\udcc6, and their deliverables, please visit the course Canvas page @ INFO 314 Canvas Homepage","title":"Course Site vs. Canvas"},{"location":"#asking-for-help","text":"If you ever need help with an assignment, please refer to this page to know where to ask: Contact Us Curious on how to develop something similar to this? Follow instructions on how to setup your own MkDocs here . \u21a9","title":"Asking for Help"},{"location":"contact/","text":"Asking teaching staff for help As teaching staff, both the instructor and the teaching assistant are here to help you as much as possible. We will both be available on Slack for questions. Nevertheless it is expected that you will have attempted to solve the issue as much as possible before reaching out for help. Below are some guidelines: When should I reach out? You should reach out for help if you have: Written down what your problem is Written down why you think you are seeing this behavior Completed your own debugging Completed your own research How should I ask? It is highly encourages that you ask your questions in a Slack Channel. You will get a response back much more quickly either from a student are teaching staff this way. In your message explain the problem and what you have tried so far. If the question pertains grading or other private information, please use Canvas messaging or email one off the staff members. Our emails are listed on the Canvas page.","title":"Contact"},{"location":"assignments/analysis-report/","text":"Report 2 - NAT and DNS analysis \u00b6 The objective of this task is to analyze the mechanics of NAT and DNS using a variety of network utilities and to use your findings to help you answer the questions defined below. Part I: NAT Analysis \u00b6 In this section, you will use netstat and netstat-nat to analyze the state of network connections from several different perspectives on your LAN. Installation \u00b6 netstat is a powerful tool for viewing information about sockets and connections on Windows, Linux, and macOS devices. The tool is installed by default by all major desktop OS vendors, though you'll find that the command line options vary slightly between implementation. netstat-nat provides a similar interface to netstat with the purpose of diving more deeply into the behavior of routed network connections and NAT. Use apt to install netstat-nat on your Pi. Root Permissions netstat-nat requires root permissions in order to run properly on your Pi, while netstat can be run without having to invoke sudo (but may provide more detailed information when used in that way). Usage Tips \u00b6 The most common options for netstat across all three operating systems are -an . The -a option instructs netstat to display server as well as client sockets, while n disables reverse DNS resolution and keeps the output easier to interpret. Tip: Reducing netstat output netstat can produce an overwhelming amount of information. To focus your attention, you can limit the output to a single protocol, e.g., tcp or udp. The syntax for this option on Windows and macOS is -p <PROTO> , e.g., netstat -anp tcp . For Linux, use -t to select only TCP sockets and -u to select only UDP packets. When running netstat-nat , the most useful view for this combination of options will be -SNn . This will show you source and destination IP addresses as well as the entries in your Pi's NAT table associated with each connection. Analysis instructions \u00b6 Setup your computer to use the Pi as a router (wifi disabled) so that you can use netstat and netstat-nat to examine open Internet connections from multiple perspectives. You will obtain the most information by running netstat on your own computer back-to-back with netstat-nat on your Pi. You should also experiment with netstat on your Pi, though you'll find it does not show you any data about routed connections. Take some time to understand what these perspectives are showing you (it may be helpful to run netstat without -n temporarily to obtain more information about the protocols and destination hosts). Try to correlate connections shown in netstat on your computer with the connections appearing in your NAT tables. Part II: DNS Analysis \u00b6 In this section, you will use the tshark utility (a commandline version of Wireshark) in order to analyze DNS requests from the perspective of your Pi's external network interface. Install and configure tshark on your Pi and perform the two following captures of DNS as described below. Capture #1 - Perform a capture of DNS queries being routed through the Pi \u00b6 Setup your computer to use the Pi as a router (wifi disabled) and launch a tshark capture on the wlan0 port of your Pi. With tshark running, perform a manual DNS query from your computer to a public DNS resolver such as 1.1.1.1. Since your computer is now using your Pi as its default DNS resolver (based on the configuration performed by DHCP), you will need to manually override the DNS settings for your query. Info Both dig and Powershell's Resolve-DNSName command provide the functionality to override the system's default resolver. Use man or other resources to find the correct syntax for your system. Important Save a copy of your capture and make note of the domain queried. Capture #2 - Perform a capture of DNS queries being resolved by your Pi : \u00b6 Setup your computer to use the Pi as a router (wifi disabled) and launch a tshark capture on the wlan0 port of your Pi. With tshark running on your Pi , clear BIND's resolver cache on your Pi (run sudo rndc reload on the Pi) and perform a manual DNS query from your computer to the Raspberry Pi based recursive resolver. Important Save a copy of your capture and make note of the domain queried. Tips \u00b6 Use Wireshark's search capabilities to look for the string in the packet details of the capture. Use capture filters to limit the capture to port 53 and display filters to further cut down on the noise of the capture (see below). In addition to your DNS queries, you may see a lot of additional DNS traffic being generated by your computer and the Pi. The following display filter will eliminate DNSSEC related queries and queries generated by network time protocol : dns && !(dns.qry.type in {43 48} || dns.qry.name contains \"ntp.org\") . Questions \u00b6 Part I \u00b6 Briefly describe NAT in your own words along with an explanation of what information it collects in order to track and masquerade connections on your behalf. Use screenshots and illustrations from the sockets you observed. Note For research purposes, you may also want to search Port Address Translation (PAT). This is the tehcnical term for the variant of NAT that we are utilizing. Part II \u00b6 For each capture, summarize the message(s) that were involved in resolving your DNS queries . * Packet # from the wireshark capture * Source and Destination IP address * Tranport layer protocol and port * Message type, e.g., query/response * Record types included in the response, e.g., NS, A, or AAAA Looking at each pair of messages above, identify what type of DNS server provided back the corresponding response (Resolver, Root Name Server, TLD Name Server, or Authoritative Name Server). Using the data you've captured for illustration (along with other resources), compare and contrast the two sets of queries (Capture #1 and Capture #2) from the perspective of your Pi. What was the role of the Pi in each of these captures? What work did it have to do in order for you to receive a response to your question? Additional Resources \u00b6 WCT01-S11: Understand Proxy/Firewall/NAT/PAT Traffic Flows [WCT01: Network Analysis Overview Course]","title":"Instructions"},{"location":"assignments/analysis-report/#report-2-nat-and-dns-analysis","text":"The objective of this task is to analyze the mechanics of NAT and DNS using a variety of network utilities and to use your findings to help you answer the questions defined below.","title":"Report 2 - NAT and DNS analysis"},{"location":"assignments/analysis-report/#part-i-nat-analysis","text":"In this section, you will use netstat and netstat-nat to analyze the state of network connections from several different perspectives on your LAN.","title":"Part I: NAT Analysis"},{"location":"assignments/analysis-report/#installation","text":"netstat is a powerful tool for viewing information about sockets and connections on Windows, Linux, and macOS devices. The tool is installed by default by all major desktop OS vendors, though you'll find that the command line options vary slightly between implementation. netstat-nat provides a similar interface to netstat with the purpose of diving more deeply into the behavior of routed network connections and NAT. Use apt to install netstat-nat on your Pi. Root Permissions netstat-nat requires root permissions in order to run properly on your Pi, while netstat can be run without having to invoke sudo (but may provide more detailed information when used in that way).","title":"Installation"},{"location":"assignments/analysis-report/#usage-tips","text":"The most common options for netstat across all three operating systems are -an . The -a option instructs netstat to display server as well as client sockets, while n disables reverse DNS resolution and keeps the output easier to interpret. Tip: Reducing netstat output netstat can produce an overwhelming amount of information. To focus your attention, you can limit the output to a single protocol, e.g., tcp or udp. The syntax for this option on Windows and macOS is -p <PROTO> , e.g., netstat -anp tcp . For Linux, use -t to select only TCP sockets and -u to select only UDP packets. When running netstat-nat , the most useful view for this combination of options will be -SNn . This will show you source and destination IP addresses as well as the entries in your Pi's NAT table associated with each connection.","title":"Usage Tips"},{"location":"assignments/analysis-report/#analysis-instructions","text":"Setup your computer to use the Pi as a router (wifi disabled) so that you can use netstat and netstat-nat to examine open Internet connections from multiple perspectives. You will obtain the most information by running netstat on your own computer back-to-back with netstat-nat on your Pi. You should also experiment with netstat on your Pi, though you'll find it does not show you any data about routed connections. Take some time to understand what these perspectives are showing you (it may be helpful to run netstat without -n temporarily to obtain more information about the protocols and destination hosts). Try to correlate connections shown in netstat on your computer with the connections appearing in your NAT tables.","title":"Analysis instructions"},{"location":"assignments/analysis-report/#part-ii-dns-analysis","text":"In this section, you will use the tshark utility (a commandline version of Wireshark) in order to analyze DNS requests from the perspective of your Pi's external network interface. Install and configure tshark on your Pi and perform the two following captures of DNS as described below.","title":"Part II: DNS Analysis"},{"location":"assignments/analysis-report/#capture-1-perform-a-capture-of-dns-queries-being-routed-through-the-pi","text":"Setup your computer to use the Pi as a router (wifi disabled) and launch a tshark capture on the wlan0 port of your Pi. With tshark running, perform a manual DNS query from your computer to a public DNS resolver such as 1.1.1.1. Since your computer is now using your Pi as its default DNS resolver (based on the configuration performed by DHCP), you will need to manually override the DNS settings for your query. Info Both dig and Powershell's Resolve-DNSName command provide the functionality to override the system's default resolver. Use man or other resources to find the correct syntax for your system. Important Save a copy of your capture and make note of the domain queried.","title":"Capture &num;1 - Perform a capture of DNS queries being routed through the Pi"},{"location":"assignments/analysis-report/#capture-2-perform-a-capture-of-dns-queries-being-resolved-by-your-pi","text":"Setup your computer to use the Pi as a router (wifi disabled) and launch a tshark capture on the wlan0 port of your Pi. With tshark running on your Pi , clear BIND's resolver cache on your Pi (run sudo rndc reload on the Pi) and perform a manual DNS query from your computer to the Raspberry Pi based recursive resolver. Important Save a copy of your capture and make note of the domain queried.","title":"Capture &num;2 - Perform a capture of DNS queries being resolved by your Pi:"},{"location":"assignments/analysis-report/#tips","text":"Use Wireshark's search capabilities to look for the string in the packet details of the capture. Use capture filters to limit the capture to port 53 and display filters to further cut down on the noise of the capture (see below). In addition to your DNS queries, you may see a lot of additional DNS traffic being generated by your computer and the Pi. The following display filter will eliminate DNSSEC related queries and queries generated by network time protocol : dns && !(dns.qry.type in {43 48} || dns.qry.name contains \"ntp.org\") .","title":"Tips"},{"location":"assignments/analysis-report/#questions","text":"","title":"Questions"},{"location":"assignments/analysis-report/#part-i","text":"Briefly describe NAT in your own words along with an explanation of what information it collects in order to track and masquerade connections on your behalf. Use screenshots and illustrations from the sockets you observed. Note For research purposes, you may also want to search Port Address Translation (PAT). This is the tehcnical term for the variant of NAT that we are utilizing.","title":"Part I"},{"location":"assignments/analysis-report/#part-ii","text":"For each capture, summarize the message(s) that were involved in resolving your DNS queries . * Packet # from the wireshark capture * Source and Destination IP address * Tranport layer protocol and port * Message type, e.g., query/response * Record types included in the response, e.g., NS, A, or AAAA Looking at each pair of messages above, identify what type of DNS server provided back the corresponding response (Resolver, Root Name Server, TLD Name Server, or Authoritative Name Server). Using the data you've captured for illustration (along with other resources), compare and contrast the two sets of queries (Capture #1 and Capture #2) from the perspective of your Pi. What was the role of the Pi in each of these captures? What work did it have to do in order for you to receive a response to your question?","title":"Part II"},{"location":"assignments/analysis-report/#additional-resources","text":"WCT01-S11: Understand Proxy/Firewall/NAT/PAT Traffic Flows [WCT01: Network Analysis Overview Course]","title":"Additional Resources"},{"location":"assignments/daemons/","text":"Controlling and Monitoring Daemons in systemd Linux \u00b6 A Word About Daemons \u00b6 The word daemon refers to a type of software run in the background on Linux and other Unix systems. Unlike other applications that computing users interact with throughout the day, daemons are characterized by their user independence. Ordinary users may be aware of the services that daemons frequently provide, but they're not involved in the daily management of these programs. It's perfectly normal for a daemon to start up with the computer and keep running until shutdown (whether or not a user logs in or interacts with the computer). As background processes, daemons provide many valuable services -- everything from managing a system's clock to slinging packets through the TCP/IP stack. In fact, the term service is closely related, if not synonomous with daemon (at least in some contexts). In the Windows OS, for example, services are employed to fill the same role. The role of systemd \u00b6 In recent years, the major Linux distributions retooled core system and service management responsibilities around the systemd ecosystem. As such, we rely heavily on the ecosystem and its toolset for most aspects of daemon management. Service Units \u00b6 Resources that can be managed by systemd are known as units . In particular, software that will be run in the background on systemd Linux is encapsulated as a service unit . systemctl is the Answer \u00b6","title":"Controlling and Monitoring Daemons in systemd Linux"},{"location":"assignments/daemons/#controlling-and-monitoring-daemons-in-systemd-linux","text":"","title":"Controlling and Monitoring Daemons in systemd Linux"},{"location":"assignments/daemons/#a-word-about-daemons","text":"The word daemon refers to a type of software run in the background on Linux and other Unix systems. Unlike other applications that computing users interact with throughout the day, daemons are characterized by their user independence. Ordinary users may be aware of the services that daemons frequently provide, but they're not involved in the daily management of these programs. It's perfectly normal for a daemon to start up with the computer and keep running until shutdown (whether or not a user logs in or interacts with the computer). As background processes, daemons provide many valuable services -- everything from managing a system's clock to slinging packets through the TCP/IP stack. In fact, the term service is closely related, if not synonomous with daemon (at least in some contexts). In the Windows OS, for example, services are employed to fill the same role.","title":"A Word About Daemons"},{"location":"assignments/daemons/#the-role-of-systemd","text":"In recent years, the major Linux distributions retooled core system and service management responsibilities around the systemd ecosystem. As such, we rely heavily on the ecosystem and its toolset for most aspects of daemon management.","title":"The role of systemd"},{"location":"assignments/daemons/#service-units","text":"Resources that can be managed by systemd are known as units . In particular, software that will be run in the background on systemd Linux is encapsulated as a service unit .","title":"Service Units"},{"location":"assignments/daemons/#systemctl-is-the-answer","text":"","title":"systemctl is the Answer"},{"location":"assignments/dhcp-setup/","text":"Set up a DHCP Server for your LAN (2022-04-11) \u00b6 Overview \u00b6 In this assignment, we'll be standing up a DHCP service on the Raspberry Pi. As we've discussed in class, DHCP is a function that is sometimes performed by routers and is a necessary service whenever we are creating a new network (of almost any type). Before you Start \u00b6 Before starting any of the work within this checkpoint, make sure that you have completed all steps from checkpoint one, including the networkd setup. You must also have completed the Address Planning Exercise correctly. You will use the parameters you selected in that exercise to configure the IP address for the Pi as well as the configuration for isc-dhcp-server . Configure Static Addresses for your Raspberry Pi \u00b6 In this step, you will add a new configuration file to networkd in order to set up static addresses on eth0 . The addresses you use here will be the one you defined for your DHCP Server and Default Gateway in the LAN Planning Exercise . Please do not try to follow other tutorials for setting up addresses Every quarter, we have students who choose to follow online tutorials instead of the instructions we've provided. Please be aware that we are not using the default Raspberry Pi networking. These tutorials will often instruct you to configure static addresses in the /etc/dhcpcd.conf file or /etc/network/interfaces . Both of these methods were disabled when we set up networkd . Create a file named 20-eth0.network in /etc/systemd/network/ (you'll need to use sudo ) and define a static configuration that includes your chosen IP address and CIDR range. This path should already contain a default configuration for ethernet interfaces, e.g., 99-eth.network . We are overriding this configuration for eth0 by naming the file in such a way that networkd will load it first and by ensuring that the configuration will match eth0 exactly. Your file should look something like: /etc/systemd/network/20-eth0.network [Match] # We only want to match the eth0 interface Name = eth0 # Provide full address config in abbreviated notation [Network] # Default Gateway / DHCP Server Address = 192.168.0.1/24 # Enable link local addresses for IPv6 (FE80::) LinkLocalAddressing = ipv6 Warning Some online references will have you add a gateway and DNS settings for your new interface. You don't need to (and definitely shouldn't) add either to this interface. This interface does not provide a path for Internet traffic, but your Pi will try to use it that way if it believes it can be used for a default route. Likewise, we don't need to give the Pi DNS settings on Ethernet. The Pi will get it\u2019s DNS from the wireless interface, which received it\u2019s DNS settings from DHCP. In order to test these new settings: Call sudo systemctl restart systemd-networkd.service or reboot your Pi. Once you log back in, verify that networkd is running by calling systemctl status systemd-networkd and use the ip addr command to check that eth0 is online with the new address. Attention Make note that the Pi is now assigned to our new subnet, but our computer will still be using it's autoconfigured IPv4 address in the 169.254/16 range. In an IPv4 only world, this would prevent us from talking to the Pi. To fix the problem, we'd have to manually configure a static IP on our laptop in the same range as the Pi's network ID. Fortunately, both devices have autoconfigured IPv6 addresses that will be discovered through mDNS. By default, this is the address that SSH will use. Install and Configure DHCP \u00b6 For this part of the exercise, we'll use the ISC DHCP Server. The ISC server is available in apt repositories, so it can be installed using: sudo apt update sudo apt install isc-dhcp-server Warning Right after installation, isc-dhcp-server will report that it failed to run, and spit out lots of nasty-looking errors. This is normal, as the DHCP server has not yet been configured. Edit /etc/default/isc-dhcp-server to specify the interfaces ( eth0 only) on which to run the DHCP server. Comment out any options pertaining to DHCP for IPv6. The stock DHCP configuration is located at /etc/dhcp/dhcpd.conf . This file contains a number of example subnet declarations that you are meant to pick and choose from in order to configure the DHCP server and to distribute addresses within your predefined address range. For this assignment, our configuration is quite minimal: Specifications Before you start to configure your subnet, comment out the lines near the top of the file that specify global settings for nameservers and domain (we won\u2019t use them right now). Create a new subnet configuration block using the network ID and network mask you established in the LAN Planning Exercise . Inside the subnet block, define a contiguous range of IP addresses for the DHCP pool out of the address range selected in the LAN Planning Exercise . You may browse the othe options available, but at this point you should not specify anything other than the DHCP lease range. Why don't we configure the default gateway or name servers yet? Students will frequently jump ahead and fill in additional network parameters. The reason we don't want to include these parameters yet is that our Pi is not yet ready to provide an Internet connection. Sending a default route back to your workstation will create a black hole of sorts for Internet traffic. Your computer will try to route the traffic through the Pi, and the Pi will simply drop everything it receives. Test DHCP Server \u00b6 Use systemctl to restart the DHCP service as shown here: sudo systemctl restart isc-dhcp-server.service If you see errors such as the one shown here, you\u2019ll need to continue troubleshooting the DHCP server (see next section). pi@titan:~ $ sudo systemctl restart isc-dhcp-server.service Job for isc-dhcp-server.service failed because the control process exited with error code. See \"systemctl status isc-dhcp-server.service\" and \"journalctl -xe\" for details. Check your local machine to confirm that an IP address in the specified network range was provided. Try running ping from both directions (laptop -> pi and pi -> laptop) to confirm that the IP address and related settings are configured correctly. Warning If you are on Windows, incoming ping requests (those from pi -> laptop) will not get any response. This is because by default Windows Firewall blocks these requests from being answered. To disable this, run a PowerShell prompt as Administrator and enter these commands: New-NetFirewallRule -DisplayName \"Allow inbound ICMPv4\" -Direction Inbound -Protocol ICMPv4 -IcmpType 8 -Action Allow New-NetFirewallRule -DisplayName \"Allow inbound ICMPv6\" -Direction Inbound -Protocol ICMPv6 -IcmpType 8 -Action Allow Troubleshooting \u00b6 Raspberry Pi OS provides us with several commands to troubleshoot and find errors related to services. Check status and recent log output using systemctl status isc-dhcp-server.service or journalctl -xe . Search the system logs for relevant errors journalctl -u isc-dhcp-server Here are some additional considerations: A misplaced space or bracket may cause DHCP to fail, so pay close attention to syntax. Your Pi will keep it's static address, so be sure that you excluded the address from the lease range in dhcpd.conf . Double check that you\u2019ve configured the server defaults with the correct interface names and commented out IPv6 related settings. Make sure both dhcpd and systemd are declaring the same static IP for the Pi. Inspect DHCP leases for clues. They can be found at /var/lib/dhcp/dhcpd.leases .","title":"Installing and Configuring the ISC DHCP Server"},{"location":"assignments/dhcp-setup/#set-up-a-dhcp-server-for-your-lan-2022-04-11","text":"","title":"Set up a DHCP Server for your LAN (2022-04-11)"},{"location":"assignments/dhcp-setup/#overview","text":"In this assignment, we'll be standing up a DHCP service on the Raspberry Pi. As we've discussed in class, DHCP is a function that is sometimes performed by routers and is a necessary service whenever we are creating a new network (of almost any type).","title":"Overview"},{"location":"assignments/dhcp-setup/#before-you-start","text":"Before starting any of the work within this checkpoint, make sure that you have completed all steps from checkpoint one, including the networkd setup. You must also have completed the Address Planning Exercise correctly. You will use the parameters you selected in that exercise to configure the IP address for the Pi as well as the configuration for isc-dhcp-server .","title":"Before you Start"},{"location":"assignments/dhcp-setup/#configure-static-addresses-for-your-raspberry-pi","text":"In this step, you will add a new configuration file to networkd in order to set up static addresses on eth0 . The addresses you use here will be the one you defined for your DHCP Server and Default Gateway in the LAN Planning Exercise . Please do not try to follow other tutorials for setting up addresses Every quarter, we have students who choose to follow online tutorials instead of the instructions we've provided. Please be aware that we are not using the default Raspberry Pi networking. These tutorials will often instruct you to configure static addresses in the /etc/dhcpcd.conf file or /etc/network/interfaces . Both of these methods were disabled when we set up networkd . Create a file named 20-eth0.network in /etc/systemd/network/ (you'll need to use sudo ) and define a static configuration that includes your chosen IP address and CIDR range. This path should already contain a default configuration for ethernet interfaces, e.g., 99-eth.network . We are overriding this configuration for eth0 by naming the file in such a way that networkd will load it first and by ensuring that the configuration will match eth0 exactly. Your file should look something like: /etc/systemd/network/20-eth0.network [Match] # We only want to match the eth0 interface Name = eth0 # Provide full address config in abbreviated notation [Network] # Default Gateway / DHCP Server Address = 192.168.0.1/24 # Enable link local addresses for IPv6 (FE80::) LinkLocalAddressing = ipv6 Warning Some online references will have you add a gateway and DNS settings for your new interface. You don't need to (and definitely shouldn't) add either to this interface. This interface does not provide a path for Internet traffic, but your Pi will try to use it that way if it believes it can be used for a default route. Likewise, we don't need to give the Pi DNS settings on Ethernet. The Pi will get it\u2019s DNS from the wireless interface, which received it\u2019s DNS settings from DHCP. In order to test these new settings: Call sudo systemctl restart systemd-networkd.service or reboot your Pi. Once you log back in, verify that networkd is running by calling systemctl status systemd-networkd and use the ip addr command to check that eth0 is online with the new address. Attention Make note that the Pi is now assigned to our new subnet, but our computer will still be using it's autoconfigured IPv4 address in the 169.254/16 range. In an IPv4 only world, this would prevent us from talking to the Pi. To fix the problem, we'd have to manually configure a static IP on our laptop in the same range as the Pi's network ID. Fortunately, both devices have autoconfigured IPv6 addresses that will be discovered through mDNS. By default, this is the address that SSH will use.","title":"Configure Static Addresses for your Raspberry Pi"},{"location":"assignments/dhcp-setup/#install-and-configure-dhcp","text":"For this part of the exercise, we'll use the ISC DHCP Server. The ISC server is available in apt repositories, so it can be installed using: sudo apt update sudo apt install isc-dhcp-server Warning Right after installation, isc-dhcp-server will report that it failed to run, and spit out lots of nasty-looking errors. This is normal, as the DHCP server has not yet been configured. Edit /etc/default/isc-dhcp-server to specify the interfaces ( eth0 only) on which to run the DHCP server. Comment out any options pertaining to DHCP for IPv6. The stock DHCP configuration is located at /etc/dhcp/dhcpd.conf . This file contains a number of example subnet declarations that you are meant to pick and choose from in order to configure the DHCP server and to distribute addresses within your predefined address range. For this assignment, our configuration is quite minimal: Specifications Before you start to configure your subnet, comment out the lines near the top of the file that specify global settings for nameservers and domain (we won\u2019t use them right now). Create a new subnet configuration block using the network ID and network mask you established in the LAN Planning Exercise . Inside the subnet block, define a contiguous range of IP addresses for the DHCP pool out of the address range selected in the LAN Planning Exercise . You may browse the othe options available, but at this point you should not specify anything other than the DHCP lease range. Why don't we configure the default gateway or name servers yet? Students will frequently jump ahead and fill in additional network parameters. The reason we don't want to include these parameters yet is that our Pi is not yet ready to provide an Internet connection. Sending a default route back to your workstation will create a black hole of sorts for Internet traffic. Your computer will try to route the traffic through the Pi, and the Pi will simply drop everything it receives.","title":"Install and Configure DHCP"},{"location":"assignments/dhcp-setup/#test-dhcp-server","text":"Use systemctl to restart the DHCP service as shown here: sudo systemctl restart isc-dhcp-server.service If you see errors such as the one shown here, you\u2019ll need to continue troubleshooting the DHCP server (see next section). pi@titan:~ $ sudo systemctl restart isc-dhcp-server.service Job for isc-dhcp-server.service failed because the control process exited with error code. See \"systemctl status isc-dhcp-server.service\" and \"journalctl -xe\" for details. Check your local machine to confirm that an IP address in the specified network range was provided. Try running ping from both directions (laptop -> pi and pi -> laptop) to confirm that the IP address and related settings are configured correctly. Warning If you are on Windows, incoming ping requests (those from pi -> laptop) will not get any response. This is because by default Windows Firewall blocks these requests from being answered. To disable this, run a PowerShell prompt as Administrator and enter these commands: New-NetFirewallRule -DisplayName \"Allow inbound ICMPv4\" -Direction Inbound -Protocol ICMPv4 -IcmpType 8 -Action Allow New-NetFirewallRule -DisplayName \"Allow inbound ICMPv6\" -Direction Inbound -Protocol ICMPv6 -IcmpType 8 -Action Allow","title":"Test DHCP Server"},{"location":"assignments/dhcp-setup/#troubleshooting","text":"Raspberry Pi OS provides us with several commands to troubleshoot and find errors related to services. Check status and recent log output using systemctl status isc-dhcp-server.service or journalctl -xe . Search the system logs for relevant errors journalctl -u isc-dhcp-server Here are some additional considerations: A misplaced space or bracket may cause DHCP to fail, so pay close attention to syntax. Your Pi will keep it's static address, so be sure that you excluded the address from the lease range in dhcpd.conf . Double check that you\u2019ve configured the server defaults with the correct interface names and commented out IPv6 related settings. Make sure both dhcpd and systemd are declaring the same static IP for the Pi. Inspect DHCP leases for clues. They can be found at /var/lib/dhcp/dhcpd.leases .","title":"Troubleshooting"},{"location":"assignments/dns-planning/","text":"Overview The objective of this exercise is to use basic knowledge of the Domain Name System (DNS) to define public and private domains for use in upcoming exercises. Follow the attached instructions to determine the organization of your domains according to the given specifications. Before you start, review this week's readings and DNS-related resources to understand the structure and constraints of legal domain names as well as the distinction between a hostname, a sub-domain, and a domain. Give consideration as well to DNS resource naming schemes. Objective For this exercise, you'll select two DNS domains and provide names for resources that would be associated with these domains. The first domain that you define will be a public-facing domain. Your public domain is the domain that customers (or in this case, classmates) would use to connect to resources you put on the Internet. The second domain we\u2019ll define is for private use only. Our private domain name will be a sub-domain of our public DNS with the restriction that it will only be available on the LAN. Private domains are incredibly valuable in business networks, where they are servers, printers, and other resources without having to keep track of IP addresses or to rely on less secure mechanisms like MDNS. Specifications All domains created for this assignment must use the .pi TLD, e.g., domain.pi. Choose a unique name for your public-facing domain name, making sure to satisfy the appropriate constraints for naming a domain. Choose a private-facing sub-domain within your public-facing domain to use for private DNS (DNS within your own intranet). The name of your subdomain does not have to be unique, since it\u2019ll be under the hierarchy of your unique public-facing domain, e.g., corp.domain.pi or lan.domain.pi. Define hostnames for important resources within your public and private-facing DNS. Each of your two domains will have its own name server. Internally (private-facing), you may refer to your name server with the same hostname that you\u2019ve already assigned your Pi, e.g., titan.corp.domain.pi. Externally (public-facing), we typically follow some sort of standardized naming convention for important server roles like our name server, e.g., ns.domain.pi or dns01.domain.pi. On your public-facing domain, define additional hostnames for the following resources: An SMTP server (mail server) that will receive mail from other domains. Mail servers also tend to follow a standard naming convention, e.g., mail01.domain.pi. A webmail server that your users can use to access their inboxes. Pick a user-friendly name that will be easy for users to remember. A hostname (web server) that customers would use to find your website. Pick a user-friendly name that will be easy for users to remember. Deliverables Fill in this provided template Download this provided templateas guided above. Then with your Linux Networking GitHub repository you created in the Checkpoints: Create a new branch for this assignment using 'git checkout -b dns-planning' Add your DNS Planning Excercise Report.md' to your repository folder. Keep it in Markdown (.md) format, don't export it to PDF. After adding the files to your repository folder, use 'git add .' to add the files to your commit you will submit Commit your added files using 'git commit -m ' Push your new commit using 'git push origin dns-planning' Create a new Pull Request for this branch by going to your GitHub repository webpage, selecting the \"Pull Requests\", selecting \"New Pull Request\", and selecting your new commit. DO NOT MERGE THE COMMIT INTO MASTER IF ASKED. The pull requests are for us to check over your work before merging it into master. Submit the link for the Pull Request via Canvas","title":"Dns planning"},{"location":"assignments/dns-zone-setup/","text":"Authoritative Name Server (last edited 2022-05-10) \u00b6 Overview \u00b6 In this assignment, we will extend our BIND configuration (think back to our DNS Resolver checkpoint ) to handle DNS queries for a domain that is in your complete control. While you don't have very many services or resources available on your network yet, this project should help you explore the ways in which DNS can be used to identify resources on a network as you add them. This task will build upon the work you did in the DNS Planning Exercise . Important With each checkpoint, we expect you to do more of the work on your own. While the initial Pi setup gave clear instructions, we are slowly moving toward giving you specifications and additional context that you need in order to determine the right steps to accomplish the task. In this assignment, you will use the provided reference documents to help you configure the project according to specification. For some students, this can be a challenging adjustment, but it is also a valuable skill to learn and practice as you prepare for technical internships and jobs. Before you start \u00b6 Before you begin, make sure that you have completed all steps through Checkpoint #4 successfully. At this point, BIND is installed and configured so that your Pi can resolve DNS queries from clients inside your LAN. DHCP is configured to provide LAN clients with the IP address of this resolver (via the domain-name-server option), and you have tested that DNS resolution is working. Before you begin, you should also confirm that you have completed the LAN Planning and DNS Planning exercises. You will be required to refer back to these worksheets. Configure the Name Server's IP Address \u00b6 During our initial LAN planning, you selected a separate static IP address for your authoritative name server. Before starting on the application level configuration, be sure to configure the new address on the LAN interface. Create a new zone file \u00b6 The documentation installed with BIND provides guidance for where to store zone files on your name server. The recommendation for primary name servers, such as the one we are creating, is to store the zone files in /etc/bind or one of its subdirectories. For this project, create a new sub-directory called zones within /etc/bind as shown below and copy the existing db.local into it as a starting point for creating your zone. Each domain used in this assignment will require its own zone file, named according to the following convention, db.<domain_name> . For example, the full path to the zone file storing gradebook.pi would be /etc/bind/zones/db.gradebook.pi. Creating your starter zone file If you have copied db.local, the initial contents of your zone file will look similar to this: ; ; BIND data file for local loopback interface ; $TTL 604800 @ IN SOA localhost. root.localhost. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS localhost. @ IN A 127.0.0.1 @ IN AAAA ::1 As is stated in the comment at the start of the file, this file is defining a special purpose zone for the localhost domain to ensure proper handling when the name is passed to BIND. Customize the localhost zone file for your own domains \u00b6 Your task at this point is to update this file to describe the domains that you selected in the DNS Planning Exercise . Important Your primary resource for this task is the Zone File Reference , which outlines the format of the zone file and the resource records that we will use. It may also be helpful to examine the section Creating the Forward Zone File in DigitalOcean's Tutorial Customize the Start of Authority (SOA) \u00b6 Update the comments at the start of the file to refer to your domain and then modify the SOA resource record based on the fully-qualified domain name of your Pi and a valid email address, e.g., your UW email. Specifying e-mail addresses for SOA records While it's not apparent on first glance, every SOA resource record contains a field called the RNAME, which specifies an email address associated with the administrator for the domain. As mentioned in Zone File Reference , RNAME records receive special formatting. You must replace the @ with a . . If the user portion of the address contains any periods, prefix with an \\ to escape them. Add NS and A records for the nameservers \u00b6 Delete the initial NS and glue records and create a new NS record and a type A glue record for your name server. The NS record will point to your server by its fully-qualified domain name. Likewise, the A record will contain the internal IP address of your server (as determined in LAN planning). The Zone File Reference provides real world examples of name servers and glue records. Using dig , e.g., dig NS microsoft.com , you can find additional examples for pretty much any public domain. Add records for additional DNS resources \u00b6 Using the provided Zone File Reference , create additional MX and A records to identify the mail server that you defined in the DNS Planning Exercise . It's okay that we haven't set up the mail server yet. Refer back to your LAN Planning and select an unused static address. Attention Pay close attention to the expected format of an MX resource record. It varies slightly from other common record types and leads to frequent errors. Declare both zones in named.conf.local \u00b6 The zone file that you have created defines the resources that can be queried by your name server, but it does not yet instruct BIND to serve the domain. To accomplish this, we will add a new zone configuration for each within /etc/bind/named.conf.local . Instructions Open /etc/bind/named.conf.local and add a new zone reference: // Replace references to gradebook.pi with your own domain name zone \"gradebook.pi\" IN { // We're setting up the primary server for the zone. In DNS, a primary // contains the zone file for a domain while secondary servers read the // zone contents from a primary server. type primary; file \"/etc/bind/zones/db.gradebook.pi\"; }; Update listen-on addresses \u00b6 In an earlier step, you set up the layer-3 configuration for a new IP address on the Pi. Update the listen-on setting you defined in the previous checkpoint to include the name server address. With this change, BIND will be able to answer recursive and authoritative queries on both addresses. We'll make further changes in the final group project to add more security and limit which queries can be answered on each IP. Validate and test your configuration \u00b6 Run named-checkconf -z to identify any immediate errors in your configuration or zone file and restart the bind9 service using systemctl . Use systemctl to verify that the service is running correctly. You can also test your configuration locally on the Pi by running dig @127.0.0.1 ns <DOMAIN_NAME> . Pay close attention to status codes and errors appearing in the response. Update DHCP \u00b6 Your LAN clients should be able to query the new domain without any additional configuration; however, we will take the opportunity to make one additional update to DHCP. Following the same process you've encountered in previous guides add the domain-name option to your subnet configuration, providing the private domain name establised in the DNS planning exercise. This option configures your LAN clients to recognize your internal domain as a default domain name when attempting to resolve hosts, e.g., dig titan would resolve records for titan.corp.gradebook.pi . Additional Resources \u00b6 A Comparison of DNS Server Types RFC 1034: Domain Names - Concepts and Facilities RFC 1035: Domain Names - Implementation and Specification How to format a zone file (Dyn.com) How to configure BIND as a Private Network DNS Server - DigitalOcean Tutorial","title":"Authoritative Zone Setup"},{"location":"assignments/dns-zone-setup/#authoritative-name-server-last-edited-2022-05-10","text":"","title":"Authoritative Name Server (last edited 2022-05-10)"},{"location":"assignments/dns-zone-setup/#overview","text":"In this assignment, we will extend our BIND configuration (think back to our DNS Resolver checkpoint ) to handle DNS queries for a domain that is in your complete control. While you don't have very many services or resources available on your network yet, this project should help you explore the ways in which DNS can be used to identify resources on a network as you add them. This task will build upon the work you did in the DNS Planning Exercise . Important With each checkpoint, we expect you to do more of the work on your own. While the initial Pi setup gave clear instructions, we are slowly moving toward giving you specifications and additional context that you need in order to determine the right steps to accomplish the task. In this assignment, you will use the provided reference documents to help you configure the project according to specification. For some students, this can be a challenging adjustment, but it is also a valuable skill to learn and practice as you prepare for technical internships and jobs.","title":"Overview"},{"location":"assignments/dns-zone-setup/#before-you-start","text":"Before you begin, make sure that you have completed all steps through Checkpoint #4 successfully. At this point, BIND is installed and configured so that your Pi can resolve DNS queries from clients inside your LAN. DHCP is configured to provide LAN clients with the IP address of this resolver (via the domain-name-server option), and you have tested that DNS resolution is working. Before you begin, you should also confirm that you have completed the LAN Planning and DNS Planning exercises. You will be required to refer back to these worksheets.","title":"Before you start"},{"location":"assignments/dns-zone-setup/#configure-the-name-servers-ip-address","text":"During our initial LAN planning, you selected a separate static IP address for your authoritative name server. Before starting on the application level configuration, be sure to configure the new address on the LAN interface.","title":"Configure the Name Server's IP Address"},{"location":"assignments/dns-zone-setup/#create-a-new-zone-file","text":"The documentation installed with BIND provides guidance for where to store zone files on your name server. The recommendation for primary name servers, such as the one we are creating, is to store the zone files in /etc/bind or one of its subdirectories. For this project, create a new sub-directory called zones within /etc/bind as shown below and copy the existing db.local into it as a starting point for creating your zone. Each domain used in this assignment will require its own zone file, named according to the following convention, db.<domain_name> . For example, the full path to the zone file storing gradebook.pi would be /etc/bind/zones/db.gradebook.pi. Creating your starter zone file If you have copied db.local, the initial contents of your zone file will look similar to this: ; ; BIND data file for local loopback interface ; $TTL 604800 @ IN SOA localhost. root.localhost. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS localhost. @ IN A 127.0.0.1 @ IN AAAA ::1 As is stated in the comment at the start of the file, this file is defining a special purpose zone for the localhost domain to ensure proper handling when the name is passed to BIND.","title":"Create a new zone file"},{"location":"assignments/dns-zone-setup/#customize-the-localhost-zone-file-for-your-own-domains","text":"Your task at this point is to update this file to describe the domains that you selected in the DNS Planning Exercise . Important Your primary resource for this task is the Zone File Reference , which outlines the format of the zone file and the resource records that we will use. It may also be helpful to examine the section Creating the Forward Zone File in DigitalOcean's Tutorial","title":"Customize the localhost zone file for your own domains"},{"location":"assignments/dns-zone-setup/#customize-the-start-of-authority-soa","text":"Update the comments at the start of the file to refer to your domain and then modify the SOA resource record based on the fully-qualified domain name of your Pi and a valid email address, e.g., your UW email. Specifying e-mail addresses for SOA records While it's not apparent on first glance, every SOA resource record contains a field called the RNAME, which specifies an email address associated with the administrator for the domain. As mentioned in Zone File Reference , RNAME records receive special formatting. You must replace the @ with a . . If the user portion of the address contains any periods, prefix with an \\ to escape them.","title":"Customize the Start of Authority (SOA)"},{"location":"assignments/dns-zone-setup/#add-ns-and-a-records-for-the-nameservers","text":"Delete the initial NS and glue records and create a new NS record and a type A glue record for your name server. The NS record will point to your server by its fully-qualified domain name. Likewise, the A record will contain the internal IP address of your server (as determined in LAN planning). The Zone File Reference provides real world examples of name servers and glue records. Using dig , e.g., dig NS microsoft.com , you can find additional examples for pretty much any public domain.","title":"Add NS and A records for the nameservers"},{"location":"assignments/dns-zone-setup/#add-records-for-additional-dns-resources","text":"Using the provided Zone File Reference , create additional MX and A records to identify the mail server that you defined in the DNS Planning Exercise . It's okay that we haven't set up the mail server yet. Refer back to your LAN Planning and select an unused static address. Attention Pay close attention to the expected format of an MX resource record. It varies slightly from other common record types and leads to frequent errors.","title":"Add records for additional DNS resources"},{"location":"assignments/dns-zone-setup/#declare-both-zones-in-namedconflocal","text":"The zone file that you have created defines the resources that can be queried by your name server, but it does not yet instruct BIND to serve the domain. To accomplish this, we will add a new zone configuration for each within /etc/bind/named.conf.local . Instructions Open /etc/bind/named.conf.local and add a new zone reference: // Replace references to gradebook.pi with your own domain name zone \"gradebook.pi\" IN { // We're setting up the primary server for the zone. In DNS, a primary // contains the zone file for a domain while secondary servers read the // zone contents from a primary server. type primary; file \"/etc/bind/zones/db.gradebook.pi\"; };","title":"Declare both zones in named.conf.local"},{"location":"assignments/dns-zone-setup/#update-listen-on-addresses","text":"In an earlier step, you set up the layer-3 configuration for a new IP address on the Pi. Update the listen-on setting you defined in the previous checkpoint to include the name server address. With this change, BIND will be able to answer recursive and authoritative queries on both addresses. We'll make further changes in the final group project to add more security and limit which queries can be answered on each IP.","title":"Update listen-on addresses"},{"location":"assignments/dns-zone-setup/#validate-and-test-your-configuration","text":"Run named-checkconf -z to identify any immediate errors in your configuration or zone file and restart the bind9 service using systemctl . Use systemctl to verify that the service is running correctly. You can also test your configuration locally on the Pi by running dig @127.0.0.1 ns <DOMAIN_NAME> . Pay close attention to status codes and errors appearing in the response.","title":"Validate and test your configuration"},{"location":"assignments/dns-zone-setup/#update-dhcp","text":"Your LAN clients should be able to query the new domain without any additional configuration; however, we will take the opportunity to make one additional update to DHCP. Following the same process you've encountered in previous guides add the domain-name option to your subnet configuration, providing the private domain name establised in the DNS planning exercise. This option configures your LAN clients to recognize your internal domain as a default domain name when attempting to resolve hosts, e.g., dig titan would resolve records for titan.corp.gradebook.pi .","title":"Update DHCP"},{"location":"assignments/dns-zone-setup/#additional-resources","text":"A Comparison of DNS Server Types RFC 1034: Domain Names - Concepts and Facilities RFC 1035: Domain Names - Implementation and Specification How to format a zone file (Dyn.com) How to configure BIND as a Private Network DNS Server - DigitalOcean Tutorial","title":"Additional Resources"},{"location":"assignments/final-project-virtual/","text":"Final Network Project (last edited 2020-06-09) \u00b6 Overview \u00b6 Working in your group, design and implement a networked system that mirrors the concept of an Internet Service Provider (ISP) with customer networks. Your primary objective in this exercise is to adapt what you've completed in previous tasks to meet the requirements specified below. Although you will be working together as a group on this project, each participant will take the lead on configuring their own network device to integrate into the ISP network. Additional configuration guidance will be made available through Slack. We will walk through new tasks together in our remaining lectures/labs. Important Instructions As soon as possible, please browse to following link and provide the requested information about your group's WireGuard configuration and individual .pi Name Servers: PICANN Registry Take time to plan out the network design and IP address usage with your group before you build. This plan is a mandatory deliverable and will be required before implementation assistance is given. We recommend that you sketch out an initial diagram of the entire network and create a checklist of major settings for each device. Before you start \u00b6 Each of your group members need to have completed the individual project checkpoints before proceeding with the configuration necessary for the final network. Each pi should function as a network gateway while also providing DHCP and private DNS services to an Ethernet-based LAN. Project Details \u00b6 The following outline summarizes the steps that are needed to inter-network your individual LANs and join them up to the global, PiCANN internet core. Once you have completed these tasks, you will be able to route traffic across our class network and participate in friendly email exchanges with your classmates on the .pi top level domain! With your group, review the ASN and address ranges defined at PiCANN and assign and ASN and distinct subnet to each group member. With your group, configure a Debian 10.3 VM at DigitalOcean (or other cloud provider) to act as an ISP router for your group using VPN-based routing links. Design a new address plan for your LAN/WAN presence based on the address range assigned in Step 1 and including a minimum of two subnets . Configure a routing link between your Pi-based router and the cloud-based ISP, setting up both ends of the VPN and the BGP peering relationships. Review the documentation you created for your .pi domain in Checkpoint #5 and update your DNS plan according to your new address plan. Configure additional \"DMZ\" addresses on your Pi and update your DNS zone configuration to serve the new addresses correctly. Install and configure the Docker-based mail servers based on your own network settings. Work with your group to test and document your work, ensuring that routing and DNS are working consistently across your shared ISP and individual Edge routers. Using your shiny new webmail service, send an email to clinton@gradebook.pi . Planning \u00b6 Up until this point, you have each configured your networks with private address ranges of your own choosing. While this is convenient for getting started, it doesn't lend itself well to a class-wide internet where each device must have its own unique addresses. Going forward, we will ask you to re-number your networks to use the assigned address blocks. This will require a small amount of collaboration within your group to assign sub-ranges. Specifications \u00b6 Assign an ASN and a distinct subnet to each member of your team. All ASNs and subnets must fall within the larger range provided for your group. Select an additional ASN to use for peering between your ISP router and the PiCANN core. Update the PiCANN peering directory with this information. Document your team's address range and individual assignments within a markdown document called final-planning.md. This document should be uploaded to your team's repository as soon as possible for referenced during the remaining parts of the project. Documentation \u00b6 As you work through each part of this project, carefully document the decisions that you make. The process of planning and recording documentation will help you to avoid mistakes and simplify the troubleshooting process. Likewise, you will be asked to provide a comprehensive view of your network design within your GitHub repository. Detailed documentation requirements are provided within the Canvas assignments. ISP Router \u00b6 As a group, you will need to set up a new Debian 10.3 droplet at Digital Ocean, install WireGuard and Free Range Routing packages, and configure a WireGuard and BGP to create a routing link with the core network. This link will provide connectivity to the other groups in the class, and the peering relationship you create with the core router will be used to exchange routes between upstream and downstream routers. Completion of this task will require collaboration with the Instruction team. Consult the [PiCANN] registry for VPN/BGP parameters that your group will use to peer with the core router. Fill in the missing values with your public key and the ASN that you assigned to the ISP router. Notify the instruction team via Slack so that we can complete the upstream configuration. Specifications \u00b6 Create a new VM using the $5/mo specs and the SSH key of one of your group members. You may also wish to enable IPv6 (can improve connectivity if any of your team mmembers have IPv6 capable ISPs (such as Comcast). Update /root/.ssh/authorized_keys on your VM to include public keys for each of your group members as well as the following key for the instructor: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIBJTZTstXqjM7lEaFj/pnRNEztiZYu4yhKBZDrUCYMi5 clinton@info314 . Install WireGuard and Free Range Routing (FRR) based on the instructions given in class and the guides posted on this site. Create a new private/public key pair and add the public key to PiCANN along with the public IPv4 address of your router. Referencing your groups configuration parameters in PiCANN, configure a persistent VPN interface to connect to the core based on the legacy Debian networking approach. Configure FRR to enable BGP and establish a peer relationship with the PiCANN core. Refer to the documentation from Checkpoint #3 to enable IPv4 forwarding with sysctl and create iptables rules to allow packets to be forwarded from your WireGuard tunnel interface. As with Checkpoint #3, set the default forwarding policy to drop packets. Make sure that you have updated the peering worksheet in PiCANN with missing parameters and notify the Instruction team that your peer is ready to connect. LAN/WAN Address Planning \u00b6 Specifications \u00b6 Each group member should subnet their PiCANN subnet into 2 - 4 distinct subnets. A minimum of two subnets per LAN are needed to meet the base project requirements. If you would like to experiment with more complex configurations later we recommend four subnets. Use one of your subnets for your internal LAN (providing DHCP and other services to devices accessing through Ethernet). A second subnet should be dedicated to any public-facing services. We'll often associate this subnet with your \"DMZ\". Edge Network Setup \u00b6 After you complete your final planning for your LAN and public address ranges, you should \"re-number\" your LAN connection to use the new LAN address range. To save yourself significant troubleshooting time, proceed carefully with this task and make sure that you apply updates to networkd, DHCP, iptables, and BIND as required to support the new addresses. It will likely be helpful to review your previous work and the guides for the past Checkpoints (especially 1 - 4). The next task in store for you is to establish connectivity and routing to the ISP VM that your group configured earlier. This is a two-part process, as you will need to create a WireGuard interface and configure peering on both routers (Debian VM and Pi). Keep in mind at this point that there are slight differences in the implementation on each end of this connection. The WireGuard configuration on the Debian VM relies on legacy Debian networking configuration while the Pi will be configured with the built-in WireGuard capabilities of systemd-networkd . We have provided reference documentation and video demos for each scenario. The tasks you are completing are not extremely difficult, but there are ample opportunities for confusion. You should review instructions and make sure that your planning documents include all of the IP addresses and other values that you will need. Having this information well organized can be the difference between finishing this task in an hour versus spending several hours debugging. Specifications \u00b6 Update all network-based services on your LAN to use the new IP address ranges as determined by your group assignments and your own address planning. Follow the linked resources to install WireGuard and Free Range Routing (FRR) on your Pi-based router. Create a new WireGuard interface and configure it to peer with the Debian-based ISP router shared with your group. Configure both ends of the VPN tunnel with IP addresses selected from your public/DMZ subnet. These addresses should be documented on your report. Since your Pi router is most likely located behind a NAT, it will not be possible for the ISP router to open/reopen the WireGuard tunnel for traffic directed to your Pi. Configure a persistent keep-alive of 25 seconds in the WireGuard peer settings on the Pi. Enable the FRR BGP daemon and configure your new router based on the provided guides. In order to do this, you will need an ASN and an additional public address to use as a router ID. Make sure that both values are included in your documentation. Log into the ISP router and update its BGP router settings to recognize your Pi-based router as a neighbor You will need the tunnel addresses from the previous step and the ASN identifiers assigned by your group to the ISP and your Edge network. Repeat the configuration process on your local router, setting up a peering (neighbor) relationship with the ISP. Use the network directive to configure your local BGP to advertise the entire LAN/WAN subnet range that you were assigned by your group. Update iptables to enable packet forwarding from your new WireGuard interface. .Pi DNS Resolution \u00b6 We've intentionally set up all of our domains within the non-existent .pi top-level domain and are limiting the resolution of these domains to our class network. By default, our resolvers won't be able to perform queries against other .pi domains since the recursive process depends on relationship between the ICANN root and the top-level domain registries. Our TLD is not present in those data stores, so we need to offer it a little help to resolve .pi domains. The work-around we're employing is to have each of your resolvers maintain a copy of the .pi zone so that it can directly discover the authoritative name servers of your peers' domains. The primary name server for .pi is running at the 10.10.10.10 address. By adding the following section to your /etc/bind/named.conf.local, your pi will perform a zone transfer with 10.10.10.10 and then periodically refresh based on the settings specified in the SOA for the TLD. zone \"pi\" IN { type primaries; secondaries { 10.10.10.10; }; }; Note If you've configured separate views for internal and external name resolution, this will be inserted into the internal view. Override DNS resolution on the Pi \u00b6 You have likely noticed that when you run a dig query from your Pi, the query will not be sent to the resolver running on your Pi. Instead, by default, these queries are sent to the addresses provided to you by DHCP on your wireless network. This leads to a case where the hosts on your network can resolve .pi domains while the Pi itself cannot. We can easily override this behavior by modifying /etc/systemd/network/99-wlan.network to add a the localhost address as a static DNS location. While your Pi will still receive additional addresses from DHCP, your Pi will only use these as a fallback. The updated configuration is shown below. [Match] Name=wlan* [Network] DHCP=yes DNS=127.0.0.1 Important You will likely need to reboot your Pi before this new setting is respected. Public Services \u00b6 Use systemd-networkd to create and configure a persistent dummy interface on the Pi as described in the attached resources. This interface will represent the \"demilitarized-zone\" of your network within which you will host your public services. For each service, you will need to set up an IP from your public subnet within the DMZ. Follow the instructions provided in the Pi Mail repository to install Docker and configure the SMTP, IMAP, and Rainloop containers to serve email for your domain. Be sure to map each of these servers to a public IP address within your DMZ. Set up your Authoritatitive Name Server to listen on a public IP address within your DMZ. Update all records, e.g., MX and webmail, to point to the correct IP addresses based on your final network planning. Allow External DNS Queries \u00b6 At this point, we are expecting the Bind9 daemon to perform two different roles, acting as a recursive resolver and as an authoritative name server. While Bind9 is more than capable of performing both tasks, this can be a risky configuration. In particular, our authoritative server has to be open to everyone, but an unrestricted resolver is like a welcome mat for attackers who may attempt cache poisoning attacks and botnets that will use it to amplify DDoS attacks. In Checkpoint #4, we took steps to prevent these types of attacks by declaring an access control list (ACL) and using it to restrict which IP addresses are allowed to make recursive queries. The configuration appears in named.conf.options as follows: acl goodclients { localhost; 172.27.2.0/26; }; options { directory \"/var/cache/bind\"; recursion yes; allow-query { goodclients; }; ... In this configuration, your name server won't be able to receive a query outside of your own LAN. With a simple change to the last two lines, we can open up our name server to the outside world while still providing some basic security against misuse. allow-recursion { goodclients; }; // change from `recursion yes;` allow-query { any; }; // change from `{ goodclients; };` Please be aware that we would look for stronger separation between these roles in a real-world scenario. At the very least, we might employ a feature of Bind9 called views . Or we could run multiple instances of Bind9 on separate IP addresses (or entirely separate servers). Making Improvements and Extra Credit \u00b6 Add an Anycast route to 10.10.10.10 and host a copy of the .pi top-level-domain Configure a private DNS zone, e.g., corp.gradebook.pi, and use BIND views to restrict access to your private zone and the DNS resolver so that it is not available outside of your local LAN. Configure policy-based routing to send all of your DNS traffic through the VPN (may be necessary if your ISP is messing with your DNS). Carefully perform hardening of your firewall rules to provide stronger security for your LAN and your router. Add a wireless access point to your Edge LANs. The wlan0 port is capable of operating as a software-based access point using the hostapd package in the Debian repositories. Firewall Rules \u00b6 Carefully perform hardening of your firewall rules to provide stronger security for your LAN and your router. Use the forward chain to prevent new connections into your LAN subnet from the routing link. In order for your users to access the rest of the Internet from your, you must still allow related/established connections back into your LAN. Carefully extend your Iptables rules to support a default DROP policy on the INPUT and OUTPUT chains, making sure that you have full utility of all of your private and public services. When experimenting with default policies on the INPUT or OUTPUT chain, you should ALWAYS use the iptables-apply command to test your rules and confirm that you are still able to create new SSH sessions. Make sure that you have written appropriate rules to accept traffic for authorized services, such as DHCP, SSH, and DNS, before changing the policy. Links and Resources \u00b6 PICANN Registry Pi Mail : Instructions and docker components needed to configure SMTP, IMAP, and a webmail server on your Pi Installing WireGuard Installing Free Range Routing (FRR) WireGuard Peering Configure Routing Links Configure Dummy Interfaces","title":"Final Network Project (last edited 2020-06-09)"},{"location":"assignments/final-project-virtual/#final-network-project-last-edited-2020-06-09","text":"","title":"Final Network Project (last edited 2020-06-09)"},{"location":"assignments/final-project-virtual/#overview","text":"Working in your group, design and implement a networked system that mirrors the concept of an Internet Service Provider (ISP) with customer networks. Your primary objective in this exercise is to adapt what you've completed in previous tasks to meet the requirements specified below. Although you will be working together as a group on this project, each participant will take the lead on configuring their own network device to integrate into the ISP network. Additional configuration guidance will be made available through Slack. We will walk through new tasks together in our remaining lectures/labs. Important Instructions As soon as possible, please browse to following link and provide the requested information about your group's WireGuard configuration and individual .pi Name Servers: PICANN Registry Take time to plan out the network design and IP address usage with your group before you build. This plan is a mandatory deliverable and will be required before implementation assistance is given. We recommend that you sketch out an initial diagram of the entire network and create a checklist of major settings for each device.","title":"Overview"},{"location":"assignments/final-project-virtual/#before-you-start","text":"Each of your group members need to have completed the individual project checkpoints before proceeding with the configuration necessary for the final network. Each pi should function as a network gateway while also providing DHCP and private DNS services to an Ethernet-based LAN.","title":"Before you start"},{"location":"assignments/final-project-virtual/#project-details","text":"The following outline summarizes the steps that are needed to inter-network your individual LANs and join them up to the global, PiCANN internet core. Once you have completed these tasks, you will be able to route traffic across our class network and participate in friendly email exchanges with your classmates on the .pi top level domain! With your group, review the ASN and address ranges defined at PiCANN and assign and ASN and distinct subnet to each group member. With your group, configure a Debian 10.3 VM at DigitalOcean (or other cloud provider) to act as an ISP router for your group using VPN-based routing links. Design a new address plan for your LAN/WAN presence based on the address range assigned in Step 1 and including a minimum of two subnets . Configure a routing link between your Pi-based router and the cloud-based ISP, setting up both ends of the VPN and the BGP peering relationships. Review the documentation you created for your .pi domain in Checkpoint #5 and update your DNS plan according to your new address plan. Configure additional \"DMZ\" addresses on your Pi and update your DNS zone configuration to serve the new addresses correctly. Install and configure the Docker-based mail servers based on your own network settings. Work with your group to test and document your work, ensuring that routing and DNS are working consistently across your shared ISP and individual Edge routers. Using your shiny new webmail service, send an email to clinton@gradebook.pi .","title":"Project Details"},{"location":"assignments/final-project-virtual/#planning","text":"Up until this point, you have each configured your networks with private address ranges of your own choosing. While this is convenient for getting started, it doesn't lend itself well to a class-wide internet where each device must have its own unique addresses. Going forward, we will ask you to re-number your networks to use the assigned address blocks. This will require a small amount of collaboration within your group to assign sub-ranges.","title":"Planning"},{"location":"assignments/final-project-virtual/#specifications","text":"Assign an ASN and a distinct subnet to each member of your team. All ASNs and subnets must fall within the larger range provided for your group. Select an additional ASN to use for peering between your ISP router and the PiCANN core. Update the PiCANN peering directory with this information. Document your team's address range and individual assignments within a markdown document called final-planning.md. This document should be uploaded to your team's repository as soon as possible for referenced during the remaining parts of the project.","title":"Specifications"},{"location":"assignments/final-project-virtual/#documentation","text":"As you work through each part of this project, carefully document the decisions that you make. The process of planning and recording documentation will help you to avoid mistakes and simplify the troubleshooting process. Likewise, you will be asked to provide a comprehensive view of your network design within your GitHub repository. Detailed documentation requirements are provided within the Canvas assignments.","title":"Documentation"},{"location":"assignments/final-project-virtual/#isp-router","text":"As a group, you will need to set up a new Debian 10.3 droplet at Digital Ocean, install WireGuard and Free Range Routing packages, and configure a WireGuard and BGP to create a routing link with the core network. This link will provide connectivity to the other groups in the class, and the peering relationship you create with the core router will be used to exchange routes between upstream and downstream routers. Completion of this task will require collaboration with the Instruction team. Consult the [PiCANN] registry for VPN/BGP parameters that your group will use to peer with the core router. Fill in the missing values with your public key and the ASN that you assigned to the ISP router. Notify the instruction team via Slack so that we can complete the upstream configuration.","title":"ISP Router"},{"location":"assignments/final-project-virtual/#specifications_1","text":"Create a new VM using the $5/mo specs and the SSH key of one of your group members. You may also wish to enable IPv6 (can improve connectivity if any of your team mmembers have IPv6 capable ISPs (such as Comcast). Update /root/.ssh/authorized_keys on your VM to include public keys for each of your group members as well as the following key for the instructor: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIBJTZTstXqjM7lEaFj/pnRNEztiZYu4yhKBZDrUCYMi5 clinton@info314 . Install WireGuard and Free Range Routing (FRR) based on the instructions given in class and the guides posted on this site. Create a new private/public key pair and add the public key to PiCANN along with the public IPv4 address of your router. Referencing your groups configuration parameters in PiCANN, configure a persistent VPN interface to connect to the core based on the legacy Debian networking approach. Configure FRR to enable BGP and establish a peer relationship with the PiCANN core. Refer to the documentation from Checkpoint #3 to enable IPv4 forwarding with sysctl and create iptables rules to allow packets to be forwarded from your WireGuard tunnel interface. As with Checkpoint #3, set the default forwarding policy to drop packets. Make sure that you have updated the peering worksheet in PiCANN with missing parameters and notify the Instruction team that your peer is ready to connect.","title":"Specifications"},{"location":"assignments/final-project-virtual/#lanwan-address-planning","text":"","title":"LAN/WAN Address Planning"},{"location":"assignments/final-project-virtual/#specifications_2","text":"Each group member should subnet their PiCANN subnet into 2 - 4 distinct subnets. A minimum of two subnets per LAN are needed to meet the base project requirements. If you would like to experiment with more complex configurations later we recommend four subnets. Use one of your subnets for your internal LAN (providing DHCP and other services to devices accessing through Ethernet). A second subnet should be dedicated to any public-facing services. We'll often associate this subnet with your \"DMZ\".","title":"Specifications"},{"location":"assignments/final-project-virtual/#edge-network-setup","text":"After you complete your final planning for your LAN and public address ranges, you should \"re-number\" your LAN connection to use the new LAN address range. To save yourself significant troubleshooting time, proceed carefully with this task and make sure that you apply updates to networkd, DHCP, iptables, and BIND as required to support the new addresses. It will likely be helpful to review your previous work and the guides for the past Checkpoints (especially 1 - 4). The next task in store for you is to establish connectivity and routing to the ISP VM that your group configured earlier. This is a two-part process, as you will need to create a WireGuard interface and configure peering on both routers (Debian VM and Pi). Keep in mind at this point that there are slight differences in the implementation on each end of this connection. The WireGuard configuration on the Debian VM relies on legacy Debian networking configuration while the Pi will be configured with the built-in WireGuard capabilities of systemd-networkd . We have provided reference documentation and video demos for each scenario. The tasks you are completing are not extremely difficult, but there are ample opportunities for confusion. You should review instructions and make sure that your planning documents include all of the IP addresses and other values that you will need. Having this information well organized can be the difference between finishing this task in an hour versus spending several hours debugging.","title":"Edge Network Setup"},{"location":"assignments/final-project-virtual/#specifications_3","text":"Update all network-based services on your LAN to use the new IP address ranges as determined by your group assignments and your own address planning. Follow the linked resources to install WireGuard and Free Range Routing (FRR) on your Pi-based router. Create a new WireGuard interface and configure it to peer with the Debian-based ISP router shared with your group. Configure both ends of the VPN tunnel with IP addresses selected from your public/DMZ subnet. These addresses should be documented on your report. Since your Pi router is most likely located behind a NAT, it will not be possible for the ISP router to open/reopen the WireGuard tunnel for traffic directed to your Pi. Configure a persistent keep-alive of 25 seconds in the WireGuard peer settings on the Pi. Enable the FRR BGP daemon and configure your new router based on the provided guides. In order to do this, you will need an ASN and an additional public address to use as a router ID. Make sure that both values are included in your documentation. Log into the ISP router and update its BGP router settings to recognize your Pi-based router as a neighbor You will need the tunnel addresses from the previous step and the ASN identifiers assigned by your group to the ISP and your Edge network. Repeat the configuration process on your local router, setting up a peering (neighbor) relationship with the ISP. Use the network directive to configure your local BGP to advertise the entire LAN/WAN subnet range that you were assigned by your group. Update iptables to enable packet forwarding from your new WireGuard interface.","title":"Specifications"},{"location":"assignments/final-project-virtual/#pi-dns-resolution","text":"We've intentionally set up all of our domains within the non-existent .pi top-level domain and are limiting the resolution of these domains to our class network. By default, our resolvers won't be able to perform queries against other .pi domains since the recursive process depends on relationship between the ICANN root and the top-level domain registries. Our TLD is not present in those data stores, so we need to offer it a little help to resolve .pi domains. The work-around we're employing is to have each of your resolvers maintain a copy of the .pi zone so that it can directly discover the authoritative name servers of your peers' domains. The primary name server for .pi is running at the 10.10.10.10 address. By adding the following section to your /etc/bind/named.conf.local, your pi will perform a zone transfer with 10.10.10.10 and then periodically refresh based on the settings specified in the SOA for the TLD. zone \"pi\" IN { type primaries; secondaries { 10.10.10.10; }; }; Note If you've configured separate views for internal and external name resolution, this will be inserted into the internal view.","title":".Pi DNS Resolution"},{"location":"assignments/final-project-virtual/#override-dns-resolution-on-the-pi","text":"You have likely noticed that when you run a dig query from your Pi, the query will not be sent to the resolver running on your Pi. Instead, by default, these queries are sent to the addresses provided to you by DHCP on your wireless network. This leads to a case where the hosts on your network can resolve .pi domains while the Pi itself cannot. We can easily override this behavior by modifying /etc/systemd/network/99-wlan.network to add a the localhost address as a static DNS location. While your Pi will still receive additional addresses from DHCP, your Pi will only use these as a fallback. The updated configuration is shown below. [Match] Name=wlan* [Network] DHCP=yes DNS=127.0.0.1 Important You will likely need to reboot your Pi before this new setting is respected.","title":"Override DNS resolution on the Pi"},{"location":"assignments/final-project-virtual/#public-services","text":"Use systemd-networkd to create and configure a persistent dummy interface on the Pi as described in the attached resources. This interface will represent the \"demilitarized-zone\" of your network within which you will host your public services. For each service, you will need to set up an IP from your public subnet within the DMZ. Follow the instructions provided in the Pi Mail repository to install Docker and configure the SMTP, IMAP, and Rainloop containers to serve email for your domain. Be sure to map each of these servers to a public IP address within your DMZ. Set up your Authoritatitive Name Server to listen on a public IP address within your DMZ. Update all records, e.g., MX and webmail, to point to the correct IP addresses based on your final network planning.","title":"Public Services"},{"location":"assignments/final-project-virtual/#allow-external-dns-queries","text":"At this point, we are expecting the Bind9 daemon to perform two different roles, acting as a recursive resolver and as an authoritative name server. While Bind9 is more than capable of performing both tasks, this can be a risky configuration. In particular, our authoritative server has to be open to everyone, but an unrestricted resolver is like a welcome mat for attackers who may attempt cache poisoning attacks and botnets that will use it to amplify DDoS attacks. In Checkpoint #4, we took steps to prevent these types of attacks by declaring an access control list (ACL) and using it to restrict which IP addresses are allowed to make recursive queries. The configuration appears in named.conf.options as follows: acl goodclients { localhost; 172.27.2.0/26; }; options { directory \"/var/cache/bind\"; recursion yes; allow-query { goodclients; }; ... In this configuration, your name server won't be able to receive a query outside of your own LAN. With a simple change to the last two lines, we can open up our name server to the outside world while still providing some basic security against misuse. allow-recursion { goodclients; }; // change from `recursion yes;` allow-query { any; }; // change from `{ goodclients; };` Please be aware that we would look for stronger separation between these roles in a real-world scenario. At the very least, we might employ a feature of Bind9 called views . Or we could run multiple instances of Bind9 on separate IP addresses (or entirely separate servers).","title":"Allow External DNS Queries"},{"location":"assignments/final-project-virtual/#making-improvements-and-extra-credit","text":"Add an Anycast route to 10.10.10.10 and host a copy of the .pi top-level-domain Configure a private DNS zone, e.g., corp.gradebook.pi, and use BIND views to restrict access to your private zone and the DNS resolver so that it is not available outside of your local LAN. Configure policy-based routing to send all of your DNS traffic through the VPN (may be necessary if your ISP is messing with your DNS). Carefully perform hardening of your firewall rules to provide stronger security for your LAN and your router. Add a wireless access point to your Edge LANs. The wlan0 port is capable of operating as a software-based access point using the hostapd package in the Debian repositories.","title":"Making Improvements and Extra Credit"},{"location":"assignments/final-project-virtual/#firewall-rules","text":"Carefully perform hardening of your firewall rules to provide stronger security for your LAN and your router. Use the forward chain to prevent new connections into your LAN subnet from the routing link. In order for your users to access the rest of the Internet from your, you must still allow related/established connections back into your LAN. Carefully extend your Iptables rules to support a default DROP policy on the INPUT and OUTPUT chains, making sure that you have full utility of all of your private and public services. When experimenting with default policies on the INPUT or OUTPUT chain, you should ALWAYS use the iptables-apply command to test your rules and confirm that you are still able to create new SSH sessions. Make sure that you have written appropriate rules to accept traffic for authorized services, such as DHCP, SSH, and DNS, before changing the policy.","title":"Firewall Rules"},{"location":"assignments/final-project-virtual/#links-and-resources","text":"PICANN Registry Pi Mail : Instructions and docker components needed to configure SMTP, IMAP, and a webmail server on your Pi Installing WireGuard Installing Free Range Routing (FRR) WireGuard Peering Configure Routing Links Configure Dummy Interfaces","title":"Links and Resources"},{"location":"assignments/group-project-connectivity/","text":"Configure BGP Routing and .Pi DNS Resolution \u00b6 Preparation \u00b6 Review your final network planning documentation and identify the following details: The ASN value assigned to your LAN. Each group member should have a unique ASN from the range given in PiCANN Routing links and associated VLANs that connect to your Pi: Each edge network router will have one routing link to the ISP router The ISP router will have on routing link per edge network plus an uplink to the class network An address from your public address range that you will use to configure your BGP router's router ID Configure Routing Links \u00b6 Follow Getting Started with Free Range Routing (FRR) on Raspberry Pi OS to install FRR and perform the initial configuration. Using the instructions provided in Configure a Routing Link for BGP Peers , perform the following tasks needed to configure BGP: Assign the router ID to the loopback interface Create and configure VLAN interfaces for \"unnumbered\" routing links Configure a BGP router using your router ID and ASN Use the neighbor directive to establish \"unnumbered\" ethernet peers over each routing link Use the network directive to advertise the full LAN/WAN address range you've been assigned. Save your configuration. Firewall Rules for Edge Routers \u00b6 Information Since we are on a lab network, you can simplify troubleshoting by setting the default forwarding policy to accept . Once you are confident that routing works, change the policy back to drop and troubleshoot your rules. Ensure that outbound traffic from your internal subnets is permitted. 1 For simplicity, you may also open up your firewall to traffic arriving from your routing links. Since our entire class network is assigned to the 172.30.0.0/16 networks you won't need to make any changes to the current NAT configuration. Likewise, you should continue to use connection state to make sure inbound packets (from wlan0) are dropped when they aren't related to established sessions Firewall Rules for ISP routers \u00b6 Information Since we are on a lab network, you can simplify troubleshoting by setting the default forwarding policy to accept . Once you are confident that routing works, change the policy back to drop and troubleshoot your rules. In addition to local traffic, your router is responsible for transit between your partners' networks and the rest of the class. To ensure that you don't interfere with this operation, add a rule to allow forwarded traffic originating from any of the routing links that you've configured. Since our entire class network is assigned to the 172.30.0.0/16 networks you won't need to make any changes to the current NAT configuration. Likewise, you should continue to use connection state to make sure inbound packets (from wlan0) are dropped when they aren't related to established sessions Configure .Pi DNS Resolution (all name servers) \u00b6 We've intentionally set up all of our domains within the non-existent .pi top-level domain and are limiting the resolution of these domains to our class network. By default, our resolvers won't be able to perform queries against other .pi domains since the recursive process depends on relationship between the ICANN root and the top-level domain registries. Our TLD is not present in those data stores, so we need to offer it a little help to resolve .pi domains. The work-around we're employing is to have each of your resolvers maintain a copy of the .pi zone so that it can directly discover the authoritative name servers of your peers' domains. The primary name server for .pi is running at the 10.10.10.10 address (one member of your group will host a copy). By adding the following section to your /etc/bind/named.conf.local, your pi will perform a zone transfer with 10.10.10.10 and then periodically refresh based on the settings specified in the SOA for the top-level domain. zone \"pi\" IN { type secondary; primaries { 10.10.10.10; }; }; This change is discussed in the LAN portion of the guide. \u21a9","title":"Configure BGP Routing and .Pi DNS Resolution"},{"location":"assignments/group-project-connectivity/#configure-bgp-routing-and-pi-dns-resolution","text":"","title":"Configure BGP Routing and .Pi DNS Resolution"},{"location":"assignments/group-project-connectivity/#preparation","text":"Review your final network planning documentation and identify the following details: The ASN value assigned to your LAN. Each group member should have a unique ASN from the range given in PiCANN Routing links and associated VLANs that connect to your Pi: Each edge network router will have one routing link to the ISP router The ISP router will have on routing link per edge network plus an uplink to the class network An address from your public address range that you will use to configure your BGP router's router ID","title":"Preparation"},{"location":"assignments/group-project-connectivity/#configure-routing-links","text":"Follow Getting Started with Free Range Routing (FRR) on Raspberry Pi OS to install FRR and perform the initial configuration. Using the instructions provided in Configure a Routing Link for BGP Peers , perform the following tasks needed to configure BGP: Assign the router ID to the loopback interface Create and configure VLAN interfaces for \"unnumbered\" routing links Configure a BGP router using your router ID and ASN Use the neighbor directive to establish \"unnumbered\" ethernet peers over each routing link Use the network directive to advertise the full LAN/WAN address range you've been assigned. Save your configuration.","title":"Configure Routing Links"},{"location":"assignments/group-project-connectivity/#firewall-rules-for-edge-routers","text":"Information Since we are on a lab network, you can simplify troubleshoting by setting the default forwarding policy to accept . Once you are confident that routing works, change the policy back to drop and troubleshoot your rules. Ensure that outbound traffic from your internal subnets is permitted. 1 For simplicity, you may also open up your firewall to traffic arriving from your routing links. Since our entire class network is assigned to the 172.30.0.0/16 networks you won't need to make any changes to the current NAT configuration. Likewise, you should continue to use connection state to make sure inbound packets (from wlan0) are dropped when they aren't related to established sessions","title":"Firewall Rules for Edge Routers"},{"location":"assignments/group-project-connectivity/#firewall-rules-for-isp-routers","text":"Information Since we are on a lab network, you can simplify troubleshoting by setting the default forwarding policy to accept . Once you are confident that routing works, change the policy back to drop and troubleshoot your rules. In addition to local traffic, your router is responsible for transit between your partners' networks and the rest of the class. To ensure that you don't interfere with this operation, add a rule to allow forwarded traffic originating from any of the routing links that you've configured. Since our entire class network is assigned to the 172.30.0.0/16 networks you won't need to make any changes to the current NAT configuration. Likewise, you should continue to use connection state to make sure inbound packets (from wlan0) are dropped when they aren't related to established sessions","title":"Firewall Rules for ISP routers"},{"location":"assignments/group-project-connectivity/#configure-pi-dns-resolution-all-name-servers","text":"We've intentionally set up all of our domains within the non-existent .pi top-level domain and are limiting the resolution of these domains to our class network. By default, our resolvers won't be able to perform queries against other .pi domains since the recursive process depends on relationship between the ICANN root and the top-level domain registries. Our TLD is not present in those data stores, so we need to offer it a little help to resolve .pi domains. The work-around we're employing is to have each of your resolvers maintain a copy of the .pi zone so that it can directly discover the authoritative name servers of your peers' domains. The primary name server for .pi is running at the 10.10.10.10 address (one member of your group will host a copy). By adding the following section to your /etc/bind/named.conf.local, your pi will perform a zone transfer with 10.10.10.10 and then periodically refresh based on the settings specified in the SOA for the top-level domain. zone \"pi\" IN { type secondary; primaries { 10.10.10.10; }; }; This change is discussed in the LAN portion of the guide. \u21a9","title":"Configure .Pi DNS Resolution (all name servers)"},{"location":"assignments/group-project-dotpi/","text":".Pi Top-Level Domain \u00b6 One member of each group should host a secondary copy of the .pi zone ( https://github.com/i314-campbell-sp19/docker-dotpi ). This server will be available across the network on the 10.10.10.10 Anycast Address. To get started, assign an additional address (`10.10.10.10/32) to your DMZ network interface.[^dmz] Install Docker \u00b6 If you have not already done so, install the Docker service now. The easiest (though not the most secure) method of doing this is to execute the scripted installer from the Docker website: curl -sSL get.docker.com | sh # (1) sudo usermod -aG docker pi # (2) Download and run the docker installer, ensuring that it completes without error. Give the pi user permission to manage Docker. You must exit and log in again before this change will take effect. Build the DotPi Container Image \u00b6 In order to run the dotpi container, you will need to build a new container image based on the Dockerfile in the Github respository. To prepare for this task, clone the docker-dotpi repository and then cd into its location. sudo apt install git # (1) git clone https://github.com/i314-campbell-sp19/docker-mail.git cd docker-mail You will need to install git if this wasn't done in a previous task. From the local repository, you can build the container image by running docker build -t dotpi . . Create an automated task for zone updates \u00b6 The zonefile included in the base container will not be up-to-date, but the latest version of this file can be downloaded from https://gist.githubusercontent.com/clintoncampbell/3df1705652a46c1f400607e5542ab827/raw . To ensure that you are always running with the latest version of the database, you will need to automate a download. Within Linux, cron is responsible for running recurring tasks. We can set up our own tasks within cron by editing the crontab with crontab -e . Follow the steps below to configure a root task that downloads the zone into /etc/dotpi once every 30 minutes: sudo mkdir -p /etc/dotpi/zones sudo crontab -e Insert a new line in the crontab containing */30 * * * * wget -O /etc/dotpi/zones/db.pi https://gist.githubusercontent.com/clintoncampbell/3df1705652a46c1f400607e5542ab827/raw Save and exit Confirm that the file has been downloaded to /etc/dotpi/zones/db.pi Launch the DotPi Container \u00b6 Use Docker to run the container and bind it to port 53 (udp+tcp). The following command will also map the /etc/dotpi/zones directory into the container at /etc/bind/zones so that the named instance running inside the container will pick up the updates retrieved by the cron job on the host. docker run -d --restart always --name dotpi -v /etc/dotpi/zones:/etc/bind/zones -p 10.10.10.10:53:53/udp -p 10.10.10.10:53:53/tcp dotpi Configure BGP to advertise 10.10.10.10 \u00b6 This section assumes that you have previously configured BGP and peered it to at least one other router. In the commands below, substitute _ASN_ for the Autonomous System Number you used when setting up BGP initially. You can review your previous settings by executing show run from the enable prompt of VTY shell. Run the following commands within VTY shell: configure terminal router bgp _ASN_ network 10.10.10.0/24 Note that we are advertising the full /24 for the anycast address. In production systems, prefixes larger than /24 are often filtered from BGP advertisements in order to constrain the size of the Internet routing tables. As such, a full /24 is used as a covering prefix for the Anycast address. Test the DotPi Resolver \u00b6 To confirm that you've installed the resolver correctly, use dig to find the NS record for gradebook.pi by running dig +norecurse @10.10.10.10 NS gradebook.pi . You should also look up the NS records for your team. If you receive an NXDOMAIN response, confirm that you have provided the proper details in the PiCANN registry. If .pi responds with the wrong address, please add a comment to your name server in the PiCANN Google Sheet so that the instructor can update the registry. If you have completed the LAN configuration, you should also be able to obtain the same information from your local Bind9 instance as shown below by running dig +norecurse @127.0.0.1 NS gradebook.pi . The +norecurse option is required to keep bind from reaching out to gradebook.pi's authoritative server, which won't be reachable until you are joined to the rest of the class network. If you have not created this interface yet, create a new dummy interface named dmz0 by following instructions provided in Configuring Dummy Interfaces in systemd-networkd . \u21a9","title":".Pi Top-Level Domain"},{"location":"assignments/group-project-dotpi/#pi-top-level-domain","text":"One member of each group should host a secondary copy of the .pi zone ( https://github.com/i314-campbell-sp19/docker-dotpi ). This server will be available across the network on the 10.10.10.10 Anycast Address. To get started, assign an additional address (`10.10.10.10/32) to your DMZ network interface.[^dmz]","title":".Pi Top-Level Domain"},{"location":"assignments/group-project-dotpi/#install-docker","text":"If you have not already done so, install the Docker service now. The easiest (though not the most secure) method of doing this is to execute the scripted installer from the Docker website: curl -sSL get.docker.com | sh # (1) sudo usermod -aG docker pi # (2) Download and run the docker installer, ensuring that it completes without error. Give the pi user permission to manage Docker. You must exit and log in again before this change will take effect.","title":"Install Docker"},{"location":"assignments/group-project-dotpi/#build-the-dotpi-container-image","text":"In order to run the dotpi container, you will need to build a new container image based on the Dockerfile in the Github respository. To prepare for this task, clone the docker-dotpi repository and then cd into its location. sudo apt install git # (1) git clone https://github.com/i314-campbell-sp19/docker-mail.git cd docker-mail You will need to install git if this wasn't done in a previous task. From the local repository, you can build the container image by running docker build -t dotpi . .","title":"Build the DotPi Container Image"},{"location":"assignments/group-project-dotpi/#create-an-automated-task-for-zone-updates","text":"The zonefile included in the base container will not be up-to-date, but the latest version of this file can be downloaded from https://gist.githubusercontent.com/clintoncampbell/3df1705652a46c1f400607e5542ab827/raw . To ensure that you are always running with the latest version of the database, you will need to automate a download. Within Linux, cron is responsible for running recurring tasks. We can set up our own tasks within cron by editing the crontab with crontab -e . Follow the steps below to configure a root task that downloads the zone into /etc/dotpi once every 30 minutes: sudo mkdir -p /etc/dotpi/zones sudo crontab -e Insert a new line in the crontab containing */30 * * * * wget -O /etc/dotpi/zones/db.pi https://gist.githubusercontent.com/clintoncampbell/3df1705652a46c1f400607e5542ab827/raw Save and exit Confirm that the file has been downloaded to /etc/dotpi/zones/db.pi","title":"Create an automated task for zone updates"},{"location":"assignments/group-project-dotpi/#launch-the-dotpi-container","text":"Use Docker to run the container and bind it to port 53 (udp+tcp). The following command will also map the /etc/dotpi/zones directory into the container at /etc/bind/zones so that the named instance running inside the container will pick up the updates retrieved by the cron job on the host. docker run -d --restart always --name dotpi -v /etc/dotpi/zones:/etc/bind/zones -p 10.10.10.10:53:53/udp -p 10.10.10.10:53:53/tcp dotpi","title":"Launch the DotPi Container"},{"location":"assignments/group-project-dotpi/#configure-bgp-to-advertise-10101010","text":"This section assumes that you have previously configured BGP and peered it to at least one other router. In the commands below, substitute _ASN_ for the Autonomous System Number you used when setting up BGP initially. You can review your previous settings by executing show run from the enable prompt of VTY shell. Run the following commands within VTY shell: configure terminal router bgp _ASN_ network 10.10.10.0/24 Note that we are advertising the full /24 for the anycast address. In production systems, prefixes larger than /24 are often filtered from BGP advertisements in order to constrain the size of the Internet routing tables. As such, a full /24 is used as a covering prefix for the Anycast address.","title":"Configure BGP to advertise 10.10.10.10"},{"location":"assignments/group-project-dotpi/#test-the-dotpi-resolver","text":"To confirm that you've installed the resolver correctly, use dig to find the NS record for gradebook.pi by running dig +norecurse @10.10.10.10 NS gradebook.pi . You should also look up the NS records for your team. If you receive an NXDOMAIN response, confirm that you have provided the proper details in the PiCANN registry. If .pi responds with the wrong address, please add a comment to your name server in the PiCANN Google Sheet so that the instructor can update the registry. If you have completed the LAN configuration, you should also be able to obtain the same information from your local Bind9 instance as shown below by running dig +norecurse @127.0.0.1 NS gradebook.pi . The +norecurse option is required to keep bind from reaching out to gradebook.pi's authoritative server, which won't be reachable until you are joined to the rest of the class network. If you have not created this interface yet, create a new dummy interface named dmz0 by following instructions provided in Configuring Dummy Interfaces in systemd-networkd . \u21a9","title":"Test the DotPi Resolver"},{"location":"assignments/group-project-local-networks/","text":"Final Network - LAN Configuration \u00b6 This page provides requirements to complete the final configuration of your LAN, including all internal address updates, private LAN resources, and firewall rules. \"Re-numbering\" your Ethernet Network \u00b6 While connecting directly to your Pi, reconfigure the routing interface on eth0 and your DHCP configuration based on your new address plan (using the addresses set aside for the untagged subnet). In addition to new address changes, we will make another change from prior checkpoints. Remove the secondary address assignments from eth0 , leaving only the gateway/DHCP address. We will be moving these addresses onto a separate virtual interface. To minimize time spent on troubleshooting, proceed carefully with this task and make sure that you update networkd and dhcpd in a consistent manner. 1 You are also advised to temporarily disable the dhcpd options for routers and domain-name-servers . This precaution will prevent attempts to use the Pi as default gateway and DNS resolver until you have completed your configuration changes and testing. Routing \u00b6 When you are confident in your updates, modify the dhcpd configuration again to provide clients on the LAN with the new default gateway address. Reload the DHCP configuration and force a lease renewal on your connection to proceed with testing. Before you move on, make sure that DHCP works and that your Pi is still able to route internet traffic for your LAN. LAN Configuration for Tagged Subnet \u00b6 Using your LAN's VLAN ID recorded in the VLAN/Switch planning document, create a new VLAN virtual network device associated with eth0 as described in Configuring VLANs in systemd-networkd . Create a .network file for this virtual interface modeled on /etc/systemd/network/20-eth0.network , and set up the gateway IP defined for your trunked network in your final address plan. DHCP \u00b6 Two additional changes will be needed to provide DHCP services on this subnet: Revisit /etc/default/isc-dhcp-server (last modified in Checkpoint #2) and update the list of DHCP interfaces to include the new VLAN interface. 2 Add a second subnet declaration to dhcpd.conf , enabling a dynamic address range and a router option specifying the gateway address for the subnet. nftables \u00b6 In Checkpoint #3, we set up nftables rules to enable NAT on outbound traffic and to allow forwarding from our internal LAN. Now that our internal LAN spans two network interfaces, it's likely that your rules will need some updates to permit traffic from the VLAN interface to be forwarded. To minimize repetition in rulesets, we can rewrite our rules to reference a set of interfaces rather than just one. Likewise, we can generalize our rule so that it allows to send traffic to anywhere from any of our internal networks. These changes are demonstrated in the example below, where a rule is updated to accept incoming packets from any member of the set { eth0, vlan2 } rather than just eth0 . This rule has logical or semantics. It allows traffic flowing from eth0 => * or vlan2 => * . - iifname eth0 oifname wlan0 accept + iifname { eth0, vlan2 } accept As with previous changes to the nftables rules, we recommend against modifying /etc/nftables.conf directly. Instead, copy the current file into your home directory and use the nftables-apply.sh script given in the project resources to test and install your updates. Testing \u00b6 This subnet is designed to accomodate the final network topology, in which your LAN devices connect to a switch port that is natively configured for the correct VLAN while your Pi is communicating over a tagged link. This poses a challenge for testing the configuration without having a correctly configured switch in hand. Please consider the following options if you would like to test your second subnet over a direct connection. VLAN tagging on macOS VLAN tagging on Windows 10/11 Apple provides full support for VLAN tagging. With your Ethernet adapter attached, create a new VLAN interface associated with the adapter based on the instructions in Apple's online help . After applying your changes in System Preferences, select the physical adapter and turn it off by change the setting Configure IPv4 . Windows support for VLAN tagging is inconsistent. With supported adapters, you may be able to set a VLAN ID by editing the advanced settings for your network adapter. To modify these settings, right click on the Start Menu and open Device Manager . Locate the correct network adapter in the device list and look for the VLAN ID option in the device's advanced properties. This option is device dependent. It will not always be present in the options list, and it is not guaranteed to function as expected when it is available. Private LAN Resources \u00b6 In this section, you will update the configuration for the network services available on your LAN, namely DNS resolution and the private domain. Configure IP Addressing \u00b6 To separate the internal service subnet from the subnets used to connect end-users to your network, we are moving the associated IP addresses to a new, virtual network device known as a dummy interface . Dummy interfaces use a loopback mechanism to provide a software-based endpoint that is always available (even when physical connections are offline). This feature is similar to the loopback interface (lo) that provides localhost networking on 127.0.0.1; however, we can still communicate to these dummy interfaces over physical network links. Create and configure a persistent dummy interface on the Pi as described in Configuring Dummy Interfaces in systemd-networkd . Add a .network configuration for this interface with Address= statements for your resolver and private name server addresses. Remember that this statement expects the address and network to be given backslash-delimited, abbreviated CIDR format. Because of the loopback-like behavior that drives dummy interfaces, you can list each address as a /32 network, as shown below: /etc/systemd/network/20-lan0.network [Match] Name = lan0 [Network] Address = 172.30.0.129/32 Address = 172.30.0.130/32 Once you have completed the configuration, reload the systemd-networkd service and verify that the new addresses are online and able to receive traffic. Bind9 \u00b6 Open named.conf.options and edit the subnet and address references to match your final address planning changes. Make sure that your ACL includes all of your assigned address space and that you server is set to listen for connections from your resolver and private name server addresses. Finally, update the authoritative name server's address record within your private zone file. Verify your updates and use rndc to reload the configuration files (as you did previously in Checkpoints #4 and #5). Test the name server from your Pi and from your laptop 3 , before updating DHCP to provide the new resolver address (on both subnets). Override DNS resolution on the Pi \u00b6 By now, you should be aware that when you run a dig query from your Pi, the queries are not being handled by your local Bind9 instance. By default, DNS resolution relies on the name server addresses that were configured by DHCP on the wireless network. To control which resolvers the Pi will use, we need to modify the resolver configuration under systemd-resolved. In this case, we'll use a systemd \"drop-in\" to set a global DNS resolver preference and a search domain. Drop-ins are a systemd configuration pattern that is used to override default behavior. Each service has its own drop-in configuration directory. If the standard location for a service doesn't already exist, administrators can enable the feature by creating the directory and additional .conf files. Run mkdir -p /etc/systemd/resolved.conf.d to create the drop-in configuration directory for the systemd-resolved resolver. Add a new configuration to this location containing the following settings (adapted to your own network). /etc/systemd/resolved.conf.d/override_dns.conf [Resolve] DNS = 172.30.0.129 # resolver address Domains = lan.gradebook.pi # private domain name Restart the systemd-resolved service and verify that the new settings appear in /etc/resolv.conf. You may notice other resolver addresses, but yours should appear first in the list. The file should end with a Search statement pointing to your private domain name. Many of the questions that arise in this process can be answered by reviewing your previous work and the project guides from those Checkpoints. \u21a9 This file's comments includes notes that are pertinent to configuring the list. \u21a9 Make sure you're querying the correct name server. Remember that dig can override the system resolver by providing an @<resolver-address> parameter before your query. The powershell command Resolve-DnsName takes a -server parameter. \u21a9","title":"Final Network - LAN Configuration"},{"location":"assignments/group-project-local-networks/#final-network-lan-configuration","text":"This page provides requirements to complete the final configuration of your LAN, including all internal address updates, private LAN resources, and firewall rules.","title":"Final Network - LAN Configuration"},{"location":"assignments/group-project-local-networks/#re-numbering-your-ethernet-network","text":"While connecting directly to your Pi, reconfigure the routing interface on eth0 and your DHCP configuration based on your new address plan (using the addresses set aside for the untagged subnet). In addition to new address changes, we will make another change from prior checkpoints. Remove the secondary address assignments from eth0 , leaving only the gateway/DHCP address. We will be moving these addresses onto a separate virtual interface. To minimize time spent on troubleshooting, proceed carefully with this task and make sure that you update networkd and dhcpd in a consistent manner. 1 You are also advised to temporarily disable the dhcpd options for routers and domain-name-servers . This precaution will prevent attempts to use the Pi as default gateway and DNS resolver until you have completed your configuration changes and testing.","title":"\"Re-numbering\" your Ethernet Network"},{"location":"assignments/group-project-local-networks/#routing","text":"When you are confident in your updates, modify the dhcpd configuration again to provide clients on the LAN with the new default gateway address. Reload the DHCP configuration and force a lease renewal on your connection to proceed with testing. Before you move on, make sure that DHCP works and that your Pi is still able to route internet traffic for your LAN.","title":"Routing"},{"location":"assignments/group-project-local-networks/#lan-configuration-for-tagged-subnet","text":"Using your LAN's VLAN ID recorded in the VLAN/Switch planning document, create a new VLAN virtual network device associated with eth0 as described in Configuring VLANs in systemd-networkd . Create a .network file for this virtual interface modeled on /etc/systemd/network/20-eth0.network , and set up the gateway IP defined for your trunked network in your final address plan.","title":"LAN Configuration for Tagged Subnet"},{"location":"assignments/group-project-local-networks/#dhcp","text":"Two additional changes will be needed to provide DHCP services on this subnet: Revisit /etc/default/isc-dhcp-server (last modified in Checkpoint #2) and update the list of DHCP interfaces to include the new VLAN interface. 2 Add a second subnet declaration to dhcpd.conf , enabling a dynamic address range and a router option specifying the gateway address for the subnet.","title":"DHCP"},{"location":"assignments/group-project-local-networks/#nftables","text":"In Checkpoint #3, we set up nftables rules to enable NAT on outbound traffic and to allow forwarding from our internal LAN. Now that our internal LAN spans two network interfaces, it's likely that your rules will need some updates to permit traffic from the VLAN interface to be forwarded. To minimize repetition in rulesets, we can rewrite our rules to reference a set of interfaces rather than just one. Likewise, we can generalize our rule so that it allows to send traffic to anywhere from any of our internal networks. These changes are demonstrated in the example below, where a rule is updated to accept incoming packets from any member of the set { eth0, vlan2 } rather than just eth0 . This rule has logical or semantics. It allows traffic flowing from eth0 => * or vlan2 => * . - iifname eth0 oifname wlan0 accept + iifname { eth0, vlan2 } accept As with previous changes to the nftables rules, we recommend against modifying /etc/nftables.conf directly. Instead, copy the current file into your home directory and use the nftables-apply.sh script given in the project resources to test and install your updates.","title":"nftables"},{"location":"assignments/group-project-local-networks/#testing","text":"This subnet is designed to accomodate the final network topology, in which your LAN devices connect to a switch port that is natively configured for the correct VLAN while your Pi is communicating over a tagged link. This poses a challenge for testing the configuration without having a correctly configured switch in hand. Please consider the following options if you would like to test your second subnet over a direct connection. VLAN tagging on macOS VLAN tagging on Windows 10/11 Apple provides full support for VLAN tagging. With your Ethernet adapter attached, create a new VLAN interface associated with the adapter based on the instructions in Apple's online help . After applying your changes in System Preferences, select the physical adapter and turn it off by change the setting Configure IPv4 . Windows support for VLAN tagging is inconsistent. With supported adapters, you may be able to set a VLAN ID by editing the advanced settings for your network adapter. To modify these settings, right click on the Start Menu and open Device Manager . Locate the correct network adapter in the device list and look for the VLAN ID option in the device's advanced properties. This option is device dependent. It will not always be present in the options list, and it is not guaranteed to function as expected when it is available.","title":"Testing"},{"location":"assignments/group-project-local-networks/#private-lan-resources","text":"In this section, you will update the configuration for the network services available on your LAN, namely DNS resolution and the private domain.","title":"Private LAN Resources"},{"location":"assignments/group-project-local-networks/#configure-ip-addressing","text":"To separate the internal service subnet from the subnets used to connect end-users to your network, we are moving the associated IP addresses to a new, virtual network device known as a dummy interface . Dummy interfaces use a loopback mechanism to provide a software-based endpoint that is always available (even when physical connections are offline). This feature is similar to the loopback interface (lo) that provides localhost networking on 127.0.0.1; however, we can still communicate to these dummy interfaces over physical network links. Create and configure a persistent dummy interface on the Pi as described in Configuring Dummy Interfaces in systemd-networkd . Add a .network configuration for this interface with Address= statements for your resolver and private name server addresses. Remember that this statement expects the address and network to be given backslash-delimited, abbreviated CIDR format. Because of the loopback-like behavior that drives dummy interfaces, you can list each address as a /32 network, as shown below: /etc/systemd/network/20-lan0.network [Match] Name = lan0 [Network] Address = 172.30.0.129/32 Address = 172.30.0.130/32 Once you have completed the configuration, reload the systemd-networkd service and verify that the new addresses are online and able to receive traffic.","title":"Configure IP Addressing"},{"location":"assignments/group-project-local-networks/#bind9","text":"Open named.conf.options and edit the subnet and address references to match your final address planning changes. Make sure that your ACL includes all of your assigned address space and that you server is set to listen for connections from your resolver and private name server addresses. Finally, update the authoritative name server's address record within your private zone file. Verify your updates and use rndc to reload the configuration files (as you did previously in Checkpoints #4 and #5). Test the name server from your Pi and from your laptop 3 , before updating DHCP to provide the new resolver address (on both subnets).","title":"Bind9"},{"location":"assignments/group-project-local-networks/#override-dns-resolution-on-the-pi","text":"By now, you should be aware that when you run a dig query from your Pi, the queries are not being handled by your local Bind9 instance. By default, DNS resolution relies on the name server addresses that were configured by DHCP on the wireless network. To control which resolvers the Pi will use, we need to modify the resolver configuration under systemd-resolved. In this case, we'll use a systemd \"drop-in\" to set a global DNS resolver preference and a search domain. Drop-ins are a systemd configuration pattern that is used to override default behavior. Each service has its own drop-in configuration directory. If the standard location for a service doesn't already exist, administrators can enable the feature by creating the directory and additional .conf files. Run mkdir -p /etc/systemd/resolved.conf.d to create the drop-in configuration directory for the systemd-resolved resolver. Add a new configuration to this location containing the following settings (adapted to your own network). /etc/systemd/resolved.conf.d/override_dns.conf [Resolve] DNS = 172.30.0.129 # resolver address Domains = lan.gradebook.pi # private domain name Restart the systemd-resolved service and verify that the new settings appear in /etc/resolv.conf. You may notice other resolver addresses, but yours should appear first in the list. The file should end with a Search statement pointing to your private domain name. Many of the questions that arise in this process can be answered by reviewing your previous work and the project guides from those Checkpoints. \u21a9 This file's comments includes notes that are pertinent to configuring the list. \u21a9 Make sure you're querying the correct name server. Remember that dig can override the system resolver by providing an @<resolver-address> parameter before your query. The powershell command Resolve-DnsName takes a -server parameter. \u21a9","title":"Override DNS resolution on the Pi"},{"location":"assignments/group-project-overview/","text":"Final Project Overview \u00b6 Working in your group, design and implement a networked system that mirrors the concept of an Internet Service Provider (ISP) with customer networks. Your primary objective in this exercise is to adapt what you've completed in previous tasks to meet the requirements specified below. Although you will be working together as a group on this project, each participant will take the lead on configuring their own network device to integrate into the ISP network. Additional configuration guidance and examples will be made available through Slack and Panopto. Before you Begin \u00b6 Each of your group members need to have completed the individual project checkpoints before proceeding with the configuration necessary for the final network. Each Pi should function as a network gateway while also providing DHCP and private DNS services to an Ethernet-based LAN. Specifications \u00b6 Each group member should subnet their designated PiCANN address block into four distinct subnets, designated as follows: Two subnets are needed to provide connectivity for end users connecting to the Pi. One subnet will be configured on the physical eth0 network interface, providing service for users connecting directly to the Pi. A second subnet is needed to support a tagged VLAN interface when attaching the Pi to switches with limited trunking support. 1 Each network will require one static address for the default gateway and DHCP server. Reserve one set of addresses for all other LAN-facing services, i.e., your recursive name server and the authoritative name server for your private DNS domain. A final set of addresses will be reserved for public-facing services. We'll sometimes refer to this subnet as your DMZ . Documentation \u00b6 As you work through each part of this project, carefully document the decisions that you make. The process of planning and recording documentation will help you to avoid mistakes and simplify the troubleshooting process. Likewise, you will be asked to provide a comprehensive view of your network design within your GitHub repository. Detailed documentation requirements are provided within the Canvas assignments. Troubleshooting \u00b6 Look for services that have failed as a result of updates by running systemctl --failed . You may ignore failures in BIND at this stage. Alternatively, use systemctl to disable the service. Using the ip address command, verify that your updated addresses appear on the proper network interfaces. This requirement is needed to support the Unifi Flex Mini switch, which does not support custom switch port configurations. It can be omitted for switch types without this limitation. \u21a9","title":"Final Project Overview"},{"location":"assignments/group-project-overview/#final-project-overview","text":"Working in your group, design and implement a networked system that mirrors the concept of an Internet Service Provider (ISP) with customer networks. Your primary objective in this exercise is to adapt what you've completed in previous tasks to meet the requirements specified below. Although you will be working together as a group on this project, each participant will take the lead on configuring their own network device to integrate into the ISP network. Additional configuration guidance and examples will be made available through Slack and Panopto.","title":"Final Project Overview"},{"location":"assignments/group-project-overview/#before-you-begin","text":"Each of your group members need to have completed the individual project checkpoints before proceeding with the configuration necessary for the final network. Each Pi should function as a network gateway while also providing DHCP and private DNS services to an Ethernet-based LAN.","title":"Before you Begin"},{"location":"assignments/group-project-overview/#specifications","text":"Each group member should subnet their designated PiCANN address block into four distinct subnets, designated as follows: Two subnets are needed to provide connectivity for end users connecting to the Pi. One subnet will be configured on the physical eth0 network interface, providing service for users connecting directly to the Pi. A second subnet is needed to support a tagged VLAN interface when attaching the Pi to switches with limited trunking support. 1 Each network will require one static address for the default gateway and DHCP server. Reserve one set of addresses for all other LAN-facing services, i.e., your recursive name server and the authoritative name server for your private DNS domain. A final set of addresses will be reserved for public-facing services. We'll sometimes refer to this subnet as your DMZ .","title":"Specifications"},{"location":"assignments/group-project-overview/#documentation","text":"As you work through each part of this project, carefully document the decisions that you make. The process of planning and recording documentation will help you to avoid mistakes and simplify the troubleshooting process. Likewise, you will be asked to provide a comprehensive view of your network design within your GitHub repository. Detailed documentation requirements are provided within the Canvas assignments.","title":"Documentation"},{"location":"assignments/group-project-overview/#troubleshooting","text":"Look for services that have failed as a result of updates by running systemctl --failed . You may ignore failures in BIND at this stage. Alternatively, use systemctl to disable the service. Using the ip address command, verify that your updated addresses appear on the proper network interfaces. This requirement is needed to support the Unifi Flex Mini switch, which does not support custom switch port configurations. It can be omitted for switch types without this limitation. \u21a9","title":"Troubleshooting"},{"location":"assignments/group-project-public-services/","text":"Final Network - Public Services \u00b6 IP Configuration \u00b6 Create and configure an additional dummy interface 1 named dmz0 on the Pi. Create a .network configuration for this interface and use it to mange the IP addresses associated with your public-facing network services, which include: the Authoritative name server for your public .pi domain your SMTP mail server (used to send and receive email on your domain) and a webmail server Authoritative DNS \u00b6 Your group should configure one public DNS zone per network based on the work you did in the original DNS planning exercise. Within your zone, you'll host records for each of your public services: NS and A reocrds for your authoritative name server MX and A records for the postfix SMTP mail server A records that will point to a rainloop Webmail server This step should not require very many changes to your Checkpoint #5 configuration. However, you should review named.conf.options and your public zone file to ensure that Bind9 is listening on the authoritative server's address and that and that address records reflect the final version of your address planning documentation. Deploy Dockerized Email \u00b6 Review the instructions at the docker-mail Github repo . You will need to refer back to these instructions to configure a full suite of email services for your public domain. Install Docker \u00b6 The easiest (though not the most secure) method of installing Docker on Raspberry Pi OS is to execute the scripted installer from the Docker website: curl -sSL get.docker.com | sh # (1) sudo usermod -aG docker pi # (2) Download and run the docker installer, ensuring that it completes without error. Give the pi user permission to manage Docker. You must exit and log in again before this change will take effect. Update nftables \u00b6 In general, Docker does a pretty good job managing its own firewall rules on Linux; however, we will need to make an update so that our containers can reach the outside world. Add a new rule to the forward chain of your filter table, granting Docker access to send outbound packets. This change is demonstrated in the following example, where we accept all packets originating from the built-in docker0 network along with the custom docker-mail network that we'll be defining shortly. iifname { eth0, vlan2 } accept +iifname { docker0, docker-mail } accept After loading these rules, you will need to restart the docker service using sudo systemctl restart docker . Build the Containers \u00b6 The docker-mail repository provides a basic mail environment based on postfix (SMTP), dovecot (IMAP), and rainloop (webmail) containers. Clone the repository to the Pi. sudo apt install git git clone https://github.com/i314-campbell-sp19/docker-mail.git Navigate to the sub-directories for each service and build a tagged image. In docker-mail/postfix run docker build -t postfix . In docker-mail/dovecot run docker build -t dovecot . In docker-mail/rainloop run docker build -t rainloop . Create a Custom Container Network \u00b6 To enable internal communication between our containers, we will attach them to a user-defined docker network. The docker-mail network created here is a bridged network that provides the containers with basic services such as IP address configuration, routing, and DNS resolution of container names. docker network create --driver bridge --opt com.docker.network.bridge.name=docker-mail docker-mail If you didn't do it already, update nftables to ensure that outbound traffic from the docker-mail network interface can be forwarded. 2 Launch and Configure the Containers \u00b6 Follow along with the instructions in Github to launch the Postfix, Dovecot, and Rainloop containers. Make sure that you properly configure the correct domain name and SMTP hostname for your domain. Update all three containers to restart automatically when the Pii is rebooted. Send Test Mail \u00b6 Until you completed the routing and .pi TLD configuration with your group, you won't be able to send inter-domain email. For now, verify that you can send an email from pi@ to pi@ . Reach out for assistance if the message does not appear in the inbox after refreshing. We may ask you to run the following commands to assist with debugging: docker ps # (1) docker logs postfix # (2) docker run -it postfix \"postqueue -p\" # (3) Shows all running containers. You should have three. Shows log output from postfix container. Check the mail queue for stuck mail. See Configuring Dummy Interfaces in systemd-networkd \u21a9 Docker must be restarted after reapplying nftables rules. \u21a9","title":"Final Network - Public Services"},{"location":"assignments/group-project-public-services/#final-network-public-services","text":"","title":"Final Network - Public Services"},{"location":"assignments/group-project-public-services/#ip-configuration","text":"Create and configure an additional dummy interface 1 named dmz0 on the Pi. Create a .network configuration for this interface and use it to mange the IP addresses associated with your public-facing network services, which include: the Authoritative name server for your public .pi domain your SMTP mail server (used to send and receive email on your domain) and a webmail server","title":"IP Configuration"},{"location":"assignments/group-project-public-services/#authoritative-dns","text":"Your group should configure one public DNS zone per network based on the work you did in the original DNS planning exercise. Within your zone, you'll host records for each of your public services: NS and A reocrds for your authoritative name server MX and A records for the postfix SMTP mail server A records that will point to a rainloop Webmail server This step should not require very many changes to your Checkpoint #5 configuration. However, you should review named.conf.options and your public zone file to ensure that Bind9 is listening on the authoritative server's address and that and that address records reflect the final version of your address planning documentation.","title":"Authoritative DNS"},{"location":"assignments/group-project-public-services/#deploy-dockerized-email","text":"Review the instructions at the docker-mail Github repo . You will need to refer back to these instructions to configure a full suite of email services for your public domain.","title":"Deploy Dockerized Email"},{"location":"assignments/group-project-public-services/#install-docker","text":"The easiest (though not the most secure) method of installing Docker on Raspberry Pi OS is to execute the scripted installer from the Docker website: curl -sSL get.docker.com | sh # (1) sudo usermod -aG docker pi # (2) Download and run the docker installer, ensuring that it completes without error. Give the pi user permission to manage Docker. You must exit and log in again before this change will take effect.","title":"Install Docker"},{"location":"assignments/group-project-public-services/#update-nftables","text":"In general, Docker does a pretty good job managing its own firewall rules on Linux; however, we will need to make an update so that our containers can reach the outside world. Add a new rule to the forward chain of your filter table, granting Docker access to send outbound packets. This change is demonstrated in the following example, where we accept all packets originating from the built-in docker0 network along with the custom docker-mail network that we'll be defining shortly. iifname { eth0, vlan2 } accept +iifname { docker0, docker-mail } accept After loading these rules, you will need to restart the docker service using sudo systemctl restart docker .","title":"Update nftables"},{"location":"assignments/group-project-public-services/#build-the-containers","text":"The docker-mail repository provides a basic mail environment based on postfix (SMTP), dovecot (IMAP), and rainloop (webmail) containers. Clone the repository to the Pi. sudo apt install git git clone https://github.com/i314-campbell-sp19/docker-mail.git Navigate to the sub-directories for each service and build a tagged image. In docker-mail/postfix run docker build -t postfix . In docker-mail/dovecot run docker build -t dovecot . In docker-mail/rainloop run docker build -t rainloop .","title":"Build the Containers"},{"location":"assignments/group-project-public-services/#create-a-custom-container-network","text":"To enable internal communication between our containers, we will attach them to a user-defined docker network. The docker-mail network created here is a bridged network that provides the containers with basic services such as IP address configuration, routing, and DNS resolution of container names. docker network create --driver bridge --opt com.docker.network.bridge.name=docker-mail docker-mail If you didn't do it already, update nftables to ensure that outbound traffic from the docker-mail network interface can be forwarded. 2","title":"Create a Custom Container Network"},{"location":"assignments/group-project-public-services/#launch-and-configure-the-containers","text":"Follow along with the instructions in Github to launch the Postfix, Dovecot, and Rainloop containers. Make sure that you properly configure the correct domain name and SMTP hostname for your domain. Update all three containers to restart automatically when the Pii is rebooted.","title":"Launch and Configure the Containers"},{"location":"assignments/group-project-public-services/#send-test-mail","text":"Until you completed the routing and .pi TLD configuration with your group, you won't be able to send inter-domain email. For now, verify that you can send an email from pi@ to pi@ . Reach out for assistance if the message does not appear in the inbox after refreshing. We may ask you to run the following commands to assist with debugging: docker ps # (1) docker logs postfix # (2) docker run -it postfix \"postqueue -p\" # (3) Shows all running containers. You should have three. Shows log output from postfix container. Check the mail queue for stuck mail. See Configuring Dummy Interfaces in systemd-networkd \u21a9 Docker must be restarted after reapplying nftables rules. \u21a9","title":"Send Test Mail"},{"location":"assignments/group-project-switch-configuration/","text":"Ubiquiti Switch Management \u00b6 Follow the instructions provided at Installing the UniFi Network Application 1 to install the web-based network controller used to manage the Unifi switches. Create VLANs and Port Profiles \u00b6 Attention The following configuration steps are based on your Switch and VLAN planning documentation. If you're using a Unifi Flex Mini (5-port switch), please ensure that you've adjusted your VLAN plan to avoid assigning any network to VLAN 1. Open the Unifi Network Application and navigate to Settings / Networks. Create one VLAN network for each team member's LAN. Create one VLAN network for each routing link identified in your planning documentation, including the links between your ISP/Edge networks and the upstream link reserved for the class. Create one VLAN network for your upstream connection to the class. Create port profiles associated with each team member's Pi. Set the native VLAN to the team member's LAN and add tagged VLANs to the profile according to which connections are available to that Pi. (For 2 or more switches) Create a port profile for the trunk links between your switches. Apply Port Configurations \u00b6 Unifi Flex Mini (5-port switch) The Unifi Flex Mini does not support custom port profiles. You may set either assign a native VLAN to a port or enable trunking by applying the all profile. Open the switch settings and assign an appropriate profile for each switch port. You may want to disconnect from the switch while doing these steps. When configuring a switch online, each change will take effect immediately, possibly impacting your remaining changes. LAN access ports (connecting to PC/Macs) should be set to the native VLAN for the team member's LAN Router connections (connecting to the Pi's) should be configured to use a custom trunk profile (or the all profile if you are configuring a Flex Mini switch). Trunk connections between switches should be configured to use a custom trunk profile (or the all profile if you are configuring a Flex Mini switch). The upstream connection to the class network should be set to the native VLAN for the upstream connection. Additional Modifications for Unifi Flex Mini \u00b6 The all profile used for trunking on the Flex Mini is hard-coded to use VLAN 1 as a native VLAN. This means that we won't get full separation of the broadcast domains for our routers, since each one will have a connection on VLAN 1. Of particular concern, the switch management interface defaults to VLAN 1 and is configured over DHCP. To resolve this problem, we can implement DHCP guarding on VLAN 1 and update the management network. We recommend that you remain disconnected from the switch before making these changes. Open the Unifi Network app and navigate to Settings / Networks. Locate the default network (this is VLAN 1), and edit the network settings to enable DHCP guarding: Enter an address outside of your assigned network range (e.g., 192.168.0.1) so that the switch will filter out all DHCP traffic on the VLAN. Navigate to Devices and select your switch. Within Settings/Services, change the management VLAN to the VLAN designated for your LAN. Repeat this step once for each switch. Connect the Switches \u00b6 In order to apply the configuration changes to your switch(es), connect your trunk between the switches (if applicable) and attach your Pi and your computer (each on their designated ports). Power on the switches and provide a moment for the configuration process to complete. Once this process completes, your switches should appear online in the devices section of the Unifi controller. See also Installing Unifi Network Application (video) \u21a9","title":"Ubiquiti Switch Management"},{"location":"assignments/group-project-switch-configuration/#ubiquiti-switch-management","text":"Follow the instructions provided at Installing the UniFi Network Application 1 to install the web-based network controller used to manage the Unifi switches.","title":"Ubiquiti Switch Management"},{"location":"assignments/group-project-switch-configuration/#create-vlans-and-port-profiles","text":"Attention The following configuration steps are based on your Switch and VLAN planning documentation. If you're using a Unifi Flex Mini (5-port switch), please ensure that you've adjusted your VLAN plan to avoid assigning any network to VLAN 1. Open the Unifi Network Application and navigate to Settings / Networks. Create one VLAN network for each team member's LAN. Create one VLAN network for each routing link identified in your planning documentation, including the links between your ISP/Edge networks and the upstream link reserved for the class. Create one VLAN network for your upstream connection to the class. Create port profiles associated with each team member's Pi. Set the native VLAN to the team member's LAN and add tagged VLANs to the profile according to which connections are available to that Pi. (For 2 or more switches) Create a port profile for the trunk links between your switches.","title":"Create VLANs and Port Profiles"},{"location":"assignments/group-project-switch-configuration/#apply-port-configurations","text":"Unifi Flex Mini (5-port switch) The Unifi Flex Mini does not support custom port profiles. You may set either assign a native VLAN to a port or enable trunking by applying the all profile. Open the switch settings and assign an appropriate profile for each switch port. You may want to disconnect from the switch while doing these steps. When configuring a switch online, each change will take effect immediately, possibly impacting your remaining changes. LAN access ports (connecting to PC/Macs) should be set to the native VLAN for the team member's LAN Router connections (connecting to the Pi's) should be configured to use a custom trunk profile (or the all profile if you are configuring a Flex Mini switch). Trunk connections between switches should be configured to use a custom trunk profile (or the all profile if you are configuring a Flex Mini switch). The upstream connection to the class network should be set to the native VLAN for the upstream connection.","title":"Apply Port Configurations"},{"location":"assignments/group-project-switch-configuration/#additional-modifications-for-unifi-flex-mini","text":"The all profile used for trunking on the Flex Mini is hard-coded to use VLAN 1 as a native VLAN. This means that we won't get full separation of the broadcast domains for our routers, since each one will have a connection on VLAN 1. Of particular concern, the switch management interface defaults to VLAN 1 and is configured over DHCP. To resolve this problem, we can implement DHCP guarding on VLAN 1 and update the management network. We recommend that you remain disconnected from the switch before making these changes. Open the Unifi Network app and navigate to Settings / Networks. Locate the default network (this is VLAN 1), and edit the network settings to enable DHCP guarding: Enter an address outside of your assigned network range (e.g., 192.168.0.1) so that the switch will filter out all DHCP traffic on the VLAN. Navigate to Devices and select your switch. Within Settings/Services, change the management VLAN to the VLAN designated for your LAN. Repeat this step once for each switch.","title":"Additional Modifications for Unifi Flex Mini"},{"location":"assignments/group-project-switch-configuration/#connect-the-switches","text":"In order to apply the configuration changes to your switch(es), connect your trunk between the switches (if applicable) and attach your Pi and your computer (each on their designated ports). Power on the switches and provide a moment for the configuration process to complete. Once this process completes, your switches should appear online in the devices section of the Unifi controller. See also Installing Unifi Network Application (video) \u21a9","title":"Connect the Switches"},{"location":"assignments/networkd-setup/","text":"Networkd Setup for Raspberry Pi OS (2020-01-22) \u00b6 Intro to Systemd \u00b6 An init provider is the first process that is launched on a Linux system. It is responsible for loading other essential services, and it ultimately becomes the parent of every other process on the system. Among the differences between different Linux distributions is the choice of init system. systemd is the initialization (init) provider most often deployed on recent Linux distributions. On Raspberry Pi OS and other recent Debian-based distros systemd replaces the aging sysvinit . We will interact directly with systemd in this tutorial by issuing systemctl commands to start, stop, enable and disable various system-level services. Beyond its job of launching essential services, systemd provides a modular interface to control many parts of the system. We've already interacted with a few of these components when we used localectl , timedatectl , and hostnamectl during the initial setup of the RaspberryPi. In this tutorial we will leverage three more systemd subsystems: journald - Collects and catalogs log files from system services and applications. You can explore these files with journalctl as seen in Troubleshooting . networkd - Detects and configures network devices and performs various other network management functions. resolved - Provides network name resolution and maintains a list of DNS servers (network-based resolvers) to contact based on settings provided by DHCP or networkd configuration files. Attention: Risk of bricking your Pi A typo or other mistake within the core network configuration can result in total loss of network connectivity, which is required to manage the Pi over ssh. Before you begin to follow these instructions, make an external copy of critical configs such as wpa_supplicant using scp in case it becomes necessary to rebuild. If you get locked out during this process, please contact the instructor to determine whether it's possible to reconnect without re-imaging the Pi. Systemd vs Default Networking \u00b6 By default, Raspberry Pi OS networking relies on a component called dhcpcd to manage interface settings, addresses, etc. While this component works well for general purpose computing, but it is not a match for every scenario. The current version of Debian (the base OS for Raspberry Pi OS) supports systemd based network management via the systemd-networkd service. Unlike dhcpcd , networkd is well-suited to managing the base configuration for our router. Enabling Networkd \u00b6 We will enable networkd in several steps. Try to complete this process in one sitting to avoid \"bricking\" your Pi (at least making it inaccessible over the network). Configure network interfaces \u00b6 To configure the network with networkd , we create files in /etc/systemd/network/ that match named network interfaces and define our desired settings settings. Create the following .network files to handle the default settings for wired and wireless interfaces. Enabling link local addresses is a critical component of these default configurations so that you can still communicate with the Pi when DHCP is not available. Warning Networkd configuration is generally easy to work with, but there are a couple of footguns to be aware of: The files are case sensitive and sometimes sensitive to seemingly innocuous changes in spacing. A file with a missing or invalid [Match] statement will be applied to every interface that hasn't already been matched by an earlier configuration. FAQ: Networkd configuration files man systemd.network provides a comprehensive reference to the format of the networkd configuration files and the process for loading them. At runtime, networkd gathers files using the .network extension from several locations, including /etc/systemd/network/ . To determine the order in which to apply configuration, networkd sorts all of these files lexically. To maintain proper control over execution order, we can prepend a two digit numeric value to the filename. This allows us to set up high-numbered default configurations that are overriden on a case-by-case basis by low-numberd configs files. Default ethernet configuration \u00b6 /etc/systemd/network/99-eth.network [Match] # Applies to eth0, eth1, ... Name = eth* [Network] # Configure IPv4 using DHCP DHCP = ipv4 # Enable link local addresses for IPv4 (169.254.x.y) and IPv6 (FE80::) LinkLocalAddressing = yes Default wireless configuration \u00b6 /etc/systemd/network/99-wlan.network [Match] Name = wlan* [Network] DHCP = ipv4 Disable default networking \u00b6 Tip: Backup configuration before proceeding If you've made any mistakes, you may lose access to your Pi after performing the following steps. Make an offline backup before you proceed by copying files to your local system with scp . # Disable default Raspberry Pi OS networking sudo systemctl mask dhcpcd.service # Disable legacy Debian networking sudo systemctl mask networking.service # Disable resolvconf service, which manages DNS servers for the OS sudo nano /etc/resolvconf.conf # Add the line resolvconf = NO to the beginning of the file Enable systemd network services \u00b6 # Enable systemd-networkd to replace Raspberry Pi OS and Debian networking sudo systemctl enable systemd-networkd # Enable systemd-resolved to replace the resolvconf service sudo systemctl enable systemd-resolved DNS resolvers for Linux are loaded from the /etc/resolv.conf . Rather than manage this directly or through resolvconf , we want to load resolvers dynamically from systemd-resolved . This is as simple as creating a link # Set up a symbolic link from systemd-resolved resolv.conf to the system resolv.conf sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf Update Wireless Service \u00b6 In order for wpa_supplicant to work correctly with networkd , one further change is needed. In our original configuration, we created a system-wide configuration file for wireless. This setup works just fine with the default networking setup, especially since the Pi is only equipped with one wireless interface by default. For networkd to work properly with wpa_supplicant , we need to attach our configuration directly to the wlan0 interface as shown below. # Rename configuration as a per-interface file sudo mv /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant-wlan0.conf # Enable the wpa_supplicant service specifically for wlan0 sudo systemctl enable wpa_supplicant@wlan0 # Disable the system-wide service sudo systemctl disable wpa_supplicant Test Your Configuration \u00b6 Call sudo reboot now to reboot the Pi. Log back in and verify that your Pi is fully operational: Confirm that your wireless interface is online cat /etc/resolv.conf to confirm that it is being populated by systemd-resolved Troubleshooting \u00b6 General Guidance \u00b6 When logging back into your Pi, you may find that some of the functionality is failing. In addition to validating log files and checking that you completed all instructions, log files can provide valuable information for detecting where an error is occurring. We have already mentioned journald earlier in this guide. In order to evaluate logs that are created by journald , we make use of the journalctl command. Read up on the less utility to learn how to efficiently navigate journalctl output. # Show log messages journalctl # Include messages marked secure sudo journalctl # Show messages from last boot journalctl -k -b -1 # Show networkd messages journalctl -u systemd-networkd # Show resolved messages journalctl -u systemd-resolved # Show wpa_supplicant messages journalctl -u wpa_supplicant # Learn more about journald man journalctl Accessing a Bricked Pi \u00b6 If you made a mistake at the wrong point in the previous process, you may not even be able to connect anymore from the network. If this happens, there are several ways to restore access: - Contact instructor for a repair script. Raspberry Pi OS provides a mechanism to run a script during the boot process. You will need access to a microSD reader/writer in order to add the script into the boot folder. - Connect a USB keyboard and HDMI monitor to the Pi in order to debug directly. You will need a micro-HDMI adapter. Most flat-screen TV's can be used as a monitor for this purpose. - Use a serial console cable to access the Pi command line directly. Come to office hours or contact instructor for this option. - Mount the SD card using a Linux virtual machine and repair the broken config files directly. Rebuilding Raspberry Pi OS \u00b6 Alternatively, you may opt to reflash your memory card and repeat initial setup. Contact the instructor before proceeding. If you find yourself in this position, the following recommendations will simplify the process: Copy a fully configured wpa_supplicant.conf to the boot volume of the memory card before the first boot. The boot process will move the file to the proper location in /etc/wpa_supplicant and set its permissions on the first boot. Remove the previous server key hash from .ssh/known_hosts to prevent ssh from complaining about the Pi's new key. macOS/Linux - Run ssh-keygen -R raspberrypi.local Windows - Edit $HOME\\.ssh\\known_hosts and remove the lines that reference raspberrypi.local before you attempt to connect. macOS/Linux - Run ssh-copy-id -i ~/.ssh/id_ed25519 to quickly copy your public keys into authorized_keys . Windows users will have to manually set this file up as shown in previous guides.","title":"networkd Setup"},{"location":"assignments/networkd-setup/#networkd-setup-for-raspberry-pi-os-2020-01-22","text":"","title":"Networkd Setup for Raspberry Pi OS (2020-01-22)"},{"location":"assignments/networkd-setup/#intro-to-systemd","text":"An init provider is the first process that is launched on a Linux system. It is responsible for loading other essential services, and it ultimately becomes the parent of every other process on the system. Among the differences between different Linux distributions is the choice of init system. systemd is the initialization (init) provider most often deployed on recent Linux distributions. On Raspberry Pi OS and other recent Debian-based distros systemd replaces the aging sysvinit . We will interact directly with systemd in this tutorial by issuing systemctl commands to start, stop, enable and disable various system-level services. Beyond its job of launching essential services, systemd provides a modular interface to control many parts of the system. We've already interacted with a few of these components when we used localectl , timedatectl , and hostnamectl during the initial setup of the RaspberryPi. In this tutorial we will leverage three more systemd subsystems: journald - Collects and catalogs log files from system services and applications. You can explore these files with journalctl as seen in Troubleshooting . networkd - Detects and configures network devices and performs various other network management functions. resolved - Provides network name resolution and maintains a list of DNS servers (network-based resolvers) to contact based on settings provided by DHCP or networkd configuration files. Attention: Risk of bricking your Pi A typo or other mistake within the core network configuration can result in total loss of network connectivity, which is required to manage the Pi over ssh. Before you begin to follow these instructions, make an external copy of critical configs such as wpa_supplicant using scp in case it becomes necessary to rebuild. If you get locked out during this process, please contact the instructor to determine whether it's possible to reconnect without re-imaging the Pi.","title":"Intro to Systemd"},{"location":"assignments/networkd-setup/#systemd-vs-default-networking","text":"By default, Raspberry Pi OS networking relies on a component called dhcpcd to manage interface settings, addresses, etc. While this component works well for general purpose computing, but it is not a match for every scenario. The current version of Debian (the base OS for Raspberry Pi OS) supports systemd based network management via the systemd-networkd service. Unlike dhcpcd , networkd is well-suited to managing the base configuration for our router.","title":"Systemd vs Default Networking"},{"location":"assignments/networkd-setup/#enabling-networkd","text":"We will enable networkd in several steps. Try to complete this process in one sitting to avoid \"bricking\" your Pi (at least making it inaccessible over the network).","title":"Enabling Networkd"},{"location":"assignments/networkd-setup/#configure-network-interfaces","text":"To configure the network with networkd , we create files in /etc/systemd/network/ that match named network interfaces and define our desired settings settings. Create the following .network files to handle the default settings for wired and wireless interfaces. Enabling link local addresses is a critical component of these default configurations so that you can still communicate with the Pi when DHCP is not available. Warning Networkd configuration is generally easy to work with, but there are a couple of footguns to be aware of: The files are case sensitive and sometimes sensitive to seemingly innocuous changes in spacing. A file with a missing or invalid [Match] statement will be applied to every interface that hasn't already been matched by an earlier configuration. FAQ: Networkd configuration files man systemd.network provides a comprehensive reference to the format of the networkd configuration files and the process for loading them. At runtime, networkd gathers files using the .network extension from several locations, including /etc/systemd/network/ . To determine the order in which to apply configuration, networkd sorts all of these files lexically. To maintain proper control over execution order, we can prepend a two digit numeric value to the filename. This allows us to set up high-numbered default configurations that are overriden on a case-by-case basis by low-numberd configs files.","title":"Configure network interfaces"},{"location":"assignments/networkd-setup/#default-ethernet-configuration","text":"/etc/systemd/network/99-eth.network [Match] # Applies to eth0, eth1, ... Name = eth* [Network] # Configure IPv4 using DHCP DHCP = ipv4 # Enable link local addresses for IPv4 (169.254.x.y) and IPv6 (FE80::) LinkLocalAddressing = yes","title":"Default ethernet configuration"},{"location":"assignments/networkd-setup/#default-wireless-configuration","text":"/etc/systemd/network/99-wlan.network [Match] Name = wlan* [Network] DHCP = ipv4","title":"Default wireless configuration"},{"location":"assignments/networkd-setup/#disable-default-networking","text":"Tip: Backup configuration before proceeding If you've made any mistakes, you may lose access to your Pi after performing the following steps. Make an offline backup before you proceed by copying files to your local system with scp . # Disable default Raspberry Pi OS networking sudo systemctl mask dhcpcd.service # Disable legacy Debian networking sudo systemctl mask networking.service # Disable resolvconf service, which manages DNS servers for the OS sudo nano /etc/resolvconf.conf # Add the line resolvconf = NO to the beginning of the file","title":"Disable default networking"},{"location":"assignments/networkd-setup/#enable-systemd-network-services","text":"# Enable systemd-networkd to replace Raspberry Pi OS and Debian networking sudo systemctl enable systemd-networkd # Enable systemd-resolved to replace the resolvconf service sudo systemctl enable systemd-resolved DNS resolvers for Linux are loaded from the /etc/resolv.conf . Rather than manage this directly or through resolvconf , we want to load resolvers dynamically from systemd-resolved . This is as simple as creating a link # Set up a symbolic link from systemd-resolved resolv.conf to the system resolv.conf sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf","title":"Enable systemd network services"},{"location":"assignments/networkd-setup/#update-wireless-service","text":"In order for wpa_supplicant to work correctly with networkd , one further change is needed. In our original configuration, we created a system-wide configuration file for wireless. This setup works just fine with the default networking setup, especially since the Pi is only equipped with one wireless interface by default. For networkd to work properly with wpa_supplicant , we need to attach our configuration directly to the wlan0 interface as shown below. # Rename configuration as a per-interface file sudo mv /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant-wlan0.conf # Enable the wpa_supplicant service specifically for wlan0 sudo systemctl enable wpa_supplicant@wlan0 # Disable the system-wide service sudo systemctl disable wpa_supplicant","title":"Update Wireless Service"},{"location":"assignments/networkd-setup/#test-your-configuration","text":"Call sudo reboot now to reboot the Pi. Log back in and verify that your Pi is fully operational: Confirm that your wireless interface is online cat /etc/resolv.conf to confirm that it is being populated by systemd-resolved","title":"Test Your Configuration"},{"location":"assignments/networkd-setup/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"assignments/networkd-setup/#general-guidance","text":"When logging back into your Pi, you may find that some of the functionality is failing. In addition to validating log files and checking that you completed all instructions, log files can provide valuable information for detecting where an error is occurring. We have already mentioned journald earlier in this guide. In order to evaluate logs that are created by journald , we make use of the journalctl command. Read up on the less utility to learn how to efficiently navigate journalctl output. # Show log messages journalctl # Include messages marked secure sudo journalctl # Show messages from last boot journalctl -k -b -1 # Show networkd messages journalctl -u systemd-networkd # Show resolved messages journalctl -u systemd-resolved # Show wpa_supplicant messages journalctl -u wpa_supplicant # Learn more about journald man journalctl","title":"General Guidance"},{"location":"assignments/networkd-setup/#accessing-a-bricked-pi","text":"If you made a mistake at the wrong point in the previous process, you may not even be able to connect anymore from the network. If this happens, there are several ways to restore access: - Contact instructor for a repair script. Raspberry Pi OS provides a mechanism to run a script during the boot process. You will need access to a microSD reader/writer in order to add the script into the boot folder. - Connect a USB keyboard and HDMI monitor to the Pi in order to debug directly. You will need a micro-HDMI adapter. Most flat-screen TV's can be used as a monitor for this purpose. - Use a serial console cable to access the Pi command line directly. Come to office hours or contact instructor for this option. - Mount the SD card using a Linux virtual machine and repair the broken config files directly.","title":"Accessing a Bricked Pi"},{"location":"assignments/networkd-setup/#rebuilding-raspberry-pi-os","text":"Alternatively, you may opt to reflash your memory card and repeat initial setup. Contact the instructor before proceeding. If you find yourself in this position, the following recommendations will simplify the process: Copy a fully configured wpa_supplicant.conf to the boot volume of the memory card before the first boot. The boot process will move the file to the proper location in /etc/wpa_supplicant and set its permissions on the first boot. Remove the previous server key hash from .ssh/known_hosts to prevent ssh from complaining about the Pi's new key. macOS/Linux - Run ssh-keygen -R raspberrypi.local Windows - Edit $HOME\\.ssh\\known_hosts and remove the lines that reference raspberrypi.local before you attempt to connect. macOS/Linux - Run ssh-copy-id -i ~/.ssh/id_ed25519 to quickly copy your public keys into authorized_keys . Windows users will have to manually set this file up as shown in previous guides.","title":"Rebuilding Raspberry Pi OS"},{"location":"assignments/pi-setup/","text":"Raspberry Pi Setup Guide (2022-03-29) \u00b6 Overview \u00b6 This guide will walk you through the steps necessary to install Raspberry Pi OS on your Pi and connect it to Wifi. While we encourage you to search online and use other resources when you encounter questions, it's important that you follow our instructions closely. Though there are many different guides that can help you accomplish the same objectives, this guide has been built based on the needs and requirements of our projects and introduces you to tools you will need throughout the quarter. The core sections of this guide will walk you through the following steps: Install the Raspberry Pi OS on a microSD Enable SSH for headless management Set locale and other base configuration Configure wifi connections Update Raspberry Pi OS and installing additional packages with apt To complete these steps, you will need all of the following items: Computer running a recent desktop OS, such as: macOS 11+, Windows 10+, or a desktop Linux distribution Ethernet network interface (built-in or USB adapter) Media card reader supporting microSD (built-in or USB adapter) Unused 8GB+ microSD card (you may repurpose an existing card, but be aware that all contents will be wiped) Before you start setting up your Pi, please review the tasks in the following section. These steps are particularly important for students running Windows and Linux. Before you start \u00b6 Windows Users \u00b6 Enable the built-in OpenSSH Client \u00b6 All current versions of Windows 10 and 11 ship with an OpenSSH client, though the feature may be disabled by default. Follow the instructions here to enable this feature. Navigate to Settings -> Apps -> Optional features Click on Add an optional feature Enter OpenSSH and select the OpenSSH Client Click next to install Text Editor \u00b6 Among the many subtle differences between Windows and Unix-based machines is a difference in the control characters used to terminate lines in text files. In many cases, this difference will prevent Linux from parsing a file you've written and copied from Windows. To avoid this issue, install a code-oriented text editor that can be configured to use Unix-style line endings and use it exclusively for the labs and projects throughout this course. Visual Studio Code and Atom are common options. To configure VS Code to use Unix-style line endings: Open Settings Search for the term \u201cEol\u201d Change the default end of line character to \\n To configure Atom to use Unix-style line endings: Open Settings Navigate to Packages / Line Ending Selector Change the Default line ending to LF Terminal \u00b6 Except when otherwise noted, I recommend that Windows users complete all Linux networking exercises within Windows PowerShell rather than Git Bash or the Command Prompt. Info For a much improved working experience, you should use the new Windows Terminal application. Terminal is available in the Microsoft Store for Windows 10 users and it is shipped pre-installed with Windows 11. By default, the terminal will run PowerShell, but it also supports Command Prompt and Windows Subsystem for Linux. Linux Users \u00b6 Using your default package manager (likely yum or apt ), confirm that Avahi mDNS services are installed (mDNS is typically part of the default distribution). Install Raspberry Pi OS \u00b6 The Raspberry Pi is a single-board computer built with Linux distributions in mind. The official operating system, which we'll use in our labs is known as Raspberry Pi OS and is based on Debian Linux. If you're familiar with Ubuntu or Arch Linux, you should be mostly at home working in Raspberry Pi OS. Don't worry if Linux is not your jam. We'll provide plenty of guidance so that you can focus your energy on network concepts. Write Raspberry Pi OS to MicroSD \u00b6 Download the Raspberry Pi Imager from https://www.raspberrypi.com/software/ and launch the software Click the button labeled CHOOSE OS Select Raspberry Pi OS (other) and scroll down to find Raspberry Pi OS Lite (64-bit) Insert a microSD card into your card reader and proceed with the install. Unlike the full version of the operating system, Raspberry Pi OS Lite is completely text-based and is well-suited for headless operation. There isn't a graphical desktop environment, but you won't need it. All of projects in this course will be completed in a remote command-line interface (CLI). Update Configuration \u00b6 Etcher will eject the microSD once the image is completely rewritten. We want to edit some files on the SD, so you will need to briefly remove the card before inserting it again. On macOS or Windows, you'll be limited to accessing the boot partition of the card. Use Explorer or Finder to locate and open the partition. You must complete the following step before the first boot. Enable SSH \u00b6 Due to security considerations, the newest versions of Raspian disable SSH by default, but it's easy to turn the feature on so that we can connect to the Pi without requiring a monitor and keyboard. To enable SSH on the first boot, add an empty file named ssh to the boot volume. There are many ways to create this file. If you want to use the command-line, follow the instructions below (macOS and Windows): macOS Windows # Unix-based systems mount external storage to a path in the directory tree. For a freshly written Raspberry Pi OS image, this path will be /Volumes/boot. touch /Volumes/boot/ssh # Windows mounts external storage to a drive letter. Replace E: with the letter assigned on your system. New-Item -type File E:\\ssh Raspberry Pi OS checks for /boot/ssh during startup. When present, the OS enables the OpenSSH daemon and deletes the file. Information Daemon is a computing term used to describe software that runs in the background, e.g., to provide a service for network-based clients. The term is most commonly associated with Unix-flavored operating systems. Initial Boot \u00b6 It's time to boot the Pi for the first time. Close your editor and any windows that are open to the microSD so that you can eject the card gracefully from your OS. Remove the microSD and insert into the card slot on your Pi. Connect power to the designated micro-USB port. Attach to your computer with an Ethernet cable and get ready to launch an SSH connection. From terminal or PowerShell, connect to the Pi for the first time by running the following command: # The default password for pi is raspberry ssh pi@raspberrypi.local This command directs your local SSH client to connect to a network host named raspberrypi.local with the username pi . Since you haven't connected to this device before, SSH should ask you to accept the connection of an unknown device before presenting you with a password prompt. Information Before the SSH client can initiate it's connection to the Pi, it must find the IP address associated with raspberrypi.local . This process is called resolution and will be completed using a protocol known as multicast DNS (mDNS). $ ssh pi@raspberrypi.local The authenticity of host 'raspberrypi.local (fe80::1b9c:bcf2:acd6:bbbe%42)' can't be established. ECDSA key fingerprint is SHA256:QqhpMybvctuIxV03xcnlANU3cxWM1JhvSYxloSd69Rw. Are you sure you want to continue connecting (yes/no)? If you had previously connected to a different host with the name raspberrypi.local , you may also see the warning shown below (please refer to the troubleshooting section to resolve this error): @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! After confirming the prompt shown above, you will see another short message followed by a password prompt. Warning: Permanently added 'raspberrypi.local,fe80::1b9c:bcf2:acd6:bbbe%42' (ECDSA) to the list of known hosts. pi@raspberrypi.local's password: The default password for the pi user is raspberry . Once login is complete, you should be greeted with a message similar to that shown here. Linux raspberrypi 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Linux raspberrypi 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. Wi-Fi is disabled because the country is not set. Use raspi-config to set the country before use. pi@raspberrypi:~ $ Choose a New Password \u00b6 Before proceeding further with setup, you should change the default password by entering the passwd at the command prompt. You will be guided through three prompts to enter the current password and then to update/confirm the new password. Danger SSH is a favorite target of malicious attackers. Nothing makes their lives easier than devices that are configured with the default password for the type of system. Default Configuration \u00b6 Several additional steps are required to prepare your Pi for future projects. While some of these steps may not seem essential, omitting them might pose consequences when trying to troubleshoot problems later in the course. Setting the timezone will ensure that log messages are displayed in local time, which is quite helpful for troubleshooting. # You can see a list of timezones by running `timedatectl list-timezones` sudo timedatectl set-timezone America/Los_Angeles Raspberry Pi OS defaults to a British locale. This can cause issues if we ever need to troubleshoot your device using an external keyboard. Configure the locale and keymap to prevent these issues. # Update /etc/locale.gen with your preferences sudo nano /etc/locale.gen # Find and uncomment the en_US.UTF-8 locale # Re-generate locale information after updating the locale.gen file sudo locale-gen # Apply new settings sudo localectl set-locale \"LANG=en_US.UTF-8\" sudo localectl set-keymap us Occasionally we'll end up running a program that uses the default editor settings for your profile (or root if we have run the program with sudo ). It's helpful to have these configured so that you don't end up stuck in vi or ed without any way to exit. # Update default editor selections for the pi user select-editor # Modify the same setting for commands that require root privileges. sudo select-editor Retain Logs Between Boots \u00b6 In recent versions of Raspberry Pi OS, system logs are collected by the journald service. In the default configuration, logs are not retained between reboots of your Pi. To ensure that logs are available when you need to debug, you can enable log retention by running the following commands. # Create the location for persistent log messages sudo mkdir -p /var/log/journal sudo systemd-tmpfiles --create --prefix /var/log/journal Update Hostname \u00b6 At first boot, we could locate our Pi on the network based on the default hostname of raspberrypi.local . This is fine in an isolated, point-to-point network, but it's a problem when we connect to shared networks. Use the hostnamectl command to set a unique name for your device. # This little pi likes to be called Titan sudo hostnamectl set-hostname titan The main change that hostnamectl makes is visible in /etc/hostname . We also need to update references to the hostname in /etc/hosts . The hosts file is present on most Operating Systems and provides a way of defining hostname/IP address associations without relying on DNS. Linux uses this file to associate your hostname to the loopback IP address. # Confirm your hostname is up to date in /etc/hostname cat /etc/hostname # Replace any references to raspberrypi in /etc/hosts sudo nano /etc/hosts FAQ: Why is sudo slow You might notice odd warnings and sudo latency immediately after changing the hostname. These should clear up once you update the hosts file . For reasons beyond the scope of this curriculum, sudo performs DNS lookups as part of its check to determine whether the current user is permitted to elevate privileges. The delay you experience is the tool waiting for a DNS response prior to its timeout. In order for the hostname changes to take full effect, reboot your pi by calling sudo reboot now . After 20 - 30 seconds your pi will be visible with the new name -- you will need to include the .local suffix on any command referencing the name. Example # ping by mDNS hostname ping titan.local # ssh by mDNS hostname ssh pi@titan.local Enable Passwordless Login \u00b6 We can significantly simplify the process of managing our Pi\u2019s by copying our public SSH keys into the authorized_keys file of the default pi user. To prepare the Raspberry Pi, we need to create a remote directory under the pi user's home directory. If you're still logged into your pi, you can create the directory using mkdir ~/.ssh . After that is done, type exit to terminate the connection and return to your local command prompt. FAQ: Why aren't ssh and scp working Please review the previous set of instructions closely. The commands below are run from your local shell. Running them inside of an existing SSH session will not have the effect you are looking for. With the directory in place, copy your public key (most likely ~/.ssh/id_ed25519.pub ) to the pi using the scp command. scp $HOME/.ssh/id_ed25519.pub pi@raspberrypi.local:.ssh/authorized_keys Info The second set of parameters in this command specifies the user ( pi ) the host ( titan.local ) and the location of the new file ( .ssh/authorized_keys ). Like ssh , scp is a user-based tool and will be executed relative to the home directory of the authenticated user ( /home/pi ). We can override the default by specifying an absolute path beginning with a / , e.g., /home/pi/.ssh/authorized_keys . Connect to Wifi \u00b6 To complete this guide, you will need to establish Internet connectivity for your Pi. Since the Pi 4 has integrated wireless capabilities, we can solve the problem by connecting to local wifi. Set the Wireless Network Locale \u00b6 Wireless networks operate in radio frequency (RF) ranges that are subject to regulation in the geographic region that the network is operated. Before turning on the wireless features of your Raspberry Pi, set the regulatory domain to the United States. There are several ways to modify wireless settings on your Pi. For now, we'll use the wpa_cli command to interactively modify the settings. # Launch wpa_cli interactively wpa_cli -i wlan0 # Enter the following commands at the wpa_cli prompt get country # Returns two letter code for current setting regulatory domain set country US # Returns OK save_config # Returns OK quit Enable the Wireless Interface \u00b6 Recent versions of the operating system use a system feature named rfkill to disable the WiFi radio by default. Before you can connect to any networks, you'll need to remove this block. sudo rfkill unblock wlan Configure the WPA Supplicant \u00b6 Wireless settings for the Pi are controlled by a service called wpa_supplicant , which stores network connection settings inside /etc/wpa_supplicant/wpa_supplicant.conf . You already saw an example of modifying these settings through wpa_cli . For the following task, I recommend that you edit the file directly in a text editor of your choice. Before you make any changes, take a look at the default configuration by running sudo cat /etc/wpa_supplicant/wpa_supplicant.conf (sudo is required since this file is only readable to root). You should see something like this: country=US ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 If you are editing the file on your own computer, paste these lines at the top of the file and add the rest of your changes below them. You will be adding a network definition for each WLAN that you want to use. Detailed configuration instructions are available in WPA Supplicant Configuration Reference . For this project, use the configuration reference to set up the following networks: Eduroam (w/ Certificate Based Authentication) (Optional) UW MPSK Network Requires Device Registration (Optional) Home Network Testing Wireless Connections \u00b6 When you are finished updating wpa_supplicant.conf reconfigure the wireless interface by calling wpa_cli -i wlan0 reconfigure . The command should return OK after a few seconds. Check that you are attached to the wireless network by calling wpa_cli -i wlan0 status . Information You previously ran the wpa_cli tool in interactive mode. The instructions above pass individual commands and return you directly to the Linux command prompt. This method is quick and convenient, but if you run into problems, interactive mode will provide the most information for debugging purposes. Example of a successful connection wpa_cli -i wlan0 status <3>Trying to associate with SSID 'eduroam' <3>Associated with 1c:28:af:07:55:31 <3>CTRL-EVENT-EAP-STARTED EAP authentication started <3>CTRL-EVENT-EAP-STATUS status='started' parameter='' <3>CTRL-EVENT-SUBNET-STATUS-UPDATE status=0 <3>CTRL-EVENT-EAP-PROPOSED-METHOD vendor=0 method=13 <3>CTRL-EVENT-EAP-STATUS status='accept proposed method' parameter='TLS' <3>CTRL-EVENT-EAP-METHOD EAP vendor 0 method 13 (TLS) selected <3>CTRL-EVENT-EAP-PEER-CERT depth=2 subject='/C=US/ST=New Jersey/L=Jersey City/O=The USERTRUST Network/CN=USERTrust RSA Certification Authority' hash=e793c9b02fd8aa13e21c31228accb08119643b749c898964b1746d46c3d4cbd2 <3>CTRL-EVENT-EAP-PEER-CERT depth=2 subject='/C=US/ST=New Jersey/L=Jersey City/O=The USERTRUST Network/CN=USERTrust RSA Certification Authority' cert=308205de308203c6a003020102021001fd6d30fca3ca51a81bbc640e35032d300d06092a864886f70d01010c0500308188310b3009060355040613025553311330110603550408130a4e6577204a6572736579311430120603550407130b4a65727365792043697479311e301c060355040a131554686520555345525452555354204e6574776f726b312e302c06035504031325555345525472757374205253412043657274696669636174696f6e20417574686f72697479301e170d3130303230313030303030305a170d3338303131383233353935395a308188310b3009060355040613025553311330110603550408130a4e6577204a657273657931... <3>CTRL-EVENT-EAP-PEER-ALT depth=0 DNS:radius.uw.edu <3>CTRL-EVENT-EAP-PEER-ALT depth=0 DNS:radius.washington.edu <3>CTRL-EVENT-EAP-STATUS status='remote certificate verification' parameter='success' <3>CTRL-EVENT-EAP-STATUS status='completion' parameter='success' <3>CTRL-EVENT-EAP-SUCCESS EAP authentication completed successfully <3>CTRL-EVENT-CONNECTED - Connection to 1c:28:af:07:55:31 completed [id=0 id_str=] Verify Connection \u00b6 In addition to wpa_cli , there are several tools that can be used to check the current state of your wireless interface and determine whether it has received a valid configuration from DHCP. # Show the current state of the wlan0 interface ip link show wlan0 3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DORMANT group default qlen 1000 link/ether b8:27:eb:db:fe:93 brd ff:ff:ff:ff:ff:ff # Show address configuration for the wlan0 interface ip addr show wlan0 3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether b8:27:eb:db:fe:93 brd ff:ff:ff:ff:ff:ff inet 10.18.185.176/15 brd 10.19.255.255 scope global wlan0 valid_lft forever preferred_lft forever inet6 fe80::ce14:df50:b3f0:9c2a/64 scope link valid_lft forever preferred_lft forever Update Software Packages \u00b6 Let's finalize the initial setup by checking for updates to Raspberry Pi OS and its default packages (this can take a few minutes on slow networks). As a Debian based Linux distribution, Raspberry Pi OS relies on apt for package management. The apt update command is used to determine whether there are new packages to download. sudo apt update sudo apt upgrade sudo apt dist-upgrade # We've found that an additional update is sometimes needed after a dist-upgrade sudo apt update # Install some useful packages while you're at it sudo apt install dnsutils Graceful Shutdown \u00b6 Never yank the power from your Pi when it's time to quit. This can lead to data corruption on the microSD (they aren't as resilient as the drives installed in your laptop). Instead, you should always issue a proper shutdown via SSH. From an SSH connection, run sudo poweroff . If you ever need to reboot the Pi, call sudo reboot now . Wait about 15 - 20 seconds to allow the Pi to complete it\u2019s shutdown process before disconnecting the power. Tips and Troubleshooting \u00b6 Can't find raspberrypi.local \u00b6 If you can't make an initial connection to the Raspberry Pi, verify the following requirements were satisfied: Raspberry Pi OS has been successfully written to microSD card Test again with a known good SD card OpenSSH daemon was enabled before booting the Pi[^ssh_gone] Physical connection is healthy Make sure that both ends of the cable are completely inserted Try an alternate cable, or test the cable with another device Network interface is functional Check for link lights on both network interfaces Verify that your network adapter is visible to the OS Determine whether your network adapter requires drivers Network interface is assigned a link local address Current system configuration supports multicast DNS (mDNS) [^ssh_gone] Raspberry Pi OS will remove the /boot/ssh file after enabling the service. You do not need to restore the file if you find that it has disappeared. Missing Network Drivers \u00b6 If you are using a USB Ethernet port for the first time on your computer, it's possible that your first attempt to connect will be unsuccessful. Some issues are resolved simply by disconnecting the USB briefly and trying to connect again after you have plugged everything back in. If your issues persist, check the manufacturer's support page or search to determine whether your computer needs additional drivers for the specific model of Ethernet adapter. If drivers are necessary, they will usually be available from the manufacturer's website. Link Local Addresses \u00b6 Run ipconfig on Windows or ifconfig on other devices to confirm that the interface registers a network connection. The local IPv4 address for this interface should begin with 169.254.x.x (link-local address range). Most devices will assign this type of address automatically if a DHCP cannot be found. Linux Some versions of Linux, e.g., Ubuntu, require you to choose between link-local addressing and DHCP. Explore your advanced adapter settings for Ethernet to change the adapter settings. Multicast DNS \u00b6 Windows Make sure that you are on a recent build of Windows 10 or Windows 11. Though mDNS is now a draft standard, Microsoft did not include a full client until late 2018. Support for mDNS on earlier versions of Windows relied on the Bonjour Print Services software that was once distributed by Apple in conjunction with iTunes and various other applications. Linux Desktop Linux distributions often support mDNS resolution using the Avahi daemon. Review the requirements at the beginning of this guide . SSH Connection Warning \u00b6 At some point, you are likely to receive the following warning when trying to launch ssh . In most cases, what you are seeing is expected behavior. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! The first time you connect to a host, SSH will bind a cryptographic signature to the hostname, e.g., raspberrypi.local and store it within ~/.ssh/known_hosts . To prevent attacks, SSH warns us when the signature changes for a known host. In our case, it's likely that there is another explanation for the mismatched signature since SSH will create a new private key every time we set up or rebuild a Raspberry Pi. Since this is not an attack scenario, resolve the conflict with ssh-keygen -R raspberrypi.local , which will remove the existing entry. Missing features in Windows SSH The ssh-keygen -R feature isn't present before Windows 10 1809. If you are still running an older version of Windows, you will have to locate known_hosts within the .ssh configuration directory and remove the line indicated by the warning message. Wireless Network is Disabled \u00b6 Check the state of your wireless network interface using the rfkill list . If a soft-block is listed for wlan0 , it's likely that you skipped one or more previous steps. Double-check your wireless locale and use rfkill to enable your interface . Permission Denied Errors \u00b6 When we're performing system and network administration, we are often in need of root privileges. Running an administrative command without the appropriate privileges will result in a permissions-related error. By default, the pi user is restricted in which parts of the system it can read and modify (Linux is heavily user-based in it's permissions model); however, the user is permitted to elevate itself to the admin level with sudo when it is necessary to perform privileged commands. As a general security precaution, don't sudo commands unless it's necessary. For now, we'll indicate when that's the case. In later tasks, you will need to make this determination on your own.","title":"Raspberry Pi Setup"},{"location":"assignments/pi-setup/#raspberry-pi-setup-guide-2022-03-29","text":"","title":"Raspberry Pi Setup Guide (2022-03-29)"},{"location":"assignments/pi-setup/#overview","text":"This guide will walk you through the steps necessary to install Raspberry Pi OS on your Pi and connect it to Wifi. While we encourage you to search online and use other resources when you encounter questions, it's important that you follow our instructions closely. Though there are many different guides that can help you accomplish the same objectives, this guide has been built based on the needs and requirements of our projects and introduces you to tools you will need throughout the quarter. The core sections of this guide will walk you through the following steps: Install the Raspberry Pi OS on a microSD Enable SSH for headless management Set locale and other base configuration Configure wifi connections Update Raspberry Pi OS and installing additional packages with apt To complete these steps, you will need all of the following items: Computer running a recent desktop OS, such as: macOS 11+, Windows 10+, or a desktop Linux distribution Ethernet network interface (built-in or USB adapter) Media card reader supporting microSD (built-in or USB adapter) Unused 8GB+ microSD card (you may repurpose an existing card, but be aware that all contents will be wiped) Before you start setting up your Pi, please review the tasks in the following section. These steps are particularly important for students running Windows and Linux.","title":"Overview"},{"location":"assignments/pi-setup/#before-you-start","text":"","title":"Before you start"},{"location":"assignments/pi-setup/#windows-users","text":"","title":"Windows Users"},{"location":"assignments/pi-setup/#enable-the-built-in-openssh-client","text":"All current versions of Windows 10 and 11 ship with an OpenSSH client, though the feature may be disabled by default. Follow the instructions here to enable this feature. Navigate to Settings -> Apps -> Optional features Click on Add an optional feature Enter OpenSSH and select the OpenSSH Client Click next to install","title":"Enable the built-in OpenSSH Client"},{"location":"assignments/pi-setup/#text-editor","text":"Among the many subtle differences between Windows and Unix-based machines is a difference in the control characters used to terminate lines in text files. In many cases, this difference will prevent Linux from parsing a file you've written and copied from Windows. To avoid this issue, install a code-oriented text editor that can be configured to use Unix-style line endings and use it exclusively for the labs and projects throughout this course. Visual Studio Code and Atom are common options. To configure VS Code to use Unix-style line endings: Open Settings Search for the term \u201cEol\u201d Change the default end of line character to \\n To configure Atom to use Unix-style line endings: Open Settings Navigate to Packages / Line Ending Selector Change the Default line ending to LF","title":"Text Editor"},{"location":"assignments/pi-setup/#terminal","text":"Except when otherwise noted, I recommend that Windows users complete all Linux networking exercises within Windows PowerShell rather than Git Bash or the Command Prompt. Info For a much improved working experience, you should use the new Windows Terminal application. Terminal is available in the Microsoft Store for Windows 10 users and it is shipped pre-installed with Windows 11. By default, the terminal will run PowerShell, but it also supports Command Prompt and Windows Subsystem for Linux.","title":"Terminal"},{"location":"assignments/pi-setup/#linux-users","text":"Using your default package manager (likely yum or apt ), confirm that Avahi mDNS services are installed (mDNS is typically part of the default distribution).","title":"Linux Users"},{"location":"assignments/pi-setup/#install-raspberry-pi-os","text":"The Raspberry Pi is a single-board computer built with Linux distributions in mind. The official operating system, which we'll use in our labs is known as Raspberry Pi OS and is based on Debian Linux. If you're familiar with Ubuntu or Arch Linux, you should be mostly at home working in Raspberry Pi OS. Don't worry if Linux is not your jam. We'll provide plenty of guidance so that you can focus your energy on network concepts.","title":"Install Raspberry Pi OS"},{"location":"assignments/pi-setup/#write-raspberry-pi-os-to-microsd","text":"Download the Raspberry Pi Imager from https://www.raspberrypi.com/software/ and launch the software Click the button labeled CHOOSE OS Select Raspberry Pi OS (other) and scroll down to find Raspberry Pi OS Lite (64-bit) Insert a microSD card into your card reader and proceed with the install. Unlike the full version of the operating system, Raspberry Pi OS Lite is completely text-based and is well-suited for headless operation. There isn't a graphical desktop environment, but you won't need it. All of projects in this course will be completed in a remote command-line interface (CLI).","title":"Write Raspberry Pi OS to MicroSD"},{"location":"assignments/pi-setup/#update-configuration","text":"Etcher will eject the microSD once the image is completely rewritten. We want to edit some files on the SD, so you will need to briefly remove the card before inserting it again. On macOS or Windows, you'll be limited to accessing the boot partition of the card. Use Explorer or Finder to locate and open the partition. You must complete the following step before the first boot.","title":"Update Configuration"},{"location":"assignments/pi-setup/#enable-ssh","text":"Due to security considerations, the newest versions of Raspian disable SSH by default, but it's easy to turn the feature on so that we can connect to the Pi without requiring a monitor and keyboard. To enable SSH on the first boot, add an empty file named ssh to the boot volume. There are many ways to create this file. If you want to use the command-line, follow the instructions below (macOS and Windows): macOS Windows # Unix-based systems mount external storage to a path in the directory tree. For a freshly written Raspberry Pi OS image, this path will be /Volumes/boot. touch /Volumes/boot/ssh # Windows mounts external storage to a drive letter. Replace E: with the letter assigned on your system. New-Item -type File E:\\ssh Raspberry Pi OS checks for /boot/ssh during startup. When present, the OS enables the OpenSSH daemon and deletes the file. Information Daemon is a computing term used to describe software that runs in the background, e.g., to provide a service for network-based clients. The term is most commonly associated with Unix-flavored operating systems.","title":"Enable SSH"},{"location":"assignments/pi-setup/#initial-boot","text":"It's time to boot the Pi for the first time. Close your editor and any windows that are open to the microSD so that you can eject the card gracefully from your OS. Remove the microSD and insert into the card slot on your Pi. Connect power to the designated micro-USB port. Attach to your computer with an Ethernet cable and get ready to launch an SSH connection. From terminal or PowerShell, connect to the Pi for the first time by running the following command: # The default password for pi is raspberry ssh pi@raspberrypi.local This command directs your local SSH client to connect to a network host named raspberrypi.local with the username pi . Since you haven't connected to this device before, SSH should ask you to accept the connection of an unknown device before presenting you with a password prompt. Information Before the SSH client can initiate it's connection to the Pi, it must find the IP address associated with raspberrypi.local . This process is called resolution and will be completed using a protocol known as multicast DNS (mDNS). $ ssh pi@raspberrypi.local The authenticity of host 'raspberrypi.local (fe80::1b9c:bcf2:acd6:bbbe%42)' can't be established. ECDSA key fingerprint is SHA256:QqhpMybvctuIxV03xcnlANU3cxWM1JhvSYxloSd69Rw. Are you sure you want to continue connecting (yes/no)? If you had previously connected to a different host with the name raspberrypi.local , you may also see the warning shown below (please refer to the troubleshooting section to resolve this error): @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! After confirming the prompt shown above, you will see another short message followed by a password prompt. Warning: Permanently added 'raspberrypi.local,fe80::1b9c:bcf2:acd6:bbbe%42' (ECDSA) to the list of known hosts. pi@raspberrypi.local's password: The default password for the pi user is raspberry . Once login is complete, you should be greeted with a message similar to that shown here. Linux raspberrypi 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Linux raspberrypi 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. Wi-Fi is disabled because the country is not set. Use raspi-config to set the country before use. pi@raspberrypi:~ $","title":"Initial Boot"},{"location":"assignments/pi-setup/#choose-a-new-password","text":"Before proceeding further with setup, you should change the default password by entering the passwd at the command prompt. You will be guided through three prompts to enter the current password and then to update/confirm the new password. Danger SSH is a favorite target of malicious attackers. Nothing makes their lives easier than devices that are configured with the default password for the type of system.","title":"Choose a New Password"},{"location":"assignments/pi-setup/#default-configuration","text":"Several additional steps are required to prepare your Pi for future projects. While some of these steps may not seem essential, omitting them might pose consequences when trying to troubleshoot problems later in the course. Setting the timezone will ensure that log messages are displayed in local time, which is quite helpful for troubleshooting. # You can see a list of timezones by running `timedatectl list-timezones` sudo timedatectl set-timezone America/Los_Angeles Raspberry Pi OS defaults to a British locale. This can cause issues if we ever need to troubleshoot your device using an external keyboard. Configure the locale and keymap to prevent these issues. # Update /etc/locale.gen with your preferences sudo nano /etc/locale.gen # Find and uncomment the en_US.UTF-8 locale # Re-generate locale information after updating the locale.gen file sudo locale-gen # Apply new settings sudo localectl set-locale \"LANG=en_US.UTF-8\" sudo localectl set-keymap us Occasionally we'll end up running a program that uses the default editor settings for your profile (or root if we have run the program with sudo ). It's helpful to have these configured so that you don't end up stuck in vi or ed without any way to exit. # Update default editor selections for the pi user select-editor # Modify the same setting for commands that require root privileges. sudo select-editor","title":"Default Configuration"},{"location":"assignments/pi-setup/#retain-logs-between-boots","text":"In recent versions of Raspberry Pi OS, system logs are collected by the journald service. In the default configuration, logs are not retained between reboots of your Pi. To ensure that logs are available when you need to debug, you can enable log retention by running the following commands. # Create the location for persistent log messages sudo mkdir -p /var/log/journal sudo systemd-tmpfiles --create --prefix /var/log/journal","title":"Retain Logs Between Boots"},{"location":"assignments/pi-setup/#update-hostname","text":"At first boot, we could locate our Pi on the network based on the default hostname of raspberrypi.local . This is fine in an isolated, point-to-point network, but it's a problem when we connect to shared networks. Use the hostnamectl command to set a unique name for your device. # This little pi likes to be called Titan sudo hostnamectl set-hostname titan The main change that hostnamectl makes is visible in /etc/hostname . We also need to update references to the hostname in /etc/hosts . The hosts file is present on most Operating Systems and provides a way of defining hostname/IP address associations without relying on DNS. Linux uses this file to associate your hostname to the loopback IP address. # Confirm your hostname is up to date in /etc/hostname cat /etc/hostname # Replace any references to raspberrypi in /etc/hosts sudo nano /etc/hosts FAQ: Why is sudo slow You might notice odd warnings and sudo latency immediately after changing the hostname. These should clear up once you update the hosts file . For reasons beyond the scope of this curriculum, sudo performs DNS lookups as part of its check to determine whether the current user is permitted to elevate privileges. The delay you experience is the tool waiting for a DNS response prior to its timeout. In order for the hostname changes to take full effect, reboot your pi by calling sudo reboot now . After 20 - 30 seconds your pi will be visible with the new name -- you will need to include the .local suffix on any command referencing the name. Example # ping by mDNS hostname ping titan.local # ssh by mDNS hostname ssh pi@titan.local","title":"Update Hostname"},{"location":"assignments/pi-setup/#enable-passwordless-login","text":"We can significantly simplify the process of managing our Pi\u2019s by copying our public SSH keys into the authorized_keys file of the default pi user. To prepare the Raspberry Pi, we need to create a remote directory under the pi user's home directory. If you're still logged into your pi, you can create the directory using mkdir ~/.ssh . After that is done, type exit to terminate the connection and return to your local command prompt. FAQ: Why aren't ssh and scp working Please review the previous set of instructions closely. The commands below are run from your local shell. Running them inside of an existing SSH session will not have the effect you are looking for. With the directory in place, copy your public key (most likely ~/.ssh/id_ed25519.pub ) to the pi using the scp command. scp $HOME/.ssh/id_ed25519.pub pi@raspberrypi.local:.ssh/authorized_keys Info The second set of parameters in this command specifies the user ( pi ) the host ( titan.local ) and the location of the new file ( .ssh/authorized_keys ). Like ssh , scp is a user-based tool and will be executed relative to the home directory of the authenticated user ( /home/pi ). We can override the default by specifying an absolute path beginning with a / , e.g., /home/pi/.ssh/authorized_keys .","title":"Enable Passwordless Login"},{"location":"assignments/pi-setup/#connect-to-wifi","text":"To complete this guide, you will need to establish Internet connectivity for your Pi. Since the Pi 4 has integrated wireless capabilities, we can solve the problem by connecting to local wifi.","title":"Connect to Wifi"},{"location":"assignments/pi-setup/#set-the-wireless-network-locale","text":"Wireless networks operate in radio frequency (RF) ranges that are subject to regulation in the geographic region that the network is operated. Before turning on the wireless features of your Raspberry Pi, set the regulatory domain to the United States. There are several ways to modify wireless settings on your Pi. For now, we'll use the wpa_cli command to interactively modify the settings. # Launch wpa_cli interactively wpa_cli -i wlan0 # Enter the following commands at the wpa_cli prompt get country # Returns two letter code for current setting regulatory domain set country US # Returns OK save_config # Returns OK quit","title":"Set the Wireless Network Locale"},{"location":"assignments/pi-setup/#enable-the-wireless-interface","text":"Recent versions of the operating system use a system feature named rfkill to disable the WiFi radio by default. Before you can connect to any networks, you'll need to remove this block. sudo rfkill unblock wlan","title":"Enable the Wireless Interface"},{"location":"assignments/pi-setup/#configure-the-wpa-supplicant","text":"Wireless settings for the Pi are controlled by a service called wpa_supplicant , which stores network connection settings inside /etc/wpa_supplicant/wpa_supplicant.conf . You already saw an example of modifying these settings through wpa_cli . For the following task, I recommend that you edit the file directly in a text editor of your choice. Before you make any changes, take a look at the default configuration by running sudo cat /etc/wpa_supplicant/wpa_supplicant.conf (sudo is required since this file is only readable to root). You should see something like this: country=US ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 If you are editing the file on your own computer, paste these lines at the top of the file and add the rest of your changes below them. You will be adding a network definition for each WLAN that you want to use. Detailed configuration instructions are available in WPA Supplicant Configuration Reference . For this project, use the configuration reference to set up the following networks: Eduroam (w/ Certificate Based Authentication) (Optional) UW MPSK Network Requires Device Registration (Optional) Home Network","title":"Configure the WPA Supplicant"},{"location":"assignments/pi-setup/#testing-wireless-connections","text":"When you are finished updating wpa_supplicant.conf reconfigure the wireless interface by calling wpa_cli -i wlan0 reconfigure . The command should return OK after a few seconds. Check that you are attached to the wireless network by calling wpa_cli -i wlan0 status . Information You previously ran the wpa_cli tool in interactive mode. The instructions above pass individual commands and return you directly to the Linux command prompt. This method is quick and convenient, but if you run into problems, interactive mode will provide the most information for debugging purposes. Example of a successful connection wpa_cli -i wlan0 status <3>Trying to associate with SSID 'eduroam' <3>Associated with 1c:28:af:07:55:31 <3>CTRL-EVENT-EAP-STARTED EAP authentication started <3>CTRL-EVENT-EAP-STATUS status='started' parameter='' <3>CTRL-EVENT-SUBNET-STATUS-UPDATE status=0 <3>CTRL-EVENT-EAP-PROPOSED-METHOD vendor=0 method=13 <3>CTRL-EVENT-EAP-STATUS status='accept proposed method' parameter='TLS' <3>CTRL-EVENT-EAP-METHOD EAP vendor 0 method 13 (TLS) selected <3>CTRL-EVENT-EAP-PEER-CERT depth=2 subject='/C=US/ST=New Jersey/L=Jersey City/O=The USERTRUST Network/CN=USERTrust RSA Certification Authority' hash=e793c9b02fd8aa13e21c31228accb08119643b749c898964b1746d46c3d4cbd2 <3>CTRL-EVENT-EAP-PEER-CERT depth=2 subject='/C=US/ST=New Jersey/L=Jersey City/O=The USERTRUST Network/CN=USERTrust RSA Certification Authority' cert=308205de308203c6a003020102021001fd6d30fca3ca51a81bbc640e35032d300d06092a864886f70d01010c0500308188310b3009060355040613025553311330110603550408130a4e6577204a6572736579311430120603550407130b4a65727365792043697479311e301c060355040a131554686520555345525452555354204e6574776f726b312e302c06035504031325555345525472757374205253412043657274696669636174696f6e20417574686f72697479301e170d3130303230313030303030305a170d3338303131383233353935395a308188310b3009060355040613025553311330110603550408130a4e6577204a657273657931... <3>CTRL-EVENT-EAP-PEER-ALT depth=0 DNS:radius.uw.edu <3>CTRL-EVENT-EAP-PEER-ALT depth=0 DNS:radius.washington.edu <3>CTRL-EVENT-EAP-STATUS status='remote certificate verification' parameter='success' <3>CTRL-EVENT-EAP-STATUS status='completion' parameter='success' <3>CTRL-EVENT-EAP-SUCCESS EAP authentication completed successfully <3>CTRL-EVENT-CONNECTED - Connection to 1c:28:af:07:55:31 completed [id=0 id_str=]","title":"Testing Wireless Connections"},{"location":"assignments/pi-setup/#verify-connection","text":"In addition to wpa_cli , there are several tools that can be used to check the current state of your wireless interface and determine whether it has received a valid configuration from DHCP. # Show the current state of the wlan0 interface ip link show wlan0 3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DORMANT group default qlen 1000 link/ether b8:27:eb:db:fe:93 brd ff:ff:ff:ff:ff:ff # Show address configuration for the wlan0 interface ip addr show wlan0 3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether b8:27:eb:db:fe:93 brd ff:ff:ff:ff:ff:ff inet 10.18.185.176/15 brd 10.19.255.255 scope global wlan0 valid_lft forever preferred_lft forever inet6 fe80::ce14:df50:b3f0:9c2a/64 scope link valid_lft forever preferred_lft forever","title":"Verify Connection"},{"location":"assignments/pi-setup/#update-software-packages","text":"Let's finalize the initial setup by checking for updates to Raspberry Pi OS and its default packages (this can take a few minutes on slow networks). As a Debian based Linux distribution, Raspberry Pi OS relies on apt for package management. The apt update command is used to determine whether there are new packages to download. sudo apt update sudo apt upgrade sudo apt dist-upgrade # We've found that an additional update is sometimes needed after a dist-upgrade sudo apt update # Install some useful packages while you're at it sudo apt install dnsutils","title":"Update Software Packages"},{"location":"assignments/pi-setup/#graceful-shutdown","text":"Never yank the power from your Pi when it's time to quit. This can lead to data corruption on the microSD (they aren't as resilient as the drives installed in your laptop). Instead, you should always issue a proper shutdown via SSH. From an SSH connection, run sudo poweroff . If you ever need to reboot the Pi, call sudo reboot now . Wait about 15 - 20 seconds to allow the Pi to complete it\u2019s shutdown process before disconnecting the power.","title":"Graceful Shutdown"},{"location":"assignments/pi-setup/#tips-and-troubleshooting","text":"","title":"Tips and Troubleshooting"},{"location":"assignments/pi-setup/#cant-find-raspberrypilocal","text":"If you can't make an initial connection to the Raspberry Pi, verify the following requirements were satisfied: Raspberry Pi OS has been successfully written to microSD card Test again with a known good SD card OpenSSH daemon was enabled before booting the Pi[^ssh_gone] Physical connection is healthy Make sure that both ends of the cable are completely inserted Try an alternate cable, or test the cable with another device Network interface is functional Check for link lights on both network interfaces Verify that your network adapter is visible to the OS Determine whether your network adapter requires drivers Network interface is assigned a link local address Current system configuration supports multicast DNS (mDNS) [^ssh_gone] Raspberry Pi OS will remove the /boot/ssh file after enabling the service. You do not need to restore the file if you find that it has disappeared.","title":"Can't find raspberrypi.local"},{"location":"assignments/pi-setup/#missing-network-drivers","text":"If you are using a USB Ethernet port for the first time on your computer, it's possible that your first attempt to connect will be unsuccessful. Some issues are resolved simply by disconnecting the USB briefly and trying to connect again after you have plugged everything back in. If your issues persist, check the manufacturer's support page or search to determine whether your computer needs additional drivers for the specific model of Ethernet adapter. If drivers are necessary, they will usually be available from the manufacturer's website.","title":"Missing Network Drivers"},{"location":"assignments/pi-setup/#link-local-addresses","text":"Run ipconfig on Windows or ifconfig on other devices to confirm that the interface registers a network connection. The local IPv4 address for this interface should begin with 169.254.x.x (link-local address range). Most devices will assign this type of address automatically if a DHCP cannot be found. Linux Some versions of Linux, e.g., Ubuntu, require you to choose between link-local addressing and DHCP. Explore your advanced adapter settings for Ethernet to change the adapter settings.","title":"Link Local Addresses"},{"location":"assignments/pi-setup/#multicast-dns","text":"Windows Make sure that you are on a recent build of Windows 10 or Windows 11. Though mDNS is now a draft standard, Microsoft did not include a full client until late 2018. Support for mDNS on earlier versions of Windows relied on the Bonjour Print Services software that was once distributed by Apple in conjunction with iTunes and various other applications. Linux Desktop Linux distributions often support mDNS resolution using the Avahi daemon. Review the requirements at the beginning of this guide .","title":"Multicast DNS"},{"location":"assignments/pi-setup/#ssh-connection-warning","text":"At some point, you are likely to receive the following warning when trying to launch ssh . In most cases, what you are seeing is expected behavior. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! The first time you connect to a host, SSH will bind a cryptographic signature to the hostname, e.g., raspberrypi.local and store it within ~/.ssh/known_hosts . To prevent attacks, SSH warns us when the signature changes for a known host. In our case, it's likely that there is another explanation for the mismatched signature since SSH will create a new private key every time we set up or rebuild a Raspberry Pi. Since this is not an attack scenario, resolve the conflict with ssh-keygen -R raspberrypi.local , which will remove the existing entry. Missing features in Windows SSH The ssh-keygen -R feature isn't present before Windows 10 1809. If you are still running an older version of Windows, you will have to locate known_hosts within the .ssh configuration directory and remove the line indicated by the warning message.","title":"SSH Connection Warning"},{"location":"assignments/pi-setup/#wireless-network-is-disabled","text":"Check the state of your wireless network interface using the rfkill list . If a soft-block is listed for wlan0 , it's likely that you skipped one or more previous steps. Double-check your wireless locale and use rfkill to enable your interface .","title":"Wireless Network is Disabled"},{"location":"assignments/pi-setup/#permission-denied-errors","text":"When we're performing system and network administration, we are often in need of root privileges. Running an administrative command without the appropriate privileges will result in a permissions-related error. By default, the pi user is restricted in which parts of the system it can read and modify (Linux is heavily user-based in it's permissions model); however, the user is permitted to elevate itself to the admin level with sudo when it is necessary to perform privileged commands. As a general security precaution, don't sudo commands unless it's necessary. For now, we'll indicate when that's the case. In later tasks, you will need to make this determination on your own.","title":"Permission Denied Errors"},{"location":"assignments/proxy-labs/","text":"HTTP Proxy Labs \u00b6 What is a proxy? \u00b6 A proxy is a network service that receives a connection and reads data from a client, acts on it, and passes that data out to another server. The proxy will also read the server's response, act on it, and send it back to the client. This simple pattern appears frequently in networks and distributed systems and quite frequently provide The value provided by a proxy is determined by the actions it takes on the data. Here are a few applications of HTTP proxies: security (e.g., inspecting HTTP content for malware) policy enforcement (e.g., preventing employees from accessing unauthorized content at work) software development (e.g., decrypting and examining HTTPS traffic) For this sequence of assignments, we are building a proxy to log metadata about HTTP requests and responses. Project Overview \u00b6 This sequence of labs is divided into 3 parts. Create a simple TCP server that is able to parse incoming HTTP/1.0 GET requests and generate a log of requests that have been received. Extend your server so that it can parse the remaining HTTP/1.0 message types and build a new HTTP message from the fields it received. Background Material \u00b6 Application Layer Messages \u00b6 Data structure \u00b6 Application protocols follow predictable patterns to marshall more complex data into byte-oriented message structures. The following patterns are commonly used for marshalling/unmarshalling data and will be discussed briefly in lab: Delimiters Type/Length/Value Fixed length fields Text encoding \u00b6 In addition to the higher-level concern of marshalling the data structures into a stream of bytes, network applications must also define the manner in which they encode/decode between characters and byte representation. There are many different ways to encode a set of characters into bytes. These are generally grouped into single and multi-byte encodings based on the number of bytes that are required to encode each character. The most prominent single-byte encodings are ASCII and ISO-8859-1, which use 7-bits and 8-bits per character respectively. These encodings are simple to work with, but they are quite limited in the size of alphabet that they can support. The advantage of multi-byte encodings, such as those defined by the Unicode standard, is the ability to represent different languages, alphabets, and sets of symbols within the application. One of the most common encodings in modern applications is UTF-8, a variable-length encoding that provides backwards compatibility with ASCII while also supporting multi-byte encodings required for broad Unicode compatibility. For the bulk of our work on developing an HTTP proxy, we will utilize the ISO-8859-1 and ASCII encodings (per the RFCs that define the protocol). Control Characters \u00b6 As users, we're generally most concerned with the visible letters of the alphabet -- or cute symbols such as \ud83d\udca9(represented as F0 9F 92 A9 in UTF-8). As developers, we often need to pay attention to the non-printable character codes. For the sake of parsing the HTTP protocol, we will concern ourselves with various types of white space, including the CRLF (0D 0A in ASCII, ISO-8859-1, and UTF-8) sequence that is used to signify the end of a line in HTTP messages. HTTP Message Structure \u00b6 HTTP messages may be formatted as ASCII (per RFC 7230) or ISO-8859-1 (per historic RFCs). Decoding text as iso-8859-1 will allow for the maximum versatility. RFC 7230 defines the structures used to represent HTTP/1.1 requests and responses https://tools.ietf.org/html/rfc7230#section-3 . HTTP-message = start-line *( header-field CRLF ) CRLF [ message-body ] Requests \u00b6 request-line - method, URI, and protocol version [header]* empty line [message body] Responses \u00b6 status-line: protocol version, a success or error code, and textual reason phrase [header]* empty line [message body]","title":"HTTP Proxy Labs"},{"location":"assignments/proxy-labs/#http-proxy-labs","text":"","title":"HTTP Proxy Labs"},{"location":"assignments/proxy-labs/#what-is-a-proxy","text":"A proxy is a network service that receives a connection and reads data from a client, acts on it, and passes that data out to another server. The proxy will also read the server's response, act on it, and send it back to the client. This simple pattern appears frequently in networks and distributed systems and quite frequently provide The value provided by a proxy is determined by the actions it takes on the data. Here are a few applications of HTTP proxies: security (e.g., inspecting HTTP content for malware) policy enforcement (e.g., preventing employees from accessing unauthorized content at work) software development (e.g., decrypting and examining HTTPS traffic) For this sequence of assignments, we are building a proxy to log metadata about HTTP requests and responses.","title":"What is a proxy?"},{"location":"assignments/proxy-labs/#project-overview","text":"This sequence of labs is divided into 3 parts. Create a simple TCP server that is able to parse incoming HTTP/1.0 GET requests and generate a log of requests that have been received. Extend your server so that it can parse the remaining HTTP/1.0 message types and build a new HTTP message from the fields it received.","title":"Project Overview"},{"location":"assignments/proxy-labs/#background-material","text":"","title":"Background Material"},{"location":"assignments/proxy-labs/#application-layer-messages","text":"","title":"Application Layer Messages"},{"location":"assignments/proxy-labs/#data-structure","text":"Application protocols follow predictable patterns to marshall more complex data into byte-oriented message structures. The following patterns are commonly used for marshalling/unmarshalling data and will be discussed briefly in lab: Delimiters Type/Length/Value Fixed length fields","title":"Data structure"},{"location":"assignments/proxy-labs/#text-encoding","text":"In addition to the higher-level concern of marshalling the data structures into a stream of bytes, network applications must also define the manner in which they encode/decode between characters and byte representation. There are many different ways to encode a set of characters into bytes. These are generally grouped into single and multi-byte encodings based on the number of bytes that are required to encode each character. The most prominent single-byte encodings are ASCII and ISO-8859-1, which use 7-bits and 8-bits per character respectively. These encodings are simple to work with, but they are quite limited in the size of alphabet that they can support. The advantage of multi-byte encodings, such as those defined by the Unicode standard, is the ability to represent different languages, alphabets, and sets of symbols within the application. One of the most common encodings in modern applications is UTF-8, a variable-length encoding that provides backwards compatibility with ASCII while also supporting multi-byte encodings required for broad Unicode compatibility. For the bulk of our work on developing an HTTP proxy, we will utilize the ISO-8859-1 and ASCII encodings (per the RFCs that define the protocol).","title":"Text encoding"},{"location":"assignments/proxy-labs/#control-characters","text":"As users, we're generally most concerned with the visible letters of the alphabet -- or cute symbols such as \ud83d\udca9(represented as F0 9F 92 A9 in UTF-8). As developers, we often need to pay attention to the non-printable character codes. For the sake of parsing the HTTP protocol, we will concern ourselves with various types of white space, including the CRLF (0D 0A in ASCII, ISO-8859-1, and UTF-8) sequence that is used to signify the end of a line in HTTP messages.","title":"Control Characters"},{"location":"assignments/proxy-labs/#http-message-structure","text":"HTTP messages may be formatted as ASCII (per RFC 7230) or ISO-8859-1 (per historic RFCs). Decoding text as iso-8859-1 will allow for the maximum versatility. RFC 7230 defines the structures used to represent HTTP/1.1 requests and responses https://tools.ietf.org/html/rfc7230#section-3 . HTTP-message = start-line *( header-field CRLF ) CRLF [ message-body ]","title":"HTTP Message Structure"},{"location":"assignments/proxy-labs/#requests","text":"request-line - method, URI, and protocol version [header]* empty line [message body]","title":"Requests"},{"location":"assignments/proxy-labs/#responses","text":"status-line: protocol version, a success or error code, and textual reason phrase [header]* empty line [message body]","title":"Responses"},{"location":"assignments/resolver-setup/","text":"Configure a Recursive DNS Resolver (last edited 2022-04-27) \u00b6 Overview \u00b6 In this assignment, we'll continue to extend the functionality of the Linux-based router by installing and configuring the open source BIND server to resolve DNS requests on behalf of hosts on your LAN. This new functionality will take the place of the public DNS resolvers we used in the previous assignments (e.g., 1.1.1.1 or 8.8.8.8 ). Important With each checkpoint, we expect you to do more of the work on your own. While the initial Pi setup gave clear instructions, we are slowly moving toward giving you specifications and additional context that you need in order to determine the right steps to accomplish the task. In this assignment, you'll be pointed toward external sources that you can reference in order to implement the project specifications. This can be a challenging adjustment, but it is also a valuable skill to learn and practice as you prepare for technical internships and jobs. Before you start \u00b6 Before you begin, make sure that you have completed all steps through Checkpoint #3 successfully. At this point, your Pi should be able to route traffic between the Ethernet LAN and a public-facing Wireless network. Likewise, DHCP should provide LAN clients with a full network configuration, including a default gateway and a public DNS resolver. As with the previous checkpoint, you will rely on parameters you determined in your LAN Planning Exercise to complete this project. Instructions \u00b6 Review your Address Plan \u00b6 Running the DNS resolver privately will require an IP address from your network range available on the Pi. While many home router configurations will use a single address for DHCP, routing, and DNS resolution, the specifications for this project require you to use a separate IP address that you selected when creating your initial address plan. Review that plan now. Configure the Resolver's IP Address \u00b6 Before you configure a new service with an address, you need to set up the address at the device level. Add your resolver's address to the static configuration for eth0 . In a networkd configuration, you can add additional addresses by putting each address (in abbreviated CIDR format) on a separate Address= line within your existing .network file. In order to do this, you may want to review the original setup given in Checkpoint #2 . Install BIND on the router \u00b6 The Berkeley Internet Name Daemon (BIND) is a robust and versatile DNS implementation distributed by the Internet Services Consortium (ISC) -- the same folks responsible for the DHCP server implementation we have deployed. The first version of BIND was released in 1986. At present, BIND 9 is the most widely deployed DNS server on the Internet. BIND and related utilities are packaged in the Debian and Raspberry Pi OS software repositories, meaning that they can be installed and managed easily with the apt utilities that we are already familiar with. For our purposes, you should install the following packages: bind9 , bind9utils , bind9-doc . Configure BIND as a Recursive Name Server (i.e., a Resolver) \u00b6 Name servers or DNS servers come in multiple flavors that are differentiated based on the queries they're configured to answer. 1 Some servers are responsible for a single tier or branch of the DNS hierarchy, e.g., names within the tcpip.dev domain, while other servers offer the ability to answer queries about any domain. BIND can be configured to operate in all of these roles, but in this checkpoint, we're focused on the latter objective. Until now, devices in your network relied on public servers to resolve recursive DNS queries , but you can configure BIND to act as the resolver for clients connecting from your LAN. The requirements for this task are described below, but you will likely need other resources in order to implement these specifications. There are a variety of tutorials available online, but Digital Ocean's community tutorial for Ubuntu Linux is more consistent than most with respect to project requirements. This guide does a good job explaining the organization of the configuration files you'll encounter and the syntax used when adding directives like acl or allow-query . Pay special attention to the caching DNS server section of this guide. The forwarding DNS server instructions are not relevant to this project. Requirements \u00b6 Use the acl directive to create an access control list (ACL) that restricts access to BIND to devices on your LAN (your subnet range in the CIDR format) in addition to the Pi itself (using the localhost keyword). If you're curious to learn more about this security precaution, read up on Cache Poisoning and DNS Amplification or hit us up in office hours. Enable recursion and use the allow-query directive to grant access through your access control list Limit which IPv4 addresses on the Pi will be listening for DNS queries by configuring a listen-on block with the following local addresses: 2 127.0.0.1 is the loopback address, allowing the Pi to use BIND to answer its own queries. The static IP configured earlier for the DNS resolver. Disable IPv6 by changing listen-on-v6 { any; }; to listen-on-v6 { none; }; . Disable DNSSEC functionality by replacing the configuration line that reads dnssec-validation from auto to no . Disabling DNSSEC is necessary due to the limitations of using a Pi versus an always on network server. Specifically, the inability of the Pi to maintain accurate time when it is powered off interferes with the verification process for DNSSEC cryptographic signatures Test and verify that the new server is operating properly \u00b6 In addition to the troubleshooting tools that we're already familiar with. BIND comes with a utility called named-checkconf that will review its core configuration files for syntax errors. It's important to run this tool each time you modify the BIND configuration in this assignment or future checkpoints. If it doesn't find any syntax errors in your configuration files, named-checkconf will return without displaying any messages. Once your files are free of errors, use systemctl to restart the bind9 service and check that it's working with dig , e.g., dig @127.0.0.1 washington.edu . As we've discussed in other places, the @IP syntax of dig is used to override local resolver settings (which are still determined by DHCP on the wireless network). Update your DHCP Server Configuration \u00b6 To wrap up this project, you need to update the DHCP server configuration so that LAN users will receive the address for the local resolver instead of the public resolver we previously used: Update DHCP server configuration so that devices configured by DHCP will use the Pi's DNS resolver rather than the public server you configured in Checkpoint #3. Use systemctl to restart the DHCP server daemon. Manually renew your DHCP configuration on your PC through the OS or by temporarily disconnecting the network cable. Verify that your computer receives the updated parameters from DHCP. See A Comparison of DNS Server Types \u21a9 This directive is missing from the original file, but you can add it immediately before or after listen-on-v6 . \u21a9","title":"DNS Resolver Setup"},{"location":"assignments/resolver-setup/#configure-a-recursive-dns-resolver-last-edited-2022-04-27","text":"","title":"Configure a Recursive DNS Resolver (last edited 2022-04-27)"},{"location":"assignments/resolver-setup/#overview","text":"In this assignment, we'll continue to extend the functionality of the Linux-based router by installing and configuring the open source BIND server to resolve DNS requests on behalf of hosts on your LAN. This new functionality will take the place of the public DNS resolvers we used in the previous assignments (e.g., 1.1.1.1 or 8.8.8.8 ). Important With each checkpoint, we expect you to do more of the work on your own. While the initial Pi setup gave clear instructions, we are slowly moving toward giving you specifications and additional context that you need in order to determine the right steps to accomplish the task. In this assignment, you'll be pointed toward external sources that you can reference in order to implement the project specifications. This can be a challenging adjustment, but it is also a valuable skill to learn and practice as you prepare for technical internships and jobs.","title":"Overview"},{"location":"assignments/resolver-setup/#before-you-start","text":"Before you begin, make sure that you have completed all steps through Checkpoint #3 successfully. At this point, your Pi should be able to route traffic between the Ethernet LAN and a public-facing Wireless network. Likewise, DHCP should provide LAN clients with a full network configuration, including a default gateway and a public DNS resolver. As with the previous checkpoint, you will rely on parameters you determined in your LAN Planning Exercise to complete this project.","title":"Before you start"},{"location":"assignments/resolver-setup/#instructions","text":"","title":"Instructions"},{"location":"assignments/resolver-setup/#review-your-address-plan","text":"Running the DNS resolver privately will require an IP address from your network range available on the Pi. While many home router configurations will use a single address for DHCP, routing, and DNS resolution, the specifications for this project require you to use a separate IP address that you selected when creating your initial address plan. Review that plan now.","title":"Review your Address Plan"},{"location":"assignments/resolver-setup/#configure-the-resolvers-ip-address","text":"Before you configure a new service with an address, you need to set up the address at the device level. Add your resolver's address to the static configuration for eth0 . In a networkd configuration, you can add additional addresses by putting each address (in abbreviated CIDR format) on a separate Address= line within your existing .network file. In order to do this, you may want to review the original setup given in Checkpoint #2 .","title":"Configure the Resolver's IP Address"},{"location":"assignments/resolver-setup/#install-bind-on-the-router","text":"The Berkeley Internet Name Daemon (BIND) is a robust and versatile DNS implementation distributed by the Internet Services Consortium (ISC) -- the same folks responsible for the DHCP server implementation we have deployed. The first version of BIND was released in 1986. At present, BIND 9 is the most widely deployed DNS server on the Internet. BIND and related utilities are packaged in the Debian and Raspberry Pi OS software repositories, meaning that they can be installed and managed easily with the apt utilities that we are already familiar with. For our purposes, you should install the following packages: bind9 , bind9utils , bind9-doc .","title":"Install BIND on the router"},{"location":"assignments/resolver-setup/#configure-bind-as-a-recursive-name-server-ie-a-resolver","text":"Name servers or DNS servers come in multiple flavors that are differentiated based on the queries they're configured to answer. 1 Some servers are responsible for a single tier or branch of the DNS hierarchy, e.g., names within the tcpip.dev domain, while other servers offer the ability to answer queries about any domain. BIND can be configured to operate in all of these roles, but in this checkpoint, we're focused on the latter objective. Until now, devices in your network relied on public servers to resolve recursive DNS queries , but you can configure BIND to act as the resolver for clients connecting from your LAN. The requirements for this task are described below, but you will likely need other resources in order to implement these specifications. There are a variety of tutorials available online, but Digital Ocean's community tutorial for Ubuntu Linux is more consistent than most with respect to project requirements. This guide does a good job explaining the organization of the configuration files you'll encounter and the syntax used when adding directives like acl or allow-query . Pay special attention to the caching DNS server section of this guide. The forwarding DNS server instructions are not relevant to this project.","title":"Configure BIND as a Recursive Name Server (i.e., a Resolver)"},{"location":"assignments/resolver-setup/#requirements","text":"Use the acl directive to create an access control list (ACL) that restricts access to BIND to devices on your LAN (your subnet range in the CIDR format) in addition to the Pi itself (using the localhost keyword). If you're curious to learn more about this security precaution, read up on Cache Poisoning and DNS Amplification or hit us up in office hours. Enable recursion and use the allow-query directive to grant access through your access control list Limit which IPv4 addresses on the Pi will be listening for DNS queries by configuring a listen-on block with the following local addresses: 2 127.0.0.1 is the loopback address, allowing the Pi to use BIND to answer its own queries. The static IP configured earlier for the DNS resolver. Disable IPv6 by changing listen-on-v6 { any; }; to listen-on-v6 { none; }; . Disable DNSSEC functionality by replacing the configuration line that reads dnssec-validation from auto to no . Disabling DNSSEC is necessary due to the limitations of using a Pi versus an always on network server. Specifically, the inability of the Pi to maintain accurate time when it is powered off interferes with the verification process for DNSSEC cryptographic signatures","title":"Requirements"},{"location":"assignments/resolver-setup/#test-and-verify-that-the-new-server-is-operating-properly","text":"In addition to the troubleshooting tools that we're already familiar with. BIND comes with a utility called named-checkconf that will review its core configuration files for syntax errors. It's important to run this tool each time you modify the BIND configuration in this assignment or future checkpoints. If it doesn't find any syntax errors in your configuration files, named-checkconf will return without displaying any messages. Once your files are free of errors, use systemctl to restart the bind9 service and check that it's working with dig , e.g., dig @127.0.0.1 washington.edu . As we've discussed in other places, the @IP syntax of dig is used to override local resolver settings (which are still determined by DHCP on the wireless network).","title":"Test and verify that the new server is operating properly"},{"location":"assignments/resolver-setup/#update-your-dhcp-server-configuration","text":"To wrap up this project, you need to update the DHCP server configuration so that LAN users will receive the address for the local resolver instead of the public resolver we previously used: Update DHCP server configuration so that devices configured by DHCP will use the Pi's DNS resolver rather than the public server you configured in Checkpoint #3. Use systemctl to restart the DHCP server daemon. Manually renew your DHCP configuration on your PC through the OS or by temporarily disconnecting the network cable. Verify that your computer receives the updated parameters from DHCP. See A Comparison of DNS Server Types \u21a9 This directive is missing from the original file, but you can add it immediately before or after listen-on-v6 . \u21a9","title":"Update your DHCP Server Configuration"},{"location":"assignments/router-setup/","text":"Build a NAT-enabled Router (2022-04-20) \u00b6 Overview \u00b6 This assignment builds on the DHCP server functionality you set up in the previous project. Follow the instructions provided here to set up NAT and enable packet forwarding on your Pi. At the end of the project, you will have a working network gateway. Note With each checkpoint, we expect you to do more of the work on your own. While the initial Pi setup gave clear instructions, we are slowly moving toward giving you specifications and additional context that you need in order to determine the right steps to accomplish the task. Before you Start \u00b6 Before you begin, make sure that you have completed all steps from Checkpoints #1 and #2 successfully. By now, your pi should be able to connect to the Internet via wireless, and it should provide DHCP services via a pre-defined address range on the ethernet-based LAN. At times in this project, you will need to refer back to the configuration you defined in the previous LAN Planning Exercise . Objectives \u00b6 In this assignment, you will be configuring the Pi as a simple Internet gateway that routes traffic between an isolated, wired LAN and an Internet-connected wireless network. Practically speaking, you'll be tethering your computer to the Pi and using it to access the rest of the Internet. Whether it is immediately obvious or not, this architecture has practical applications. It is not always a good idea to connect your computer directly to an untrusted network. With a few more components, the Pi provides a simple firewall that can protect against many types of threats. Further, the Pi can be used to tunnel your traffic through a personal VPN, ensuring that that it cannot be intercepted or tampered with on a public network or local ISP. Project outline \u00b6 The main steps of this project are listed below: Configure basic firewall rules and NAT Enable packet forwarding settings within Raspberry Pi OS Update DHCP to provide gateway and DNS settings Test and troubleshoot your configuration Overview of NAT \u00b6 The hosts in our network use RFC-1918 addresses, which are restricted to private networks and cannot be used as a source or destination for addresses on packets being sent over the Internet. We'll address this problem with network address translation (NAT) , which will allow your Pi to communicate on the Internet by masquerading with the public address assigned to the WAN port of the router. This setup is a special case of source NAT in that many private IP addresses will be mapped to one public address on the external interface. To accommodate, the Pi will need to monitor the state of each connection and other network traffic so that it can route to the correct host on the internal network when incoming traffic is received. Configuring NAT \u00b6 NAT functionality is supported natively in Linux through the netfilter firewall and can be managed through a framework known as nftables by defining rules that filter and manipulate packets. Attention Throughout the instructions, we'll refer to the wired interface as <LAN> (because it serves our local network) and the wireless interface as the <WAN> (because it connects us to the Internet). Your configuration files will reflect the OS-assigned interface names, such as: eth0 and wlan0 . We have prepared an nftables tutorial that focuses specifically on the features that are required to implement NAT . Read this tutorial carefully before you attempt to configure nftables on your Pi. Rule Specification \u00b6 The previous guide contains a template and partial ruleset to help you enable NAT and restrict traffic forwarded between networks. Save a copy of this template in the home directory of your Pi and fill in the missing values so that it complies with the following requirements: Create a table named filter with a base chain named forward that is attached to the filter / forward hook. Use a default policy to drop packets on the forward chain unless they're explicitly allowed by another rule. Include a rule to allow all outbound packets on the forward chain. Include a rule to allow inbound packets on the forward chain if they are related to previous packets or established connections. Create a table named nat with a base chain named postrouting that is attached to the nat / postrouting hook. Include a rule to masquerade the addresses for outbound packets on the <WAN> interface. Testing and Applying Rules \u00b6 After you finish filling in the missing values in the reference template according to the above specifications, follow the instructions in the provided tutorial to test your rules and load them at boot. You will not be able to completely test your rules until you complete upcoming steps. What you should ensure at this point is that the rules are applied and that you are not locked out of the Pi. Enable Packet Forwarding \u00b6 With your nftables configuration in place, you are ready to enable forwarding within the OS. By default, the Linux networking stack accepts packets with its own IP addresses and discards everything else. This behavior can be changed through the sysctl service, enabling the network stack to forward packets that are destined for nodes on another network. To turn on IPv4 forwarding when the system boots, add a new file named /etc/sysctl.d/10-forward_ip4.conf containing net.ipv4.ip_forward=1 . After saving this file, call sudo sysctl -p --system . Update DHCP Configuration \u00b6 Update the DHCP configuration written in the previous assignment to provide clients with settings for a default router and a public DNS resolver (called domain name servers in isc-dhcp-server ). Use the examples provided in the default dhcpd.conf as the basis for your changes. Restart isc-dhcp-server in order to load the new configuration. Renew your DHCP lease by temporarily disconnecting Ethernet or following instructions provided in the resources section of this site. Test your Configuration \u00b6 Once you have completed these changes, you should be able to access external networks by way of the Raspberry Pi. Disable wireless networking and other network interfaces on your laptop so that the Pi is your only route to the Internet. Try connecting to a well-known website from your browser. From your laptop's command line, use the traceroute command ( tracert on Windows) to confirm that your Pi is the first hop of this route. Troubleshooting \u00b6 If you run into problems here, there are a few points to check. First, try to ping a known address such as 1.1.1.1 from your computer. This will tell you whether or not you have connectivity outside your network. If you're at UW, try pinging 128.95.112.1, to determine whether you can access hosts on campus. You may also try pinging a known domain name like amazon.com (and washington.edu if you're on campus). If you can't ping anything, you may have an issue with the network configuration on your computer. Try pinging the static address you created for the Pi. If this fails with no route to host, go back and make sure you set up the Pi and your computer correctly. If you can ping by IP address, but not name, you have an issue with DNS. Verify that DHCP is providing a valid name server address. If you're able to ping your Pi by it's IP and you're certain that you've set up your local network correctly, go back and confirm that the Pi has forwarding enabled for IP and that your iptables rules are loading.","title":"Router Setup"},{"location":"assignments/router-setup/#build-a-nat-enabled-router-2022-04-20","text":"","title":"Build a NAT-enabled Router (2022-04-20)"},{"location":"assignments/router-setup/#overview","text":"This assignment builds on the DHCP server functionality you set up in the previous project. Follow the instructions provided here to set up NAT and enable packet forwarding on your Pi. At the end of the project, you will have a working network gateway. Note With each checkpoint, we expect you to do more of the work on your own. While the initial Pi setup gave clear instructions, we are slowly moving toward giving you specifications and additional context that you need in order to determine the right steps to accomplish the task.","title":"Overview"},{"location":"assignments/router-setup/#before-you-start","text":"Before you begin, make sure that you have completed all steps from Checkpoints #1 and #2 successfully. By now, your pi should be able to connect to the Internet via wireless, and it should provide DHCP services via a pre-defined address range on the ethernet-based LAN. At times in this project, you will need to refer back to the configuration you defined in the previous LAN Planning Exercise .","title":"Before you Start"},{"location":"assignments/router-setup/#objectives","text":"In this assignment, you will be configuring the Pi as a simple Internet gateway that routes traffic between an isolated, wired LAN and an Internet-connected wireless network. Practically speaking, you'll be tethering your computer to the Pi and using it to access the rest of the Internet. Whether it is immediately obvious or not, this architecture has practical applications. It is not always a good idea to connect your computer directly to an untrusted network. With a few more components, the Pi provides a simple firewall that can protect against many types of threats. Further, the Pi can be used to tunnel your traffic through a personal VPN, ensuring that that it cannot be intercepted or tampered with on a public network or local ISP.","title":"Objectives"},{"location":"assignments/router-setup/#project-outline","text":"The main steps of this project are listed below: Configure basic firewall rules and NAT Enable packet forwarding settings within Raspberry Pi OS Update DHCP to provide gateway and DNS settings Test and troubleshoot your configuration","title":"Project outline"},{"location":"assignments/router-setup/#overview-of-nat","text":"The hosts in our network use RFC-1918 addresses, which are restricted to private networks and cannot be used as a source or destination for addresses on packets being sent over the Internet. We'll address this problem with network address translation (NAT) , which will allow your Pi to communicate on the Internet by masquerading with the public address assigned to the WAN port of the router. This setup is a special case of source NAT in that many private IP addresses will be mapped to one public address on the external interface. To accommodate, the Pi will need to monitor the state of each connection and other network traffic so that it can route to the correct host on the internal network when incoming traffic is received.","title":"Overview of NAT"},{"location":"assignments/router-setup/#configuring-nat","text":"NAT functionality is supported natively in Linux through the netfilter firewall and can be managed through a framework known as nftables by defining rules that filter and manipulate packets. Attention Throughout the instructions, we'll refer to the wired interface as <LAN> (because it serves our local network) and the wireless interface as the <WAN> (because it connects us to the Internet). Your configuration files will reflect the OS-assigned interface names, such as: eth0 and wlan0 . We have prepared an nftables tutorial that focuses specifically on the features that are required to implement NAT . Read this tutorial carefully before you attempt to configure nftables on your Pi.","title":"Configuring NAT"},{"location":"assignments/router-setup/#rule-specification","text":"The previous guide contains a template and partial ruleset to help you enable NAT and restrict traffic forwarded between networks. Save a copy of this template in the home directory of your Pi and fill in the missing values so that it complies with the following requirements: Create a table named filter with a base chain named forward that is attached to the filter / forward hook. Use a default policy to drop packets on the forward chain unless they're explicitly allowed by another rule. Include a rule to allow all outbound packets on the forward chain. Include a rule to allow inbound packets on the forward chain if they are related to previous packets or established connections. Create a table named nat with a base chain named postrouting that is attached to the nat / postrouting hook. Include a rule to masquerade the addresses for outbound packets on the <WAN> interface.","title":"Rule Specification"},{"location":"assignments/router-setup/#testing-and-applying-rules","text":"After you finish filling in the missing values in the reference template according to the above specifications, follow the instructions in the provided tutorial to test your rules and load them at boot. You will not be able to completely test your rules until you complete upcoming steps. What you should ensure at this point is that the rules are applied and that you are not locked out of the Pi.","title":"Testing and Applying Rules"},{"location":"assignments/router-setup/#enable-packet-forwarding","text":"With your nftables configuration in place, you are ready to enable forwarding within the OS. By default, the Linux networking stack accepts packets with its own IP addresses and discards everything else. This behavior can be changed through the sysctl service, enabling the network stack to forward packets that are destined for nodes on another network. To turn on IPv4 forwarding when the system boots, add a new file named /etc/sysctl.d/10-forward_ip4.conf containing net.ipv4.ip_forward=1 . After saving this file, call sudo sysctl -p --system .","title":"Enable Packet Forwarding"},{"location":"assignments/router-setup/#update-dhcp-configuration","text":"Update the DHCP configuration written in the previous assignment to provide clients with settings for a default router and a public DNS resolver (called domain name servers in isc-dhcp-server ). Use the examples provided in the default dhcpd.conf as the basis for your changes. Restart isc-dhcp-server in order to load the new configuration. Renew your DHCP lease by temporarily disconnecting Ethernet or following instructions provided in the resources section of this site.","title":"Update DHCP Configuration"},{"location":"assignments/router-setup/#test-your-configuration","text":"Once you have completed these changes, you should be able to access external networks by way of the Raspberry Pi. Disable wireless networking and other network interfaces on your laptop so that the Pi is your only route to the Internet. Try connecting to a well-known website from your browser. From your laptop's command line, use the traceroute command ( tracert on Windows) to confirm that your Pi is the first hop of this route.","title":"Test your Configuration"},{"location":"assignments/router-setup/#troubleshooting","text":"If you run into problems here, there are a few points to check. First, try to ping a known address such as 1.1.1.1 from your computer. This will tell you whether or not you have connectivity outside your network. If you're at UW, try pinging 128.95.112.1, to determine whether you can access hosts on campus. You may also try pinging a known domain name like amazon.com (and washington.edu if you're on campus). If you can't ping anything, you may have an issue with the network configuration on your computer. Try pinging the static address you created for the Pi. If this fails with no route to host, go back and make sure you set up the Pi and your computer correctly. If you can ping by IP address, but not name, you have an issue with DNS. Verify that DHCP is providing a valid name server address. If you're able to ping your Pi by it's IP and you're certain that you've set up your local network correctly, go back and confirm that the Pi has forwarding enabled for IP and that your iptables rules are loading.","title":"Troubleshooting"},{"location":"assignments/tls13-complete-handshake/","text":"Completing the TLS 1.3 Handshake \u00b6 Overview \u00b6 In the first stage of the TLS 1.3 handshake, the client and server negotiate encryption parameters and exchange asymmetric key material by sending an unecrypted Hello message. After completing this exchange, each participant computes symmetric traffic encryption keys that are used when sending and receiving the remaining messages in the handshake. We'll move forward in this section with the goal of completing the handshake and computing a second set of symmetric traffic encryption keys to protect application layer data. Additional Handshake Messages \u00b6 After the server sends its Hello message and computes the handshake traffic encryption keys, it is required to send several additional handshake messages, including the following: Encrypted Extensions (8), Certificate (11), Certificate Verify (15), and Finished (20). Prior to sending the Finished message, a TLS 1.3 server may also send additional handshake messages, such as a Certificate Request . These handshake messages enable the server to send additional options through the TLS extension mechanism, authenticate its identity using a PKI-based certificate mechanism, request authentication of the client, and prove integrity of the handshake and its own traffic key computations. After receiving and processing the remaining handshake messages from the server, the TLS client responds to additional requests such as a Certificate Request and updates the handshake message transcript. Next, the client computes a hash-based message authentication code (HMAC) over the message transcript. This value, referred to as the client's Verify Data is encapsulated in the handshake protocol's Finished message and sent to the server. The client's Finished message signals the end of the handshake to the server and enables it to cryptographically verify the integrity of the handshake and confirm that the client holds the correct encryption secrets. Backwards Compatibility \u00b6 Along with its remaining handshake messages, the server might also send a Change Cipher Spec . This message was used in previous TLS versions to signal a cipher configuration change, such as the transition from sending records in plaintext to sending them in ciphertext. This record type is only included in the TLS 1.3 for compatibility with middleboxes such as proxy servers, load balancers, and web application firewalls. TLS 1.3 clients must be able to receive a Change Cipher Spec message to ensure compatibility, but they must not take any further action after reading and removing it from the underlying data s Implementation Tasks \u00b6 Sticking to our goal of writing the least amount of functionality needed to send and receive encrypted application traffic, we can proceed without needing to fully parse the handshake messages mentioned above. However, since these messages are part of the handshake, their plaintext content does need to be included in the handshake transcript so that client can compute the required HMAC and application traffic keys. Even in our toy implementation, we are likely to encounter a Change Cipher Spec message. This message is passed in an unencrypted record type that can be identified by the record header's type value (20). Since it is used only for compatibility, the Change Cipher Spec should be skipped without further processing. Further, the message is not part of the handshake protocol, and it is omitted from the handshake transcript. The additional funcitionality required to complete this task is summarized here: Compute handshake traffic encryption keys using the get_handshake_cipher() method of TLSContext . This step is described within Generating TLS 1.3 Handshake Keys . Continue processing each TLS record sent by the server until you have seen its Finished message (handshake type 20). Encrypted records should be handled according to the process described in Working with Encrypted TLS Records . You will need to detect Change Cipher Spec messages (record type 20), but you should not do any further processing after removing the messages from the incoming socket buffer. Decrypt each Application Data message (record type 23), and determine the underlying message type by examining the 1-byte record footer that was appended to the original message data. Add the decrypted message body from each Handshake message (record type 22) to the handshake transcript using the update_transcript() method of TLSContext . Use the compute_verify_data() of TLSContext to compute the client-generated Verify Data based on the current handshake transcript. This method is called without arguments and returns a Python bytes object. Construct a handshake Finished message using the the computed Verify Data , and return it to the server as an encrypted record. Finally, use the get_application_cipher() method of TLSContext to generate traffic keys for application data.","title":"Completing the TLS 1.3 Handshake"},{"location":"assignments/tls13-complete-handshake/#completing-the-tls-13-handshake","text":"","title":"Completing the TLS 1.3 Handshake"},{"location":"assignments/tls13-complete-handshake/#overview","text":"In the first stage of the TLS 1.3 handshake, the client and server negotiate encryption parameters and exchange asymmetric key material by sending an unecrypted Hello message. After completing this exchange, each participant computes symmetric traffic encryption keys that are used when sending and receiving the remaining messages in the handshake. We'll move forward in this section with the goal of completing the handshake and computing a second set of symmetric traffic encryption keys to protect application layer data.","title":"Overview"},{"location":"assignments/tls13-complete-handshake/#additional-handshake-messages","text":"After the server sends its Hello message and computes the handshake traffic encryption keys, it is required to send several additional handshake messages, including the following: Encrypted Extensions (8), Certificate (11), Certificate Verify (15), and Finished (20). Prior to sending the Finished message, a TLS 1.3 server may also send additional handshake messages, such as a Certificate Request . These handshake messages enable the server to send additional options through the TLS extension mechanism, authenticate its identity using a PKI-based certificate mechanism, request authentication of the client, and prove integrity of the handshake and its own traffic key computations. After receiving and processing the remaining handshake messages from the server, the TLS client responds to additional requests such as a Certificate Request and updates the handshake message transcript. Next, the client computes a hash-based message authentication code (HMAC) over the message transcript. This value, referred to as the client's Verify Data is encapsulated in the handshake protocol's Finished message and sent to the server. The client's Finished message signals the end of the handshake to the server and enables it to cryptographically verify the integrity of the handshake and confirm that the client holds the correct encryption secrets.","title":"Additional Handshake Messages"},{"location":"assignments/tls13-complete-handshake/#backwards-compatibility","text":"Along with its remaining handshake messages, the server might also send a Change Cipher Spec . This message was used in previous TLS versions to signal a cipher configuration change, such as the transition from sending records in plaintext to sending them in ciphertext. This record type is only included in the TLS 1.3 for compatibility with middleboxes such as proxy servers, load balancers, and web application firewalls. TLS 1.3 clients must be able to receive a Change Cipher Spec message to ensure compatibility, but they must not take any further action after reading and removing it from the underlying data s","title":"Backwards Compatibility"},{"location":"assignments/tls13-complete-handshake/#implementation-tasks","text":"Sticking to our goal of writing the least amount of functionality needed to send and receive encrypted application traffic, we can proceed without needing to fully parse the handshake messages mentioned above. However, since these messages are part of the handshake, their plaintext content does need to be included in the handshake transcript so that client can compute the required HMAC and application traffic keys. Even in our toy implementation, we are likely to encounter a Change Cipher Spec message. This message is passed in an unencrypted record type that can be identified by the record header's type value (20). Since it is used only for compatibility, the Change Cipher Spec should be skipped without further processing. Further, the message is not part of the handshake protocol, and it is omitted from the handshake transcript. The additional funcitionality required to complete this task is summarized here: Compute handshake traffic encryption keys using the get_handshake_cipher() method of TLSContext . This step is described within Generating TLS 1.3 Handshake Keys . Continue processing each TLS record sent by the server until you have seen its Finished message (handshake type 20). Encrypted records should be handled according to the process described in Working with Encrypted TLS Records . You will need to detect Change Cipher Spec messages (record type 20), but you should not do any further processing after removing the messages from the incoming socket buffer. Decrypt each Application Data message (record type 23), and determine the underlying message type by examining the 1-byte record footer that was appended to the original message data. Add the decrypted message body from each Handshake message (record type 22) to the handshake transcript using the update_transcript() method of TLSContext . Use the compute_verify_data() of TLSContext to compute the client-generated Verify Data based on the current handshake transcript. This method is called without arguments and returns a Python bytes object. Construct a handshake Finished message using the the computed Verify Data , and return it to the server as an encrypted record. Finally, use the get_application_cipher() method of TLSContext to generate traffic keys for application data.","title":"Implementation Tasks"},{"location":"assignments/tls13-encrypt-decrypt/","text":"Working with Encrypted TLS Records \u00b6 Overview \u00b6 After generating symmetric keys used to protect later handshake messages or application traffic, you are ready begin using these keys to encrypt outbound traffic or decrypt incoming traffic. The helper classes provided for this project encapsulates this functionality into the TLSCipher class, which you can retrieve by calling get_handshake_cipher() (after receiving the server's hello message) and get_application_cipher() prior to sending the client's finish message. AEAD Ciphers \u00b6 All TLS 1.3 cipher suites implement a mode of encryption known as Authenticated Encryption with Associated Data (AEAD). While symmetric encryption is used to generate ciphertext that can't be read without a key, the ciphertext (and underlying plaintext) produced by many encryption modes can often be modified without detection. Authenticated encryption modes add an authentication tag to the ciphertext in order to ensure the integrity of the message by detecting changes that occur after the data is encrypted. AEAD takes this integrity mechanism one step further, providing integrity across plaintext data that is associated with an encrypted message. This feature can be used to ensure that metadata outside of the encrypted messages is left intact. When TLS encrypts a message, the 5-byte record header is left unencrypted. By using AEAD algorithms, TLS 1.3 defends against changes across the entire TLS record construct while leaving the record header visible to the recipient. Even a change to the unencrypted record header, e.g., changing the TLS record type or version, can be detected by the recipient. TLSCipher Operations \u00b6 The get_handshake_cipher() and get_application_cipher() methods return TLSCipher objects that provide their own encrypt() and decrypt() methods. Since TLSCipher objects implement AEAD ciphers, two inputs are required for each cryptographic operation. The plaintext (for encrypt) or ciphertext and authentication tag (for decrypt) Additional data that will be bound to the cipher text through the AEAD integrity mechanism The TLSCipher encrypt() method returns a new byte object that includes the ciphertext and authentication tag. The length of this object equals the length of the original plaintext plus 16 bytes for the authentication tag. The byte object returned by decrypt() includes only the plaintext byte that were originally encrypted without any additional data or authentication tag. The 16-byte authentication tag of the ciphertext is stripped off and validated by the decrypt operation. An exception will be thrown if the authentication tag cannot be verified due to changes in the ciphertext or additional data. Encrypted Record Structure \u00b6 You've already worked with unencrypted records used to send client and server hello messages. To complete the handshake and start exchanging application data, you also need to be able to build and parse encrypted records. On the outside, these records look similar to those you've already seen, though they are always assigned record type 23 (the assigned value for application data) to ensure that the connection peer can recognize that the record data will need to be decrypted before further processing. The following steps are needed to build a protected record: Append the real message type (such as 22 or 23) as a 1-byte trailer at the end of the message body to obtain the plaintext record data Compute length of the encrypted record body by adding 16 bytes to the plaintext record length to account for the authentication tag Compute the 5 byte record header with type 23 (application data), version b'\\x03\\03', and the computed ciphertext length Using the 5-byte record header as additional authenticated data, encrypt the body of the record Concatenate the header and encrypted body Likewise, the process to decrypt and parse a message looks like so: Parse the 5 byte record header to obtain the type, version, and length of the record If the record type is 23, you will need to decrypt in order to proceed Split the record into its header and the remaining body Passing in the 5-byte record header as additional authenticated data, decrypt the body of the record Split the plaintext returned from the decryption to obtain the message body and 1-byte record type (the real type this time) Example Encrypt/Decrypt \u00b6 The following code demonstrates this entire process. handshake_cipher = get_handshake_cipher () # Build TAG_LENGTH = 16 data = b 'insert real data here' plaintext = data + b ' \\16 ' # indicates this is actually a handshake message ciphertext_length = len ( plaintext ) + TAG_LENGTH record_header = b ' \\x17 ' + b ' \\x03\\x03 ' + ciphertext_length . to_bytes ( 2 , 'big' ) ciphertext = handshake_cipher . encrypt ( plaintext , record_header ) record = record_header + ciphertext # Parse rtype , rversion , rlength = record [ 0 ], record [ 1 , 3 ], int . from_bytes ( record [ 3 , 5 ], 'big' ) if rtype = 23 : # must be encrypted record_header , ciphertext = record [ 0 : 5 ], record [ 5 : 5 + rlength ] plaintext = handshake_cipher . decrypt ( ciphertext , record_header ) data , rtype = plaintext [ 0 : - 1 ], plaintext [ - 1 ] # rtype is now set to the actual record type taken from the final byte of the decrypted message # data is now set to the actual plaintext message and can be parsed as you've done with server hello","title":"Working with Encrypted TLS Records"},{"location":"assignments/tls13-encrypt-decrypt/#working-with-encrypted-tls-records","text":"","title":"Working with Encrypted TLS Records"},{"location":"assignments/tls13-encrypt-decrypt/#overview","text":"After generating symmetric keys used to protect later handshake messages or application traffic, you are ready begin using these keys to encrypt outbound traffic or decrypt incoming traffic. The helper classes provided for this project encapsulates this functionality into the TLSCipher class, which you can retrieve by calling get_handshake_cipher() (after receiving the server's hello message) and get_application_cipher() prior to sending the client's finish message.","title":"Overview"},{"location":"assignments/tls13-encrypt-decrypt/#aead-ciphers","text":"All TLS 1.3 cipher suites implement a mode of encryption known as Authenticated Encryption with Associated Data (AEAD). While symmetric encryption is used to generate ciphertext that can't be read without a key, the ciphertext (and underlying plaintext) produced by many encryption modes can often be modified without detection. Authenticated encryption modes add an authentication tag to the ciphertext in order to ensure the integrity of the message by detecting changes that occur after the data is encrypted. AEAD takes this integrity mechanism one step further, providing integrity across plaintext data that is associated with an encrypted message. This feature can be used to ensure that metadata outside of the encrypted messages is left intact. When TLS encrypts a message, the 5-byte record header is left unencrypted. By using AEAD algorithms, TLS 1.3 defends against changes across the entire TLS record construct while leaving the record header visible to the recipient. Even a change to the unencrypted record header, e.g., changing the TLS record type or version, can be detected by the recipient.","title":"AEAD Ciphers"},{"location":"assignments/tls13-encrypt-decrypt/#tlscipher-operations","text":"The get_handshake_cipher() and get_application_cipher() methods return TLSCipher objects that provide their own encrypt() and decrypt() methods. Since TLSCipher objects implement AEAD ciphers, two inputs are required for each cryptographic operation. The plaintext (for encrypt) or ciphertext and authentication tag (for decrypt) Additional data that will be bound to the cipher text through the AEAD integrity mechanism The TLSCipher encrypt() method returns a new byte object that includes the ciphertext and authentication tag. The length of this object equals the length of the original plaintext plus 16 bytes for the authentication tag. The byte object returned by decrypt() includes only the plaintext byte that were originally encrypted without any additional data or authentication tag. The 16-byte authentication tag of the ciphertext is stripped off and validated by the decrypt operation. An exception will be thrown if the authentication tag cannot be verified due to changes in the ciphertext or additional data.","title":"TLSCipher Operations"},{"location":"assignments/tls13-encrypt-decrypt/#encrypted-record-structure","text":"You've already worked with unencrypted records used to send client and server hello messages. To complete the handshake and start exchanging application data, you also need to be able to build and parse encrypted records. On the outside, these records look similar to those you've already seen, though they are always assigned record type 23 (the assigned value for application data) to ensure that the connection peer can recognize that the record data will need to be decrypted before further processing. The following steps are needed to build a protected record: Append the real message type (such as 22 or 23) as a 1-byte trailer at the end of the message body to obtain the plaintext record data Compute length of the encrypted record body by adding 16 bytes to the plaintext record length to account for the authentication tag Compute the 5 byte record header with type 23 (application data), version b'\\x03\\03', and the computed ciphertext length Using the 5-byte record header as additional authenticated data, encrypt the body of the record Concatenate the header and encrypted body Likewise, the process to decrypt and parse a message looks like so: Parse the 5 byte record header to obtain the type, version, and length of the record If the record type is 23, you will need to decrypt in order to proceed Split the record into its header and the remaining body Passing in the 5-byte record header as additional authenticated data, decrypt the body of the record Split the plaintext returned from the decryption to obtain the message body and 1-byte record type (the real type this time)","title":"Encrypted Record Structure"},{"location":"assignments/tls13-encrypt-decrypt/#example-encryptdecrypt","text":"The following code demonstrates this entire process. handshake_cipher = get_handshake_cipher () # Build TAG_LENGTH = 16 data = b 'insert real data here' plaintext = data + b ' \\16 ' # indicates this is actually a handshake message ciphertext_length = len ( plaintext ) + TAG_LENGTH record_header = b ' \\x17 ' + b ' \\x03\\x03 ' + ciphertext_length . to_bytes ( 2 , 'big' ) ciphertext = handshake_cipher . encrypt ( plaintext , record_header ) record = record_header + ciphertext # Parse rtype , rversion , rlength = record [ 0 ], record [ 1 , 3 ], int . from_bytes ( record [ 3 , 5 ], 'big' ) if rtype = 23 : # must be encrypted record_header , ciphertext = record [ 0 : 5 ], record [ 5 : 5 + rlength ] plaintext = handshake_cipher . decrypt ( ciphertext , record_header ) data , rtype = plaintext [ 0 : - 1 ], plaintext [ - 1 ] # rtype is now set to the actual record type taken from the final byte of the decrypted message # data is now set to the actual plaintext message and can be parsed as you've done with server hello","title":"Example Encrypt/Decrypt"},{"location":"assignments/tls13-key-generation/","text":"Generating TLS 1.3 Handshake Keys \u00b6 Overview \u00b6 After processing the server's hello message to determine the its preferred cipher suite and public key, you will have everything needed to compute symmetric encryption keys that are used to protect the rest of the handshake. These calculations are already written for you in the TLSContext class that was introduced in the first part of this assignment; however, you will need to pass the server's contributions into the context in order to complete the process. Server Encryption Parameters \u00b6 In the first step of the TLS 1.3 handshake, our client proposed an elliptic curve Diffie-Hellman key exchange using x25519 parameters. In response, the server provided an x25519 public key within a Key Share extension (type 51) attached to the server hello. This value is used by the client to complete the ECDHE key exchange from its side. Pass the the public key extracted from this extension to the set_server_public() method of TLSContext as shown below: # After processing server hello and extensions tls . set_server_public ( server_public_key ) # (1) tls is a TLSContext object. server_public_key contains the public key extracted from the Server Hello message. This value is a bytes object with key data only. Be sure to strip the key type and length fields. In addition to the key exchange parameters, the client's hello message offered a list of cipher suites, i.e., symmetric encryption configurations, that the client is willing to accept. The server is responsible for selecting one of these options and providing the 2-byte assigned identifier back to the client. Use the set_cipher_suite() method to configure the TLSContext with the server's response. tls . set_cipher_suite ( server_cipher_suite ) # (1) server_cipher_suite should be a 2-byte identifier associated with one of the cipher suites offered in the Client Hello message. Handshake Transcript and Hash \u00b6 In order to prevent attacks on the unencrypted handshake, TLS clients and servers maintain a transcript of each message handshake message sent and received. At different points during the handshake, clients and servers will compute a hash from this transcript. By incorporating this hash into the computation of encryption keys, TLS prevents outside attackers from making changes to the handshake that would allow them to break encryption. Any attempt to do so will change the key computation for either the server or the client. Each time you send or receive a handshake message, use the TLSContext's update_transcript() method to update the internal handshake transcript so that this hash can be computed properly in later steps. Pass the raw handshake bytes to the method on each call, but be sure to exclude the 5-byte record header. # After creating the client_hello message tls . update_transcript ( client_hello [ 5 :]) # (1) In this example, client_hello is a bytes object containing a 5-byte record header that needs to be sliced away. Computing Handshake Keys \u00b6 After completing the previous steps, you will be able to compute the keys used by the client and server to send encrypted handshake messages. The code for this computation is already provided within the TLSContext class. The get_handshake_cipher() method returns a new object that you will use in future steps to encrypt and decrypt data. handshake_cipher = tls . get_handshake_cipher () # example decrypt: handshake_cipher.decrypt(record['data'], record['header'])","title":"Key Generation"},{"location":"assignments/tls13-key-generation/#generating-tls-13-handshake-keys","text":"","title":"Generating TLS 1.3 Handshake Keys"},{"location":"assignments/tls13-key-generation/#overview","text":"After processing the server's hello message to determine the its preferred cipher suite and public key, you will have everything needed to compute symmetric encryption keys that are used to protect the rest of the handshake. These calculations are already written for you in the TLSContext class that was introduced in the first part of this assignment; however, you will need to pass the server's contributions into the context in order to complete the process.","title":"Overview"},{"location":"assignments/tls13-key-generation/#server-encryption-parameters","text":"In the first step of the TLS 1.3 handshake, our client proposed an elliptic curve Diffie-Hellman key exchange using x25519 parameters. In response, the server provided an x25519 public key within a Key Share extension (type 51) attached to the server hello. This value is used by the client to complete the ECDHE key exchange from its side. Pass the the public key extracted from this extension to the set_server_public() method of TLSContext as shown below: # After processing server hello and extensions tls . set_server_public ( server_public_key ) # (1) tls is a TLSContext object. server_public_key contains the public key extracted from the Server Hello message. This value is a bytes object with key data only. Be sure to strip the key type and length fields. In addition to the key exchange parameters, the client's hello message offered a list of cipher suites, i.e., symmetric encryption configurations, that the client is willing to accept. The server is responsible for selecting one of these options and providing the 2-byte assigned identifier back to the client. Use the set_cipher_suite() method to configure the TLSContext with the server's response. tls . set_cipher_suite ( server_cipher_suite ) # (1) server_cipher_suite should be a 2-byte identifier associated with one of the cipher suites offered in the Client Hello message.","title":"Server Encryption Parameters"},{"location":"assignments/tls13-key-generation/#handshake-transcript-and-hash","text":"In order to prevent attacks on the unencrypted handshake, TLS clients and servers maintain a transcript of each message handshake message sent and received. At different points during the handshake, clients and servers will compute a hash from this transcript. By incorporating this hash into the computation of encryption keys, TLS prevents outside attackers from making changes to the handshake that would allow them to break encryption. Any attempt to do so will change the key computation for either the server or the client. Each time you send or receive a handshake message, use the TLSContext's update_transcript() method to update the internal handshake transcript so that this hash can be computed properly in later steps. Pass the raw handshake bytes to the method on each call, but be sure to exclude the 5-byte record header. # After creating the client_hello message tls . update_transcript ( client_hello [ 5 :]) # (1) In this example, client_hello is a bytes object containing a 5-byte record header that needs to be sliced away.","title":"Handshake Transcript and Hash"},{"location":"assignments/tls13-key-generation/#computing-handshake-keys","text":"After completing the previous steps, you will be able to compute the keys used by the client and server to send encrypted handshake messages. The code for this computation is already provided within the TLSContext class. The get_handshake_cipher() method returns a new object that you will use in future steps to encrypt and decrypt data. handshake_cipher = tls . get_handshake_cipher () # example decrypt: handshake_cipher.decrypt(record['data'], record['header'])","title":"Computing Handshake Keys"},{"location":"assignments/tls13-wireshark-decryption/","text":"Analyzing Encrypted Traffic with Wirehark \u00b6 To present a detailed, protocol-aware view of network packets, Wireshark uses a library of decoders to parse and interpret the headers and data at each layer of the network protocol stack. With support for thousands of protocols, Wireshark is even able to provide a rich view of application layer messages. By default, strong encryption limits Wireshark's feature set. As a passive observer of conversations, Wireshark is not able to obtain or compute encryption keys that are needed to decrypt network traffic that it observes. To work around this limitation, Wireshark can be configured to load the TLS session secrets from a filesystem based log. Wireshark uses these secrets to generate handshake and application traffic keys that allow it to fully decode each step of the TLS handshake and higher-layer application traffic. Logging Keys from TLSContext \u00b6 The TLSContext class that is defined in the project repository includes a log_keys() method that generates the log entries needed to facilitate this process. This method emits four rows of text representing the client/server handshake secrets and the client/server application secrets. Each of log entry is also associated with the client random value from the current session's Client Hello . This value enables Wireshark to quickly identify a TLS session and select the appropriate secrets from the log file. To save these entries into a Wireshark-compatible log file, update your handshake code to append the new secrets to a file. The following example creates or updates a file named info314_tls13_keys in the current user's home directory. home_directory = os . environ [ 'HOME' ] with open ( f ' { home_directory } /info314_tls13_keys' , 'a' ) as f : entry = context . log_keys () f . write ( entry ) Call tls.generate_handshake_keys() and tls.generate_application_keys() before log_keys() method. For a more flexible approach, please follow the steps in Updated Key Logging Methods . Wireshark TLS Preferences \u00b6 To start analyzing encrypted traffic, add the location of the log file to TLS protocol preferences in Wireshark: Open Wireshark's preferences pane Expand Protocols in the left pane of the preference window and scroll until you find TLS. Enter the full path to the log in the (Pre)-Master-Secret log filename. (Optional) Select or deselect from the default options to control Wireshark decoding behavior: Reassemble TLS records spanning multiple TCP segments Reassemble TLS Application Data spanning multiple TLS records Message Authentication Code (MAC), ignore \"mac failed\" (useful for debugging) Updated Key Logging Methods \u00b6 For more flexibility, update helpers.py and add the following snippet immediately before or after the existing log_keys() definition. These methods will emit handshake and application keys in separate steps, which makes it somewhat easier to troubleshoot issues associated with the completion of the handshake. def log_handshake_keys ( self ): out = f \"CLIENT_HANDSHAKE_TRAFFIC_SECRET { self . client_random . hex () } { self . client_handshake_secret . hex () } \\n \" out += f \"SERVER_HANDSHAKE_TRAFFIC_SECRET { self . client_random . hex () } { self . server_handshake_secret . hex () } \\n \" return out def log_application_keys ( self ): out = f \"CLIENT_TRAFFIC_SECRET_0 { self . client_random . hex () } { self . client_application_secret . hex () } \\n \" out += f \"SERVER_TRAFFIC_SECRET_0 { self . client_random . hex () } { self . server_application_secret . hex () } \\n \" return out","title":"Decrypting TLS Traffic in Wireshark"},{"location":"assignments/tls13-wireshark-decryption/#analyzing-encrypted-traffic-with-wirehark","text":"To present a detailed, protocol-aware view of network packets, Wireshark uses a library of decoders to parse and interpret the headers and data at each layer of the network protocol stack. With support for thousands of protocols, Wireshark is even able to provide a rich view of application layer messages. By default, strong encryption limits Wireshark's feature set. As a passive observer of conversations, Wireshark is not able to obtain or compute encryption keys that are needed to decrypt network traffic that it observes. To work around this limitation, Wireshark can be configured to load the TLS session secrets from a filesystem based log. Wireshark uses these secrets to generate handshake and application traffic keys that allow it to fully decode each step of the TLS handshake and higher-layer application traffic.","title":"Analyzing Encrypted Traffic with Wirehark"},{"location":"assignments/tls13-wireshark-decryption/#logging-keys-from-tlscontext","text":"The TLSContext class that is defined in the project repository includes a log_keys() method that generates the log entries needed to facilitate this process. This method emits four rows of text representing the client/server handshake secrets and the client/server application secrets. Each of log entry is also associated with the client random value from the current session's Client Hello . This value enables Wireshark to quickly identify a TLS session and select the appropriate secrets from the log file. To save these entries into a Wireshark-compatible log file, update your handshake code to append the new secrets to a file. The following example creates or updates a file named info314_tls13_keys in the current user's home directory. home_directory = os . environ [ 'HOME' ] with open ( f ' { home_directory } /info314_tls13_keys' , 'a' ) as f : entry = context . log_keys () f . write ( entry ) Call tls.generate_handshake_keys() and tls.generate_application_keys() before log_keys() method. For a more flexible approach, please follow the steps in Updated Key Logging Methods .","title":"Logging Keys from TLSContext"},{"location":"assignments/tls13-wireshark-decryption/#wireshark-tls-preferences","text":"To start analyzing encrypted traffic, add the location of the log file to TLS protocol preferences in Wireshark: Open Wireshark's preferences pane Expand Protocols in the left pane of the preference window and scroll until you find TLS. Enter the full path to the log in the (Pre)-Master-Secret log filename. (Optional) Select or deselect from the default options to control Wireshark decoding behavior: Reassemble TLS records spanning multiple TCP segments Reassemble TLS Application Data spanning multiple TLS records Message Authentication Code (MAC), ignore \"mac failed\" (useful for debugging)","title":"Wireshark TLS Preferences"},{"location":"assignments/tls13-wireshark-decryption/#updated-key-logging-methods","text":"For more flexibility, update helpers.py and add the following snippet immediately before or after the existing log_keys() definition. These methods will emit handshake and application keys in separate steps, which makes it somewhat easier to troubleshoot issues associated with the completion of the handshake. def log_handshake_keys ( self ): out = f \"CLIENT_HANDSHAKE_TRAFFIC_SECRET { self . client_random . hex () } { self . client_handshake_secret . hex () } \\n \" out += f \"SERVER_HANDSHAKE_TRAFFIC_SECRET { self . client_random . hex () } { self . server_handshake_secret . hex () } \\n \" return out def log_application_keys ( self ): out = f \"CLIENT_TRAFFIC_SECRET_0 { self . client_random . hex () } { self . client_application_secret . hex () } \\n \" out += f \"SERVER_TRAFFIC_SECRET_0 { self . client_random . hex () } { self . server_application_secret . hex () } \\n \" return out","title":"Updated Key Logging Methods"},{"location":"assignments/tls13/","text":"TLS 1.3 Lab Introduction \u00b6 Overview \u00b6 This lab is the start of a multi-week project building a minimal HTTPS client using the TLS 1.3 protocol over TCP. The overall goal will be to complete a TLS 1.3 handshake, send a simple HTTP GET request to the course website over the encrypted channel, and process its response. With the short time remaining, you may not be able to complete the project in its entirety, but you will get plenty of hands-on experience with common protocol implementation challenges. Be aware that this is a complicated protocol. This guide is provided as a high-level reference, but we will also be providing starter code and walking through code in class. If you find yourself struggling, please review the resources and ask for help. Limitations \u00b6 Our implementation will not be feature complete or even secure on a practical level. The objective is to strip away as many unnecessary details as necessary so in order to handle data for a single HTTP request and response. The first detail that we have removed is concurrency. A non-concurrent network application is easier to reason about for a beginner because it is restricted to sequential operations and can't perform reading and writing operations at the same time. We will also ignore the following tasks that would be needed in a real TLS implementation handshake verification (security critical) certificate verification (security critical) signature verification (security critical) error handling / alerts key updates client certificates pre-shared keys session tickets Cryptography \u00b6 Even with the these omissions, a functional TLS 1.3 implementation is still quite a challenging task due to its use of cryptography to generate keys and encrypt / decrypt application layer data. To simplify the task, the project repository includes a module named helpers.py that contains classes that will manage these more complex concerns and allow you to focus on the practical elements of communication Layer 4 - 7 communication. Resources \u00b6 In addition to example code and demonstrations provided in the course repository and lectures, you will need to reference resources that decompose real TLS connections. By imitating the examples, you will be able to create a working version of TLS without having to become a protocol expert in advance. The following two sites will be used extensively. The Illustrated TLS 1.3 Connection A Walkthrough of the TLS 1.3 Handshake Likewise, RFC 8446 is the definitive resource to learn more about the protocol. The Transport Layer Security (TLS) Protocol Version 1.3 (RFC 8446) Tasks \u00b6 Preparation \u00b6 The code provided for this course relies on Python 3.9+ and one external cryptographic library. Once you've confirmed that you have the proper version of Python installed, use your preferred dependency management workflow to install the cryptography package. If you're unfamiliar with project dependency management, you can make the package available to all Python 3 code on your system by running pip3 install cryptography . Create TCP Connection \u00b6 Create a client-based TCP connection using the sockets library. Connecting to the requested host will initiate a TCP handshake. Before the application exits, you should close the socket. Establish TLSContext \u00b6 Before you get too far in the project, you will need to import the TLSContext class from the project directory and create a new context instance that'll help you manage the cryptographic aspects of your connection. The following snippet demonstrates how to initialize the context and retrieve saved properties. from helpers import TLSContext def hostname = \"info314.tcpip.dev\" # Create a new context tls = TLSContext ( hostname = hostname ) # Generate client_random, private_key, and public_key tls . generate_handshake_parameters () # Inspect values that your handshake code will rely on print ( f \" { tls . hostname =} \" ) print ( f \" { tls . client_random . hex ( ' ' ) =} \" ) print ( f \" { tls . public_key . hex ( ' ' ) =} \" ) print ( f \" { tls . cipher_suites =} \" ) print ( f \" { tls . signature_algorithms =} \" ) Begin TLS Handshake \u00b6 In this assignment, you will focus on generating/sending a ClientHello message and processing the ServerHello message that is sent back in response. Send Client Hello \u00b6 Build and send an unencrypted record containing ClientHello message. The ClientHello message initiates the TLS handshake and provides an initial set of parameters that the server can use to determine the capabilities of the client and compute a shared secret. Be aware that the ClientHello for TLS 1.3 is disguised to appear as an earlier version of the protocol to avoid problems with legacy middle boxes . To complete this disguise, TLS 1.3 will outwardly present TLS 1.2 and also include certain fields that don't provide any function in TLS 1.3. Record and Handshake Headers \u00b6 As a rather complex protocol, TLS uses multiple layers of messages headers to communicate message structure to software. When we send the ClientHello message on the network, it will require the following parts: TLS Record Header Every TLS message is encoded as a record with a 5-byte header, including a 1-byte record type, a 2-byte protocol version, and a 2-byte length field. The ClientHello record header sets the type to 22 for handshake message and sets the version to TLS 1.0 b'\\x03\\x01' . The length is encoded in network byte order and excludes the 5-bytes of record header. Handshake Header Every TLS handshake message will also have a 4-byte header, including a 1-byte message type and a 3-byte length field. The ClientHello message sets the type to 1. The length is encoded in network byte order and excludes the length of the record and handshake headers. Core Message Structure \u00b6 Each message type prescribes specific requirements for the structure of its messages. The following fields make up the payload of the ClientHello message. Client Version The ClientHello version field is a two-byte field set to TLS 1.2 b'\\x03\\x03 for backwards compatibility. The real version is sent using the extension mechanism. Client Random: Set to 32 bytes of random data. You may create random bytes using os.urandom(32) or use client_random from the current TLSContext. Session ID Provide a non-zero 32 byte Session ID value (for backwards compatibility). You may create bytes using os.urandom(32) . Cipher Suites Indicates symmetric encryption and hash combinations that are supported by the client. The TLSContext for your session contains a property named cipher_suites with a list of 2-byte cipher-suite identifiers supported by instructor-provided TLSCipher class. Compression Methods Indicates compression methods that are supported by the client. This field is included for backwards compatibility since TLS 1.3 does not support compression. The list should only include the null ( b'\\x00' ) compression method Extensions Length The main ClientHello body ends with a 2-byte length field specifying the size of the extension data that is included in this message. Extensions \u00b6 TLS uses extensions to implement functionality that may not be supported by all clients and servers. Extension syntax varies by type. To enable software to cope with extensions that are not implemented, each extension begins with its own 4-byte header made up from a 2-byte type field and a 2-byte length. In the case of TLS 1.3, extensions are also used to ensure middle box compatibility by disguising the message body as TLS 1.2. As such, all TLS 1.3 implementations are required to include specific extensions within the ClientHello. The following extensions should be included in the ClientHello: Server Name Extension (Type 0) Provides the hostname so that the server can select the correct certificates. This mechanism is frequently used with HTTPS servers. Supported Groups Extension (Type 10) Indicates which key exchange algorithms the client supports. For a minimal implementation, we will support the x25519 key exchange, which is identified by the value 0x001D . Signature Algorithm Extension (Type 13) Identifies signature algorithms that will be accepted for Certificate and CertificateVerify messages. We won't implement any signature algorithms, but we must provide a valid list. Supported Extension (Type 43) Indicates that the client is requesting a TLS 1.3 handshake. Set to the TLS 1.3 version indicator, i.e., b'\\x03\\x04' Key Share Extension (Type 51) Provides the client's public key to the server. The TLSContext for your session contains a property named public_key that is set to the byte-level representation of the public key generated for the current session. Receive Server Hello \u00b6 Once a ClientHello is properly constructed and sent by a client, a server is expected to reply with a ServerHello message in return. Breaking this message into its parts is a critical step that the client must take before it will be possible to compute encryption parameters needed to read / write any further messages. TLS Record Header Use the 5-byte header TLS record header to ensure determine the length of the message and to verify the type of message being read. For ServerHello the type should be set to 22 (handshake message) and the version will be TLS 1.2 b'\\x03\\x03' . The length should be decoded in network byte order. Handshake Header Use the 4-byte header TLS message header to verify that the handshake message is a ServerHello. To know whether you are processing a ServerHello message, verify that the type is 2. Decode the length to determine the number of bytes expected in the message. Server Version This two-byte version field will have been set to TLS 1.2 (`b'\\x03\\x03') for backwards compatibility. The real version is sent using the extension mechanism. Server Random The server will have sent 32 bytes of random data generated for this connection. You will not need to work with this data directly, but you may inspect it. Session ID For TLS 1.3, the session id is only included for compatibility with middle boxes . The server should return the value originally given in the ClientHello. Compression The server will return a 1-byte value indicating that it accepted the null compression offer made by the client. Cipher Suite The server will return a 2-byte value indicating which cipher was chosen from the options given in the ClientHello. Save this value to a variable for later use. The ServerHello message contents include a set of extensions that must be parsed individually. Every extension begins with its own 4-byte header including a 2-byte type and a 2-byte length field. You may ignore all extensions except for the following. Supported Versions Extension (Type 43) Indicates that the server agrees to a TLS 1.3 handshake when provided and set to the TLS 1.3 2-byte version ( b'\\x03\\x04' ) Key Share Extension (Type 51) Provides the server's public key which is needed to complete the key exchange. Verify that a x25519 public key (identified as 0x001d ) is included and save the value to a variable for later use. Reference \u00b6 The followiong tables are provided as a quick reference for many of the standard types/values that you'll encounter when working with TLS. TLS Record Types (encode as 1-byte integer) \u00b6 Description Value handshake 22 change cipher spec 20 application data 23 alert 21 TLS Handshake Message Types (encode as 1-byte integer) \u00b6 Description Value client hello 1 server hello 2 new session ticket 4 encrypted extensions 8 certificate 11 certificate verify 15 handshake finished 20 TLS Handshake Extension Types (encode as 1-byte integer) \u00b6 Description Value server name 0 supported groups 10 signature algorithm 13 supported versions 43 key share 51 Cipher Suites (encode bytes) \u00b6 Description Value TLS_AES_128_GCM_SHA256 {0x13,0x01} TLS_AES_256_GCM_SHA384 {0x13,0x02} TLS_CHACHA20_POLY1305_SHA256 {0x13,0x03} Signature Algorithms (encode as 2-byte integer) \u00b6 Description Value ECDSA-SECP256r1-SHA256 0x0403 ECDSA-SECP384r1-SHA384 0x0503 ECDSA-SECP521r1-SHA512 0x0603 ED25519 0x0807 ED448 0x0808 RSA-PSS-PSS-SHA256 0x0809 RSA-PSS-PSS-SHA384 0x080a RSA-PSS-PSS-SHA512 0x080b RSA-PSS-RSAE-SHA256 0x0804 RSA-PSS-RSAE-SHA384 0x0805 RSA-PSS-RSAE-SHA512 0x0806 RSA-PKCS1-SHA256 0x0401 RSA-PKCS1-SHA384 0x0501 RSA-PKCS1-SHA512 0x0601","title":"Getting Started"},{"location":"assignments/tls13/#tls-13-lab-introduction","text":"","title":"TLS 1.3 Lab Introduction"},{"location":"assignments/tls13/#overview","text":"This lab is the start of a multi-week project building a minimal HTTPS client using the TLS 1.3 protocol over TCP. The overall goal will be to complete a TLS 1.3 handshake, send a simple HTTP GET request to the course website over the encrypted channel, and process its response. With the short time remaining, you may not be able to complete the project in its entirety, but you will get plenty of hands-on experience with common protocol implementation challenges. Be aware that this is a complicated protocol. This guide is provided as a high-level reference, but we will also be providing starter code and walking through code in class. If you find yourself struggling, please review the resources and ask for help.","title":"Overview"},{"location":"assignments/tls13/#limitations","text":"Our implementation will not be feature complete or even secure on a practical level. The objective is to strip away as many unnecessary details as necessary so in order to handle data for a single HTTP request and response. The first detail that we have removed is concurrency. A non-concurrent network application is easier to reason about for a beginner because it is restricted to sequential operations and can't perform reading and writing operations at the same time. We will also ignore the following tasks that would be needed in a real TLS implementation handshake verification (security critical) certificate verification (security critical) signature verification (security critical) error handling / alerts key updates client certificates pre-shared keys session tickets","title":"Limitations"},{"location":"assignments/tls13/#cryptography","text":"Even with the these omissions, a functional TLS 1.3 implementation is still quite a challenging task due to its use of cryptography to generate keys and encrypt / decrypt application layer data. To simplify the task, the project repository includes a module named helpers.py that contains classes that will manage these more complex concerns and allow you to focus on the practical elements of communication Layer 4 - 7 communication.","title":"Cryptography"},{"location":"assignments/tls13/#resources","text":"In addition to example code and demonstrations provided in the course repository and lectures, you will need to reference resources that decompose real TLS connections. By imitating the examples, you will be able to create a working version of TLS without having to become a protocol expert in advance. The following two sites will be used extensively. The Illustrated TLS 1.3 Connection A Walkthrough of the TLS 1.3 Handshake Likewise, RFC 8446 is the definitive resource to learn more about the protocol. The Transport Layer Security (TLS) Protocol Version 1.3 (RFC 8446)","title":"Resources"},{"location":"assignments/tls13/#tasks","text":"","title":"Tasks"},{"location":"assignments/tls13/#preparation","text":"The code provided for this course relies on Python 3.9+ and one external cryptographic library. Once you've confirmed that you have the proper version of Python installed, use your preferred dependency management workflow to install the cryptography package. If you're unfamiliar with project dependency management, you can make the package available to all Python 3 code on your system by running pip3 install cryptography .","title":"Preparation"},{"location":"assignments/tls13/#create-tcp-connection","text":"Create a client-based TCP connection using the sockets library. Connecting to the requested host will initiate a TCP handshake. Before the application exits, you should close the socket.","title":"Create TCP Connection"},{"location":"assignments/tls13/#establish-tlscontext","text":"Before you get too far in the project, you will need to import the TLSContext class from the project directory and create a new context instance that'll help you manage the cryptographic aspects of your connection. The following snippet demonstrates how to initialize the context and retrieve saved properties. from helpers import TLSContext def hostname = \"info314.tcpip.dev\" # Create a new context tls = TLSContext ( hostname = hostname ) # Generate client_random, private_key, and public_key tls . generate_handshake_parameters () # Inspect values that your handshake code will rely on print ( f \" { tls . hostname =} \" ) print ( f \" { tls . client_random . hex ( ' ' ) =} \" ) print ( f \" { tls . public_key . hex ( ' ' ) =} \" ) print ( f \" { tls . cipher_suites =} \" ) print ( f \" { tls . signature_algorithms =} \" )","title":"Establish TLSContext"},{"location":"assignments/tls13/#begin-tls-handshake","text":"In this assignment, you will focus on generating/sending a ClientHello message and processing the ServerHello message that is sent back in response.","title":"Begin TLS Handshake"},{"location":"assignments/tls13/#send-client-hello","text":"Build and send an unencrypted record containing ClientHello message. The ClientHello message initiates the TLS handshake and provides an initial set of parameters that the server can use to determine the capabilities of the client and compute a shared secret. Be aware that the ClientHello for TLS 1.3 is disguised to appear as an earlier version of the protocol to avoid problems with legacy middle boxes . To complete this disguise, TLS 1.3 will outwardly present TLS 1.2 and also include certain fields that don't provide any function in TLS 1.3.","title":"Send Client Hello"},{"location":"assignments/tls13/#record-and-handshake-headers","text":"As a rather complex protocol, TLS uses multiple layers of messages headers to communicate message structure to software. When we send the ClientHello message on the network, it will require the following parts: TLS Record Header Every TLS message is encoded as a record with a 5-byte header, including a 1-byte record type, a 2-byte protocol version, and a 2-byte length field. The ClientHello record header sets the type to 22 for handshake message and sets the version to TLS 1.0 b'\\x03\\x01' . The length is encoded in network byte order and excludes the 5-bytes of record header. Handshake Header Every TLS handshake message will also have a 4-byte header, including a 1-byte message type and a 3-byte length field. The ClientHello message sets the type to 1. The length is encoded in network byte order and excludes the length of the record and handshake headers.","title":"Record and Handshake Headers"},{"location":"assignments/tls13/#core-message-structure","text":"Each message type prescribes specific requirements for the structure of its messages. The following fields make up the payload of the ClientHello message. Client Version The ClientHello version field is a two-byte field set to TLS 1.2 b'\\x03\\x03 for backwards compatibility. The real version is sent using the extension mechanism. Client Random: Set to 32 bytes of random data. You may create random bytes using os.urandom(32) or use client_random from the current TLSContext. Session ID Provide a non-zero 32 byte Session ID value (for backwards compatibility). You may create bytes using os.urandom(32) . Cipher Suites Indicates symmetric encryption and hash combinations that are supported by the client. The TLSContext for your session contains a property named cipher_suites with a list of 2-byte cipher-suite identifiers supported by instructor-provided TLSCipher class. Compression Methods Indicates compression methods that are supported by the client. This field is included for backwards compatibility since TLS 1.3 does not support compression. The list should only include the null ( b'\\x00' ) compression method Extensions Length The main ClientHello body ends with a 2-byte length field specifying the size of the extension data that is included in this message.","title":"Core Message Structure"},{"location":"assignments/tls13/#extensions","text":"TLS uses extensions to implement functionality that may not be supported by all clients and servers. Extension syntax varies by type. To enable software to cope with extensions that are not implemented, each extension begins with its own 4-byte header made up from a 2-byte type field and a 2-byte length. In the case of TLS 1.3, extensions are also used to ensure middle box compatibility by disguising the message body as TLS 1.2. As such, all TLS 1.3 implementations are required to include specific extensions within the ClientHello. The following extensions should be included in the ClientHello: Server Name Extension (Type 0) Provides the hostname so that the server can select the correct certificates. This mechanism is frequently used with HTTPS servers. Supported Groups Extension (Type 10) Indicates which key exchange algorithms the client supports. For a minimal implementation, we will support the x25519 key exchange, which is identified by the value 0x001D . Signature Algorithm Extension (Type 13) Identifies signature algorithms that will be accepted for Certificate and CertificateVerify messages. We won't implement any signature algorithms, but we must provide a valid list. Supported Extension (Type 43) Indicates that the client is requesting a TLS 1.3 handshake. Set to the TLS 1.3 version indicator, i.e., b'\\x03\\x04' Key Share Extension (Type 51) Provides the client's public key to the server. The TLSContext for your session contains a property named public_key that is set to the byte-level representation of the public key generated for the current session.","title":"Extensions"},{"location":"assignments/tls13/#receive-server-hello","text":"Once a ClientHello is properly constructed and sent by a client, a server is expected to reply with a ServerHello message in return. Breaking this message into its parts is a critical step that the client must take before it will be possible to compute encryption parameters needed to read / write any further messages. TLS Record Header Use the 5-byte header TLS record header to ensure determine the length of the message and to verify the type of message being read. For ServerHello the type should be set to 22 (handshake message) and the version will be TLS 1.2 b'\\x03\\x03' . The length should be decoded in network byte order. Handshake Header Use the 4-byte header TLS message header to verify that the handshake message is a ServerHello. To know whether you are processing a ServerHello message, verify that the type is 2. Decode the length to determine the number of bytes expected in the message. Server Version This two-byte version field will have been set to TLS 1.2 (`b'\\x03\\x03') for backwards compatibility. The real version is sent using the extension mechanism. Server Random The server will have sent 32 bytes of random data generated for this connection. You will not need to work with this data directly, but you may inspect it. Session ID For TLS 1.3, the session id is only included for compatibility with middle boxes . The server should return the value originally given in the ClientHello. Compression The server will return a 1-byte value indicating that it accepted the null compression offer made by the client. Cipher Suite The server will return a 2-byte value indicating which cipher was chosen from the options given in the ClientHello. Save this value to a variable for later use. The ServerHello message contents include a set of extensions that must be parsed individually. Every extension begins with its own 4-byte header including a 2-byte type and a 2-byte length field. You may ignore all extensions except for the following. Supported Versions Extension (Type 43) Indicates that the server agrees to a TLS 1.3 handshake when provided and set to the TLS 1.3 2-byte version ( b'\\x03\\x04' ) Key Share Extension (Type 51) Provides the server's public key which is needed to complete the key exchange. Verify that a x25519 public key (identified as 0x001d ) is included and save the value to a variable for later use.","title":"Receive Server Hello"},{"location":"assignments/tls13/#reference","text":"The followiong tables are provided as a quick reference for many of the standard types/values that you'll encounter when working with TLS.","title":"Reference"},{"location":"assignments/tls13/#tls-record-types-encode-as-1-byte-integer","text":"Description Value handshake 22 change cipher spec 20 application data 23 alert 21","title":"TLS Record Types (encode as 1-byte integer)"},{"location":"assignments/tls13/#tls-handshake-message-types-encode-as-1-byte-integer","text":"Description Value client hello 1 server hello 2 new session ticket 4 encrypted extensions 8 certificate 11 certificate verify 15 handshake finished 20","title":"TLS Handshake Message Types (encode as 1-byte integer)"},{"location":"assignments/tls13/#tls-handshake-extension-types-encode-as-1-byte-integer","text":"Description Value server name 0 supported groups 10 signature algorithm 13 supported versions 43 key share 51","title":"TLS Handshake Extension Types (encode as 1-byte integer)"},{"location":"assignments/tls13/#cipher-suites-encode-bytes","text":"Description Value TLS_AES_128_GCM_SHA256 {0x13,0x01} TLS_AES_256_GCM_SHA384 {0x13,0x02} TLS_CHACHA20_POLY1305_SHA256 {0x13,0x03}","title":"Cipher Suites (encode bytes)"},{"location":"assignments/tls13/#signature-algorithms-encode-as-2-byte-integer","text":"Description Value ECDSA-SECP256r1-SHA256 0x0403 ECDSA-SECP384r1-SHA384 0x0503 ECDSA-SECP521r1-SHA512 0x0603 ED25519 0x0807 ED448 0x0808 RSA-PSS-PSS-SHA256 0x0809 RSA-PSS-PSS-SHA384 0x080a RSA-PSS-PSS-SHA512 0x080b RSA-PSS-RSAE-SHA256 0x0804 RSA-PSS-RSAE-SHA384 0x0805 RSA-PSS-RSAE-SHA512 0x0806 RSA-PKCS1-SHA256 0x0401 RSA-PKCS1-SHA384 0x0501 RSA-PKCS1-SHA512 0x0601","title":"Signature Algorithms (encode as 2-byte integer)"},{"location":"assignments/vlan-challenge/","text":"VLAN Challenge (last edited 2020-02-06) \u00b6 Overview \u00b6 The objective of this assignment is to determine a VLAN strategy and port configuration that overlays the given routing topology onto a managed 8-port switch. The routing topology that you will be working with in this challenge is representative of the topology used in our final, group project. In this topology, we have three autonomous systems, i.e., networks that are managed independently from one another. Each of our three routers serves a group of local users via a LAN segment in addition to being connected to external networks via point-to-point routing links. The network positioned at the top of the diagram will function as an Internet Service Provider (ISP) for the other networks networks, routing traffic between them and other groups within the class. The links between routers are known as routing links. Each one represents a separate point-to-point network over which the routers will forward messages and share information about the inter-network topology. Instructions \u00b6 Identify broadcast domains \u00b6 Identify the distinct broadcast domains in the system and assign a different VLAN label (between 2 and 4094) to each of these network segments. Define physical connections \u00b6 Assign each physical connection to a port on the switch. Since the topology is determined by port configuration, you will need to keep track of which device and network interface is associated with each port. Choose an order that is easy to remember. Create port configurations \u00b6 Once you have identified the VLANs and mapped ports to physical topology, you can begin to define the port configurations. For each port, you will define a native VLAN (untagged) and zero or more tagged VLANs. A port can have both types of VLANs associated with it, though there can only be one native VLAN configured for any port. Untagged ethernet frames received on a port will be mapped internally to the native VLAN of the port and can only be forwarded (or flooded) through links attached to ports that are configured with the same VLAN (tagged or untagged). When a VLAN is configured to be tagged on a specific port, that port will add a VLAN identifier to outgoing frames and read/remove the identifiers from incoming frames. Adding a tagged VLAN to a port creates a trunk. Trunk links expect the same tag configuration on both ends of the link, i.e., they require explicit configuration on both sides of the trunk. Ports without any tagged VLANs are called access ports. These are preferred for most applications since the VLAN configuration will be encapsulated within the switch and transparent to users. LAN connections \u00b6 For simplicity, start the process by defining the port configurations for a single broadcast domain associated with one of the LANs in the topology, e.g., LAN A. Pay close attention to the requirements given in the next section, which state that LAN connections to A, B, and C should be accessible without tagging. Routing links \u00b6 Once you have completed the configuration for independent LANs, turn your attention to the routing links between the LANs. Update the configuration for each side of the routing link (two physical ports) with the appropriate VLAN configurations. Uplink \u00b6 Finally, turn your attention to the connection that forms the uplink to the core network for the class. The uplink is a routing link, and it is configured in much the same manner as the other routing links in our topology. However, pay close attention to the assignment specifications and the implications for the final port configuration. Specifications \u00b6 In addition to the following the given network layer topology, please align your VLAN strategy with requirements below: Layer-3 Network Diagram Example Physical Diagram Access links to general LANs \u00b6 LANs A, B, and C are general purpose networks and should be exposed as untagged VLANs. This enables us to alternate seamlessly between a direct connect from our laptop to Pi and a connection that runs through the switch. If we were to rely on tagged VLANs to access a given LAN, you would need to configure VLANs on your laptop in order to connect directly to the Pi. Tagged Routing Links \u00b6 Routing links may rely on tagged VLANs. The router will connect to these VLANs via virtual network interfaces that are configured to exchange tagged Ethernet traffic rather than standard, untagged frames. The router side of this configuration is beyond the scope of this exercise. Untagged Uplink Connection \u00b6 The remote end of the uplink connection will be untagged. Make sure that you configure the associated port accordingly. Eliminate Extraneous Connections \u00b6 For each port, only expose the VLANs that are necessary to satisfy the routing requirements indicated in the diagram. Adding additional VLANs creates unintended paths for communication, e.g., allowing Laptop A to communicate directly with Laptop B. For the purposes of this assignment, treat this sort of unintended pathway as a security exposure.","title":"VLAN Challenge (last edited 2020-02-06)"},{"location":"assignments/vlan-challenge/#vlan-challenge-last-edited-2020-02-06","text":"","title":"VLAN Challenge (last edited 2020-02-06)"},{"location":"assignments/vlan-challenge/#overview","text":"The objective of this assignment is to determine a VLAN strategy and port configuration that overlays the given routing topology onto a managed 8-port switch. The routing topology that you will be working with in this challenge is representative of the topology used in our final, group project. In this topology, we have three autonomous systems, i.e., networks that are managed independently from one another. Each of our three routers serves a group of local users via a LAN segment in addition to being connected to external networks via point-to-point routing links. The network positioned at the top of the diagram will function as an Internet Service Provider (ISP) for the other networks networks, routing traffic between them and other groups within the class. The links between routers are known as routing links. Each one represents a separate point-to-point network over which the routers will forward messages and share information about the inter-network topology.","title":"Overview"},{"location":"assignments/vlan-challenge/#instructions","text":"","title":"Instructions"},{"location":"assignments/vlan-challenge/#identify-broadcast-domains","text":"Identify the distinct broadcast domains in the system and assign a different VLAN label (between 2 and 4094) to each of these network segments.","title":"Identify broadcast domains"},{"location":"assignments/vlan-challenge/#define-physical-connections","text":"Assign each physical connection to a port on the switch. Since the topology is determined by port configuration, you will need to keep track of which device and network interface is associated with each port. Choose an order that is easy to remember.","title":"Define physical connections"},{"location":"assignments/vlan-challenge/#create-port-configurations","text":"Once you have identified the VLANs and mapped ports to physical topology, you can begin to define the port configurations. For each port, you will define a native VLAN (untagged) and zero or more tagged VLANs. A port can have both types of VLANs associated with it, though there can only be one native VLAN configured for any port. Untagged ethernet frames received on a port will be mapped internally to the native VLAN of the port and can only be forwarded (or flooded) through links attached to ports that are configured with the same VLAN (tagged or untagged). When a VLAN is configured to be tagged on a specific port, that port will add a VLAN identifier to outgoing frames and read/remove the identifiers from incoming frames. Adding a tagged VLAN to a port creates a trunk. Trunk links expect the same tag configuration on both ends of the link, i.e., they require explicit configuration on both sides of the trunk. Ports without any tagged VLANs are called access ports. These are preferred for most applications since the VLAN configuration will be encapsulated within the switch and transparent to users.","title":"Create port configurations"},{"location":"assignments/vlan-challenge/#lan-connections","text":"For simplicity, start the process by defining the port configurations for a single broadcast domain associated with one of the LANs in the topology, e.g., LAN A. Pay close attention to the requirements given in the next section, which state that LAN connections to A, B, and C should be accessible without tagging.","title":"LAN connections"},{"location":"assignments/vlan-challenge/#routing-links","text":"Once you have completed the configuration for independent LANs, turn your attention to the routing links between the LANs. Update the configuration for each side of the routing link (two physical ports) with the appropriate VLAN configurations.","title":"Routing links"},{"location":"assignments/vlan-challenge/#uplink","text":"Finally, turn your attention to the connection that forms the uplink to the core network for the class. The uplink is a routing link, and it is configured in much the same manner as the other routing links in our topology. However, pay close attention to the assignment specifications and the implications for the final port configuration.","title":"Uplink"},{"location":"assignments/vlan-challenge/#specifications","text":"In addition to the following the given network layer topology, please align your VLAN strategy with requirements below: Layer-3 Network Diagram Example Physical Diagram","title":"Specifications"},{"location":"assignments/vlan-challenge/#access-links-to-general-lans","text":"LANs A, B, and C are general purpose networks and should be exposed as untagged VLANs. This enables us to alternate seamlessly between a direct connect from our laptop to Pi and a connection that runs through the switch. If we were to rely on tagged VLANs to access a given LAN, you would need to configure VLANs on your laptop in order to connect directly to the Pi.","title":"Access links to general LANs"},{"location":"assignments/vlan-challenge/#tagged-routing-links","text":"Routing links may rely on tagged VLANs. The router will connect to these VLANs via virtual network interfaces that are configured to exchange tagged Ethernet traffic rather than standard, untagged frames. The router side of this configuration is beyond the scope of this exercise.","title":"Tagged Routing Links"},{"location":"assignments/vlan-challenge/#untagged-uplink-connection","text":"The remote end of the uplink connection will be untagged. Make sure that you configure the associated port accordingly.","title":"Untagged Uplink Connection"},{"location":"assignments/vlan-challenge/#eliminate-extraneous-connections","text":"For each port, only expose the VLANs that are necessary to satisfy the routing requirements indicated in the diagram. Adding additional VLANs creates unintended paths for communication, e.g., allowing Laptop A to communicate directly with Laptop B. For the purposes of this assignment, treat this sort of unintended pathway as a security exposure.","title":"Eliminate Extraneous Connections"},{"location":"assignments/wireshark01/","text":"Analyzing DHCP and ARP with Wireshark \u00b6 Lab 1 Assignment page on Canvas Overview \u00b6 The purpose of this lab is for students to get familiar with basic functionalities of Wireshark, and to be able to capture and analyze network traffic. There will be multiple correct ways to complete this lab, we highly recommend using search engines to help you find solutions. Introduction to Wireshark \u00b6 Wireshark is a tool designed to record and observe the messages that are sent over a network and to provide an analyst with tools to understand and troubleshoot the protocols associated with those messages. Starting a Capture \u00b6 Open Wireshark and locate the Capture section of the launch screen. This section contains an input field for configuring capture filters and a list of physical and virtual interfaces that can be used to capture packets. To the right of each interface, you should notice an animated \u201csparkline\u201d which indicates the level of activity on the associated network. You can launch a capture on your active interface (likely Wi-Fi or Ethernet) by double-clicking on the respective label. If a capture filter was specified before you selected the interface, Wireshark ignores any packets that don't match the filter. If the filter input is empty, Wireshark records everything it sees on the wire. Recording continues until you press the stop icon in the top toolbar or close the application. Exploring a Capture \u00b6 By default, Wireshark will divide capture-related content among three panes: Packet List Packet Details Packet Bytes The Packet List displays all packets in the current capture, summarizing important details about traffic flow and the type of data contained in the packet. The Packet Details view initially displays a layered summary of the protocols represented in the selected packet. A more detailed view of each protocol can be explored by clicking the arrow icons to the left of the summary. The order of the protocols in this view corresponds to the order in which each protocol\u2019s header appears in the data frame. The Packet Bytes pane can be useful for understanding the basic structure of raw network messages. As you navigate through the details in this view, Wireshark will highlight the corresponding bytes in the Packet Bytes pane. Narrowing your Search \u00b6 If you have any software, particularly a web browser, running in the background, you'll notice that Wireshark can quickly accumulate a large list of packets. Fortunately, the software provides a variety of tools to help you more easily locate packets relevant to your search. The packet list can be modified non-destructively by adding/removing display filters 1 in the input field below the top toolbar. Display filters are a valuable analytic tool that allows you to remove noise and quickly focus on packets that match certain criteria. In addition to writing your own display filters, you can access a variety of context-specific analysis tools by right clicking on any row of the Packet List or a field within the Packet Details pane. These tools can help you create a display filter based on the current packet or to investigate a conversation that spans multiple packets. Instructions \u00b6 DHCP \u00b6 Setup \u00b6 Stop any ongoing captures and configure a new capture on your wireless interface with capture filter arp || udp portrange 67-68 . This filter will prevent Wireshark from capturing excessive amounts of traffic so that we can leave the capture running for the entire lab. While our current capture should be fairly quiet owing to the previous capture filter, create a display filter to further reduce the number of visible packets (Hint: Type dhcp into the display filter input below the main wireshark toolbar). At the end of the lab, save your capture and submit it with your assignment. Request a new DHCP Lease \u00b6 In order to properly complete this lab, you will need to terminate your current DHCP lease so that you can capture the process of DHCP initializing your network interface. This process will differ depending on your OS. Follow the instructions linked on the resources site to complete this process. Report \u00b6 Based on your capture, create an outline of your complete DHCP exchange. For each message: Include a screenshot of the packet details summary. Include a brief written summary, identifying: DHCP message type, DHCP transaction ID, source and destination Ethernet addresses, source and destination IP addresses, and UDP source and destination UDP ports associated. How can you determine which messages were sent by your own device versus the DHCP server? Based on the outline you created above, determine the purpose of the 0.0.0.0 address appearing within the DHCP exchange. What Ethernet-layer (Layer 2) address corresponds to the 255.255.255.255 (Layer 3) IP address? Using online resources as necessary, determine the purpose of these special addresses. Which of the fields that you have observed can be used to distinguish between different conversations between the same client and server? If you look closely at the packet details for each message, you'll notice that each DHCP message contains a variety of options. In DHCP, options allow DHCP clients and servers to adapt the protocol to their own needs. Like many other protocols, DHCP encodes options as a type , a length , and a value . Based on this structure, we can continue to extend the protocol without needing to change the basic foundation. Using your search engine of choice, identify the IETF RFC (# and name) that defines the common option types for the DHCP protocol. Which DHCP Option (#) tells us the DHCP message type? How many bytes are required to encode the type? Which DHCP Option (#) tells us the length of a DHCP lease? How many bytes are required to encode the duration of the lease? According to the RFC, is it possible to specify the lease length in any unit of time other than seconds? Compare the Lease Time option of the Discover message with the value in the Offer message. Did your device request a particular duration? If so, did the server honor this request? Using online resources as needed, determine what happens at the end of a DHCP address lease. Based on the order of the messages in the capture and the details we've asked you to examine, offer an explanation of how the DHCP protocol works to configure your network interface with appropriate settings. How does the protocol make use of Ethernet and IP broadcast functionality, and why is that important? Use your capture to illustrate your point. ARP \u00b6 Setup \u00b6 You may continue to use the same capture for this section. If you launch a new capture, please save the first capture and submit both with your assignment. Before you begin the analysis questions, clear the ARP cache per instructions linked on the resources site and generate some Internet traffic, e.g., browse the web. Remove any existing display filters and create a new filter that will only show ARP related traffic. (Hint: type arp in the display filter input). Report \u00b6 Outline a complete ARP exchange (request and response). For each message: Include a screenshot of the packet details summary. Include a brief written summary, identifying: ARP Opcode, Sender and Target Ethernet addresses, Sender and Target IP addresses. Identify the 48-bit hardware address associated with your network interface and use this information to specify which message(s) originated from your local device? Determine which messages are sent to a broadcast destination. Why do you think the ARP protocol makes use of the broadcast destination? Aside from the broadcast address, what other differences do you notice between the contents of ARP requests and replies? Spend a moment comparing the overall packet structure (as seen in the Packet Details view) between DHCP and ARP. Identify any layers that are present in one protocol but not in the other. In order for a network message to be considered an IP packet, the message must contain an Internet Protocol layer that includes an IP header for the rest of the message. Does the ARP protocol use IP packets to communicate? Describe in your own words how ARP works to allow hosts to communicate in a Layer-2 network based on IP address. Use your capture to illustrate your points. Do not confuse display filters and capture filters. They serve very different purposes and even use distinct syntax. \u21a9","title":"Analyze DHCP and ARP with Wireshark"},{"location":"assignments/wireshark01/#analyzing-dhcp-and-arp-with-wireshark","text":"Lab 1 Assignment page on Canvas","title":"Analyzing DHCP and ARP with Wireshark"},{"location":"assignments/wireshark01/#overview","text":"The purpose of this lab is for students to get familiar with basic functionalities of Wireshark, and to be able to capture and analyze network traffic. There will be multiple correct ways to complete this lab, we highly recommend using search engines to help you find solutions.","title":"Overview"},{"location":"assignments/wireshark01/#introduction-to-wireshark","text":"Wireshark is a tool designed to record and observe the messages that are sent over a network and to provide an analyst with tools to understand and troubleshoot the protocols associated with those messages.","title":"Introduction to Wireshark"},{"location":"assignments/wireshark01/#starting-a-capture","text":"Open Wireshark and locate the Capture section of the launch screen. This section contains an input field for configuring capture filters and a list of physical and virtual interfaces that can be used to capture packets. To the right of each interface, you should notice an animated \u201csparkline\u201d which indicates the level of activity on the associated network. You can launch a capture on your active interface (likely Wi-Fi or Ethernet) by double-clicking on the respective label. If a capture filter was specified before you selected the interface, Wireshark ignores any packets that don't match the filter. If the filter input is empty, Wireshark records everything it sees on the wire. Recording continues until you press the stop icon in the top toolbar or close the application.","title":"Starting a Capture"},{"location":"assignments/wireshark01/#exploring-a-capture","text":"By default, Wireshark will divide capture-related content among three panes: Packet List Packet Details Packet Bytes The Packet List displays all packets in the current capture, summarizing important details about traffic flow and the type of data contained in the packet. The Packet Details view initially displays a layered summary of the protocols represented in the selected packet. A more detailed view of each protocol can be explored by clicking the arrow icons to the left of the summary. The order of the protocols in this view corresponds to the order in which each protocol\u2019s header appears in the data frame. The Packet Bytes pane can be useful for understanding the basic structure of raw network messages. As you navigate through the details in this view, Wireshark will highlight the corresponding bytes in the Packet Bytes pane.","title":"Exploring a Capture"},{"location":"assignments/wireshark01/#narrowing-your-search","text":"If you have any software, particularly a web browser, running in the background, you'll notice that Wireshark can quickly accumulate a large list of packets. Fortunately, the software provides a variety of tools to help you more easily locate packets relevant to your search. The packet list can be modified non-destructively by adding/removing display filters 1 in the input field below the top toolbar. Display filters are a valuable analytic tool that allows you to remove noise and quickly focus on packets that match certain criteria. In addition to writing your own display filters, you can access a variety of context-specific analysis tools by right clicking on any row of the Packet List or a field within the Packet Details pane. These tools can help you create a display filter based on the current packet or to investigate a conversation that spans multiple packets.","title":"Narrowing your Search"},{"location":"assignments/wireshark01/#instructions","text":"","title":"Instructions"},{"location":"assignments/wireshark01/#dhcp","text":"","title":"DHCP"},{"location":"assignments/wireshark01/#setup","text":"Stop any ongoing captures and configure a new capture on your wireless interface with capture filter arp || udp portrange 67-68 . This filter will prevent Wireshark from capturing excessive amounts of traffic so that we can leave the capture running for the entire lab. While our current capture should be fairly quiet owing to the previous capture filter, create a display filter to further reduce the number of visible packets (Hint: Type dhcp into the display filter input below the main wireshark toolbar). At the end of the lab, save your capture and submit it with your assignment.","title":"Setup"},{"location":"assignments/wireshark01/#request-a-new-dhcp-lease","text":"In order to properly complete this lab, you will need to terminate your current DHCP lease so that you can capture the process of DHCP initializing your network interface. This process will differ depending on your OS. Follow the instructions linked on the resources site to complete this process.","title":"Request a new DHCP Lease"},{"location":"assignments/wireshark01/#report","text":"Based on your capture, create an outline of your complete DHCP exchange. For each message: Include a screenshot of the packet details summary. Include a brief written summary, identifying: DHCP message type, DHCP transaction ID, source and destination Ethernet addresses, source and destination IP addresses, and UDP source and destination UDP ports associated. How can you determine which messages were sent by your own device versus the DHCP server? Based on the outline you created above, determine the purpose of the 0.0.0.0 address appearing within the DHCP exchange. What Ethernet-layer (Layer 2) address corresponds to the 255.255.255.255 (Layer 3) IP address? Using online resources as necessary, determine the purpose of these special addresses. Which of the fields that you have observed can be used to distinguish between different conversations between the same client and server? If you look closely at the packet details for each message, you'll notice that each DHCP message contains a variety of options. In DHCP, options allow DHCP clients and servers to adapt the protocol to their own needs. Like many other protocols, DHCP encodes options as a type , a length , and a value . Based on this structure, we can continue to extend the protocol without needing to change the basic foundation. Using your search engine of choice, identify the IETF RFC (# and name) that defines the common option types for the DHCP protocol. Which DHCP Option (#) tells us the DHCP message type? How many bytes are required to encode the type? Which DHCP Option (#) tells us the length of a DHCP lease? How many bytes are required to encode the duration of the lease? According to the RFC, is it possible to specify the lease length in any unit of time other than seconds? Compare the Lease Time option of the Discover message with the value in the Offer message. Did your device request a particular duration? If so, did the server honor this request? Using online resources as needed, determine what happens at the end of a DHCP address lease. Based on the order of the messages in the capture and the details we've asked you to examine, offer an explanation of how the DHCP protocol works to configure your network interface with appropriate settings. How does the protocol make use of Ethernet and IP broadcast functionality, and why is that important? Use your capture to illustrate your point.","title":"Report"},{"location":"assignments/wireshark01/#arp","text":"","title":"ARP"},{"location":"assignments/wireshark01/#setup_1","text":"You may continue to use the same capture for this section. If you launch a new capture, please save the first capture and submit both with your assignment. Before you begin the analysis questions, clear the ARP cache per instructions linked on the resources site and generate some Internet traffic, e.g., browse the web. Remove any existing display filters and create a new filter that will only show ARP related traffic. (Hint: type arp in the display filter input).","title":"Setup"},{"location":"assignments/wireshark01/#report_1","text":"Outline a complete ARP exchange (request and response). For each message: Include a screenshot of the packet details summary. Include a brief written summary, identifying: ARP Opcode, Sender and Target Ethernet addresses, Sender and Target IP addresses. Identify the 48-bit hardware address associated with your network interface and use this information to specify which message(s) originated from your local device? Determine which messages are sent to a broadcast destination. Why do you think the ARP protocol makes use of the broadcast destination? Aside from the broadcast address, what other differences do you notice between the contents of ARP requests and replies? Spend a moment comparing the overall packet structure (as seen in the Packet Details view) between DHCP and ARP. Identify any layers that are present in one protocol but not in the other. In order for a network message to be considered an IP packet, the message must contain an Internet Protocol layer that includes an IP header for the rest of the message. Does the ARP protocol use IP packets to communicate? Describe in your own words how ARP works to allow hosts to communicate in a Layer-2 network based on IP address. Use your capture to illustrate your points. Do not confuse display filters and capture filters. They serve very different purposes and even use distinct syntax. \u21a9","title":"Report"},{"location":"assignments/wireshark02/","text":"Lab 2 - Analyze DNS & HTTP in Wireshark \u00b6 Lab 2 Assignment page on Canvas Overview \u00b6 The purpose of this lab is for students to gain hands on experience with DNS. By the end of the lab you will be familiar with: dig (or PowerShell's Resolve-DnsName command) DNS queries security faults of DNS We highly recommend using search engines to help you find solutions. As usual, there will be multiple ways to complete this lab. Please use the template provided on Canvas under the Assignment \"Lab 2 - Analyze DNS & HTTP in Wireshark\" to complete your lab report. Part I - website \u00b6 Pick a popular website that has a lot of content on it. Ideally it should contain advertisements. You will be using it throughout this lab. Report : What website did you select? Part II - dig \u00b6 Before jumping into more complicated scenarios we would like you to learn how to use the dig command as it is an incredibly helpful and simple tool. We've provided some resources at Perform DNS Loookups Manually to help you get started. Use dig to lookup the domain name of the website you selected. Open up a new tab in your browser and enter (one of) the IP address(es) returned by dig to discover where it will take you. If dig returned more than one address, open up a second tab and enter it now. Note Don't panic if you receive an error instead of a live site. Some servers host more than one website and need the name to help route you to the right place. Try another site, e.g., uw.edu, and see if you get different results. Report : What addresses did the dig command return? Copy dig results to your report (code block or screenshot). What did you observe when you browsed to the IP addresses directly? Aside from A records containing IP addresses, did you discover any other DNS records from your query? List at least 3 other record types that DNS manages (use Google to look up other kinds of records if your query returned less than 3 types!) Look closely at the output of the dig command. How can you be sure that the query completed successfully? Identify the IP address of the server used to handle your query. If you used PowerShell's Resolve-DnsName then you won't see the server IP that answered your request. Instead use ipconfig /all and find the IP under DNS Servers under your network interface. Part III - dev tools \u00b6 Open up a new tab preferably in a chromium based browser (Chrome, Brave, etc...). Open up the dev tools (right click on page and click Inspect), and go to the Network option. In that very same tab paste in your selected web page into the URL bar and click enter. You should see all of the GET and POST requests that the browser made for that webpage load up in the dev tools. Right-click the header of the Network Log table and select Domain. The domain of each resource is now shown. Take some time to scroll through the domains, files, and file types your website was requesting. Report : From a quick glance what is the most common file type requested? Approximately how many domains do you see in that list that don't matchup with the website domain you initially visited? Why do you think this page is getting information from other websites? If you had to guess, how many DNS requests do you think were sent in order to fully load this page? Part IV - wireshark \u00b6 Before examining DNS requests in Wireshark you will want to clear your DNS cache. Instructions on what that means, what it's for, and how to do so can be found here . Create a capture of you visiting your website by: Open Wireshark, begin a capture Quickly open a new tab and visit your website in your browser Once it has fully loaded end your Wireshark capture. Now filter for DNS packets only in the display filter. Identify the DNS response containing the information you needed in order to convert your website name into an IP address. Use the information contained within that packet for the following deliverable. Hint Learn how to use the search tool to find string content or research display filters that allow you to specify the domain name. Report : Assuming almost all of the DNS requests you see in Wireshark right now are for the one website you visited, how many DNS requests do you see? Overall were there less or more DNS queries than you'd expect? How did you identify the DNS packet(s) associated with the website you visited? Provide screenshots of the packet(s) (specifically of the DNS information in Packet Details). List the ip addresses you received for the website from the DNS server that resolved your request. Which transport layer protocol (think OSI model) is used to carry the DNS packet? Compare this DNS response to others in the capture (generate more if needed). Which port number(s) are shared in common across these DNS requests? Part V - security \u00b6 Open two packets in bytes view, a dns and a http packet that is encrypted with tls. Double click one of the DNS packets in order to be able to see the bytes view. Remove the dns display filter and replace it with tls (web traffic). Open one of the tls packets in byte view too. Report : Examine the bytes view of the two packets. Do you see any human readable values in the output? Looking at these two packets and others in your capture, does Wireshark provide any clues about whether or not your DNS is encrypted? Does it provide any clues on whether your web traffic is encrypted? Attacker: What information might an outside observer be able to glean about your computing activities by capturing your DNS traffic? Was any discernible information revealed (as far as you can tell) through your web traffic?","title":"Analyze DNS & HTTP in Wireshark"},{"location":"assignments/wireshark02/#lab-2-analyze-dns-http-in-wireshark","text":"Lab 2 Assignment page on Canvas","title":"Lab 2 - Analyze DNS &amp; HTTP in Wireshark"},{"location":"assignments/wireshark02/#overview","text":"The purpose of this lab is for students to gain hands on experience with DNS. By the end of the lab you will be familiar with: dig (or PowerShell's Resolve-DnsName command) DNS queries security faults of DNS We highly recommend using search engines to help you find solutions. As usual, there will be multiple ways to complete this lab. Please use the template provided on Canvas under the Assignment \"Lab 2 - Analyze DNS & HTTP in Wireshark\" to complete your lab report.","title":"Overview"},{"location":"assignments/wireshark02/#part-i-website","text":"Pick a popular website that has a lot of content on it. Ideally it should contain advertisements. You will be using it throughout this lab. Report : What website did you select?","title":"Part I - website"},{"location":"assignments/wireshark02/#part-ii-dig","text":"Before jumping into more complicated scenarios we would like you to learn how to use the dig command as it is an incredibly helpful and simple tool. We've provided some resources at Perform DNS Loookups Manually to help you get started. Use dig to lookup the domain name of the website you selected. Open up a new tab in your browser and enter (one of) the IP address(es) returned by dig to discover where it will take you. If dig returned more than one address, open up a second tab and enter it now. Note Don't panic if you receive an error instead of a live site. Some servers host more than one website and need the name to help route you to the right place. Try another site, e.g., uw.edu, and see if you get different results. Report : What addresses did the dig command return? Copy dig results to your report (code block or screenshot). What did you observe when you browsed to the IP addresses directly? Aside from A records containing IP addresses, did you discover any other DNS records from your query? List at least 3 other record types that DNS manages (use Google to look up other kinds of records if your query returned less than 3 types!) Look closely at the output of the dig command. How can you be sure that the query completed successfully? Identify the IP address of the server used to handle your query. If you used PowerShell's Resolve-DnsName then you won't see the server IP that answered your request. Instead use ipconfig /all and find the IP under DNS Servers under your network interface.","title":"Part II - dig"},{"location":"assignments/wireshark02/#part-iii-dev-tools","text":"Open up a new tab preferably in a chromium based browser (Chrome, Brave, etc...). Open up the dev tools (right click on page and click Inspect), and go to the Network option. In that very same tab paste in your selected web page into the URL bar and click enter. You should see all of the GET and POST requests that the browser made for that webpage load up in the dev tools. Right-click the header of the Network Log table and select Domain. The domain of each resource is now shown. Take some time to scroll through the domains, files, and file types your website was requesting. Report : From a quick glance what is the most common file type requested? Approximately how many domains do you see in that list that don't matchup with the website domain you initially visited? Why do you think this page is getting information from other websites? If you had to guess, how many DNS requests do you think were sent in order to fully load this page?","title":"Part III - dev tools"},{"location":"assignments/wireshark02/#part-iv-wireshark","text":"Before examining DNS requests in Wireshark you will want to clear your DNS cache. Instructions on what that means, what it's for, and how to do so can be found here . Create a capture of you visiting your website by: Open Wireshark, begin a capture Quickly open a new tab and visit your website in your browser Once it has fully loaded end your Wireshark capture. Now filter for DNS packets only in the display filter. Identify the DNS response containing the information you needed in order to convert your website name into an IP address. Use the information contained within that packet for the following deliverable. Hint Learn how to use the search tool to find string content or research display filters that allow you to specify the domain name. Report : Assuming almost all of the DNS requests you see in Wireshark right now are for the one website you visited, how many DNS requests do you see? Overall were there less or more DNS queries than you'd expect? How did you identify the DNS packet(s) associated with the website you visited? Provide screenshots of the packet(s) (specifically of the DNS information in Packet Details). List the ip addresses you received for the website from the DNS server that resolved your request. Which transport layer protocol (think OSI model) is used to carry the DNS packet? Compare this DNS response to others in the capture (generate more if needed). Which port number(s) are shared in common across these DNS requests?","title":"Part IV - wireshark"},{"location":"assignments/wireshark02/#part-v-security","text":"Open two packets in bytes view, a dns and a http packet that is encrypted with tls. Double click one of the DNS packets in order to be able to see the bytes view. Remove the dns display filter and replace it with tls (web traffic). Open one of the tls packets in byte view too. Report : Examine the bytes view of the two packets. Do you see any human readable values in the output? Looking at these two packets and others in your capture, does Wireshark provide any clues about whether or not your DNS is encrypted? Does it provide any clues on whether your web traffic is encrypted? Attacker: What information might an outside observer be able to glean about your computing activities by capturing your DNS traffic? Was any discernible information revealed (as far as you can tell) through your web traffic?","title":"Part V - security"},{"location":"assignments/wireshark03/","text":"Lab 3 - Analyze Zeroconf in Wireshark \u00b6 Lab 3 Assignment page on Canvas Overview \u00b6 Most of the time, our discussion about IP addresses are focused on globally routable addresses or on RFC1918 private addresses. In this lab, we are going to explore another type of address that can be used without any explicit configuration (either by a user or network administrator). We\u2019re also going to look at how these addresses fit in to a group of protocols called the zero-configuration networking (zeroconf) protocols and explore how zeroconf appears in this class and in our daily use of network technology. This lab will require a combination of Wireshark analysis and Internet research. We\u2019ve provided links to several references as a starting point, but you are free to look up other resources as needed. Please cite all sources in your deliverable. Resources \u00b6 https://en.wikipedia.org/wiki/Link-local_address (Links to an external site.) https://tools.ietf.org/html/rfc3927 (Links to an external site.) https://en.wikipedia.org/wiki/.local (Links to an external site.) https://en.wikipedia.org/wiki/Zero-configuration_networking (Links to an external site.) Part I - Identification \u00b6 Report: Before you start, take a moment to record some details about your computer and your Ethernet network adapter. These details may be helpful to you in your analysis: Hostname (Computer, Pi) MAC Address (Computer, Pi) Part II - Powering on your Pi \u00b6 If you already started your Pi, shut it down and disconnect power before you begin. Launch a new Wireshark capture over the Ethernet connection to your Pi. Linux users should listen on the \u201cAll\u201d interface and may want to disable their wireless connection before capturing to reduce noise and focus on the important details. With your capture running, power on the Pi. You\u2019ll be keeping an eye on the capture in order to see what happens when your computer and your Pi first connect to the network. Report: Identify the link-local addresses and mDNS names associated with your computer and your Pi. Using your capture as a reference, identify the messages that your Pi sends while autoconfiguring its own IP addresses. Describe the autoconfiguration process used by hosts to choose a link-local address and confirm that it is unique on the local network segment. Part III - Contacting your Pi \u00b6 With your capture still running, let\u2019s try to contact your Pi. Try pinging your Pi based on the hostname \u201craspberrypi.local\u201d (substitute your own hostname if you\u2019ve already changed it). Likewise, try connecting to your pi via SSH. Report: Using your capture, identify an example of an IPv4 and IPv6 mDNS request. Identify the multicast addresses used by mDNS in IPv4 and IPv6. Using your capture, identify an example of an IPv4 and IPv6 mDNS response. Are mDNS responses sent to a multicast address or to a specific unicast address. Identify the destination addresses used to reach your Pi in the final ICMP echo request (ping) and SSH connection. Part IV - Manually Querying mDNS devices \u00b6 Lastly, let\u2019s look at some tools that will allow us to manually query mDNS devices on our network. Unlike DNS, we should see that individual devices answer their own queries. Windows users can use the powershell command Resolve-DNSName while macOS and Linux users should be able to use dns-sd . Report: Search online or use man to look up syntax for the relevant command on your system, and make an mDNS request to your Pi. Provide a screenshot of your mDNS request and the output received. Part V - Protocol Research \u00b6 Perform your own research into these protocols and answer the following questions. We recommend starting with the resources listed at the end of this guide. In your own words, define the term multicast and describe how it differs from broadcast and unicast communication. Describe the major difference between how link local addresses are assigned and used in IPv4 versus in IPv6. In your own words, summarize what RFC 3927 says about determining whether two hosts are on the same link. Based on what you\u2019ve learned, describe how we are able to connect with a Pi based on a pre-defined hostname without the need for any infrastructure like a DHCP or DNS server.","title":"Analyze Zeroconf in Wireshark"},{"location":"assignments/wireshark03/#lab-3-analyze-zeroconf-in-wireshark","text":"Lab 3 Assignment page on Canvas","title":"Lab 3 - Analyze Zeroconf in Wireshark"},{"location":"assignments/wireshark03/#overview","text":"Most of the time, our discussion about IP addresses are focused on globally routable addresses or on RFC1918 private addresses. In this lab, we are going to explore another type of address that can be used without any explicit configuration (either by a user or network administrator). We\u2019re also going to look at how these addresses fit in to a group of protocols called the zero-configuration networking (zeroconf) protocols and explore how zeroconf appears in this class and in our daily use of network technology. This lab will require a combination of Wireshark analysis and Internet research. We\u2019ve provided links to several references as a starting point, but you are free to look up other resources as needed. Please cite all sources in your deliverable.","title":"Overview"},{"location":"assignments/wireshark03/#resources","text":"https://en.wikipedia.org/wiki/Link-local_address (Links to an external site.) https://tools.ietf.org/html/rfc3927 (Links to an external site.) https://en.wikipedia.org/wiki/.local (Links to an external site.) https://en.wikipedia.org/wiki/Zero-configuration_networking (Links to an external site.)","title":"Resources"},{"location":"assignments/wireshark03/#part-i-identification","text":"Report: Before you start, take a moment to record some details about your computer and your Ethernet network adapter. These details may be helpful to you in your analysis: Hostname (Computer, Pi) MAC Address (Computer, Pi)","title":"Part I - Identification"},{"location":"assignments/wireshark03/#part-ii-powering-on-your-pi","text":"If you already started your Pi, shut it down and disconnect power before you begin. Launch a new Wireshark capture over the Ethernet connection to your Pi. Linux users should listen on the \u201cAll\u201d interface and may want to disable their wireless connection before capturing to reduce noise and focus on the important details. With your capture running, power on the Pi. You\u2019ll be keeping an eye on the capture in order to see what happens when your computer and your Pi first connect to the network. Report: Identify the link-local addresses and mDNS names associated with your computer and your Pi. Using your capture as a reference, identify the messages that your Pi sends while autoconfiguring its own IP addresses. Describe the autoconfiguration process used by hosts to choose a link-local address and confirm that it is unique on the local network segment.","title":"Part II - Powering on your Pi"},{"location":"assignments/wireshark03/#part-iii-contacting-your-pi","text":"With your capture still running, let\u2019s try to contact your Pi. Try pinging your Pi based on the hostname \u201craspberrypi.local\u201d (substitute your own hostname if you\u2019ve already changed it). Likewise, try connecting to your pi via SSH. Report: Using your capture, identify an example of an IPv4 and IPv6 mDNS request. Identify the multicast addresses used by mDNS in IPv4 and IPv6. Using your capture, identify an example of an IPv4 and IPv6 mDNS response. Are mDNS responses sent to a multicast address or to a specific unicast address. Identify the destination addresses used to reach your Pi in the final ICMP echo request (ping) and SSH connection.","title":"Part III - Contacting your Pi"},{"location":"assignments/wireshark03/#part-iv-manually-querying-mdns-devices","text":"Lastly, let\u2019s look at some tools that will allow us to manually query mDNS devices on our network. Unlike DNS, we should see that individual devices answer their own queries. Windows users can use the powershell command Resolve-DNSName while macOS and Linux users should be able to use dns-sd . Report: Search online or use man to look up syntax for the relevant command on your system, and make an mDNS request to your Pi. Provide a screenshot of your mDNS request and the output received.","title":"Part IV - Manually Querying mDNS devices"},{"location":"assignments/wireshark03/#part-v-protocol-research","text":"Perform your own research into these protocols and answer the following questions. We recommend starting with the resources listed at the end of this guide. In your own words, define the term multicast and describe how it differs from broadcast and unicast communication. Describe the major difference between how link local addresses are assigned and used in IPv4 versus in IPv6. In your own words, summarize what RFC 3927 says about determining whether two hosts are on the same link. Based on what you\u2019ve learned, describe how we are able to connect with a Pi based on a pre-defined hostname without the need for any infrastructure like a DHCP or DNS server.","title":"Part V - Protocol Research"},{"location":"assignments/wireshark04/","text":"Lab 4 - Analyze TCP with ncat and Wireshark \u00b6 Lab 4 Assignment page on Canvas Overview \u00b6 The purpose of this lab is for students to gain hands on experience with TCP connections. By the end of the lab you will be familiar with: ncat TCP handshakes http https Security faults of http We highly recommend using search engines to help you find solutions. Setup \u00b6 For this lab, we are going to use the incredibly versatile ncat utility to directly read and write data to and from HTTP(s) servers. Some of you may already be familiar with a similar tool known as netcat ( nc from the command line on most Linux or macOS machines). ncat is a re-implementation of netcat that adds some handy features (like SSL/TLS connections). Installing ncat \u00b6 Windows macOS & Linux Please follow instructions to install ncat from https://nmap.org/ncat/ . You can accomplish this either by installing the nmap port scanner suite or by installing the portable executable . Please test your installation by running ncat from a new Powershell console. You may need to update your system path to include the directory in which you installed ncat . Install nmap from your preferred package manager (e.g., apt or brew ) or follow instructions provided at nmap.org . Part I - TCP Analysis Introduction \u00b6 Capture \u00b6 The instructions below can be used to manually perform an HTTP exchange with a server via the ncat tool. This process approximates the exchange that occurs between your web browser and a web server after you enter a URL into the address bar or click on a hyperlink. Why don't I see any output? At this point, we're interacting directly with a server in a text-based protocol. The server will wait silently for you to enter a valid message. Per RFC 2616, the request you are sending is multiple lines and is terminated by two new lines . If you wait too long or submit something that violates the specification, the server will respond with an error and close the connection. Capture Instructions \u00b6 Create a capture filter that will select traffic appearing on TCP port 80 or 443. Launch a new Wireshark capture on your primary network interface with the capture filter from Step 1. Launch a couple of new terminals (mac/linux) or Powershell consoles (windows) and follow these steps to make HTTP requests to neverssl.com and wikipedia.org (in separate consoles): NeverSSL a. Open a new connection: ncat neverssl.com 80 b. Start a new HTTP requests (terminated with a newline ) GET / HTTP/1.1 c. Add a Host header followed by two new lines Host: neverssl.com Wikipedia a. Open a new connection: ncat --ssl www.wikipedia.org 443 b. Start a new HTTP requests (terminated with a newline ) GET / HTTP/1.1 c. Add a Host header followed by two new lines Host: www.wikipedia.org Close your connections with CTRL-C End your Wireshark capture and save a copy of the capture to complete the remaining analysis. Save the ncat output to a notepad or file (for questions 3 & 4 on the lab report). Report \u00b6 What capture filter did you use to select TCP traffic on ports 80 and 443? Briefly describe the difference between a capture filter and a display filter. In what way do they serve different purposes? Paste in the first 10 lines of Wikipedia's server's response from the ncat output. Paste in the first 10 lines of NeverSSL's server's response from the ncat output. Part II - Plaintext (http) Analysis - NeverSSL \u00b6 Perform a search in Wireshark ( CMD-F or CTRL-F ) to find the string neverssl.com in packet details . Note You'll need to adjust the options for your search via dropdowns This search should lead you to the reassembled HTTP session. Review the summary of the reassembled TCP segments provided inside the Packet Details . For an alternate perspective, right click on any frame belonging to the connection and select Follow -> TCP Stream . Finally, right click on any frame in the connection and select Prepare Conversation Filter -> TCP Report \u00b6 Fill out the table in the lab report template for the first 10 frames of the NeverSSL connection in Wireshark by identifying each frame's: Frame # Source ( client or server ) Flags Sequence number Acknowledgement number Length of payload (additional data) (If you are confused about table syntax in Markdown, go here and scroll to to \"Tables\") Which information is used by the client to identify messages from the connection? Which information is used by the server to identify messages from the connection? Fill out the table in the lab report template for the last 5 frames of the NeverSSL connection in Wireshark Part III - Encrypted (https) Analysis - Wikipedia \u00b6 Perform a new search in Wireshark to find wikipedia.org . Be careful with this search since the search term appears in the page content from neverssl.com . Once you have identified the a frame from this TCP connection, prepare a new conversation filter so that you can take a closer look at the session. Hint We are looking for the term to appear in a Transport Layer Security option. We won't actually see the contents of our HTTPS session since the connection is encrypted by the time we enter it. Note It may be helpful to create a table or illustration that lists significant frames and their role in the session. Report \u00b6 Fill out the table in the lab report template for the first 10 frames of the Wikipedia connection in Wireshark Fill out the table in the lab report template for the last 5 frames of the Wikipedia connection in Wireshark What is the frame number of the first frame to contain a Transport Layer Security header? Looking at the first frames of the SSL/TLS session, identify the messages sent in the TLS handshake (hint: look for Handshake Type in the packet details). Create a display filter to show the server side of the conversation only. Can you find any stream anomalies, e.g., duplicate data, out-of-order segments, or duplicate ACK numbers? (Hint: These are labeled in the Info field of the packet list) Part IV - General TCP Analysis \u00b6 Report \u00b6 What function does the opening handshake of TCP accomplish? Describe how you would identify stream anomalies by using sequence and acknowledgement numbers of TCP segments. Bonus (Optional) \u00b6 Report \u00b6 (5 points) Create a basic sequence diagram of the TCP segments sent in wikipedia.org session. Do not diagram all 100+ Do not diagram all 100+ frames of the wikipedia.org session, but you should include enough to illustrate the TLS handshake, the first few frames of encrypted data, and the closing of the TCP socket. You can draw this out on paper and submit a scan or use any other tool capable of building diagrams. Take a look at https://websequencediagrams.com . Your diagram should include annotations for the following details: Frame # (on each message) TCP Flags (on the setup/teardown handshake) TLS Handshake Protocol steps (if applicable) # of bytes transferred (messages carrying data) Hint: Be careful to exclude reassembled messages from your diagram (e.g., frames labeled HTTP or TLS that represent multiple TCP segments).","title":"Analyze TCP with ncat and Wireshark"},{"location":"assignments/wireshark04/#lab-4-analyze-tcp-with-ncat-and-wireshark","text":"Lab 4 Assignment page on Canvas","title":"Lab 4 - Analyze TCP with ncat and Wireshark"},{"location":"assignments/wireshark04/#overview","text":"The purpose of this lab is for students to gain hands on experience with TCP connections. By the end of the lab you will be familiar with: ncat TCP handshakes http https Security faults of http We highly recommend using search engines to help you find solutions.","title":"Overview"},{"location":"assignments/wireshark04/#setup","text":"For this lab, we are going to use the incredibly versatile ncat utility to directly read and write data to and from HTTP(s) servers. Some of you may already be familiar with a similar tool known as netcat ( nc from the command line on most Linux or macOS machines). ncat is a re-implementation of netcat that adds some handy features (like SSL/TLS connections).","title":"Setup"},{"location":"assignments/wireshark04/#installing-ncat","text":"Windows macOS & Linux Please follow instructions to install ncat from https://nmap.org/ncat/ . You can accomplish this either by installing the nmap port scanner suite or by installing the portable executable . Please test your installation by running ncat from a new Powershell console. You may need to update your system path to include the directory in which you installed ncat . Install nmap from your preferred package manager (e.g., apt or brew ) or follow instructions provided at nmap.org .","title":"Installing ncat"},{"location":"assignments/wireshark04/#part-i-tcp-analysis-introduction","text":"","title":"Part I - TCP Analysis Introduction"},{"location":"assignments/wireshark04/#capture","text":"The instructions below can be used to manually perform an HTTP exchange with a server via the ncat tool. This process approximates the exchange that occurs between your web browser and a web server after you enter a URL into the address bar or click on a hyperlink. Why don't I see any output? At this point, we're interacting directly with a server in a text-based protocol. The server will wait silently for you to enter a valid message. Per RFC 2616, the request you are sending is multiple lines and is terminated by two new lines . If you wait too long or submit something that violates the specification, the server will respond with an error and close the connection.","title":"Capture"},{"location":"assignments/wireshark04/#capture-instructions","text":"Create a capture filter that will select traffic appearing on TCP port 80 or 443. Launch a new Wireshark capture on your primary network interface with the capture filter from Step 1. Launch a couple of new terminals (mac/linux) or Powershell consoles (windows) and follow these steps to make HTTP requests to neverssl.com and wikipedia.org (in separate consoles): NeverSSL a. Open a new connection: ncat neverssl.com 80 b. Start a new HTTP requests (terminated with a newline ) GET / HTTP/1.1 c. Add a Host header followed by two new lines Host: neverssl.com Wikipedia a. Open a new connection: ncat --ssl www.wikipedia.org 443 b. Start a new HTTP requests (terminated with a newline ) GET / HTTP/1.1 c. Add a Host header followed by two new lines Host: www.wikipedia.org Close your connections with CTRL-C End your Wireshark capture and save a copy of the capture to complete the remaining analysis. Save the ncat output to a notepad or file (for questions 3 & 4 on the lab report).","title":"Capture Instructions"},{"location":"assignments/wireshark04/#report","text":"What capture filter did you use to select TCP traffic on ports 80 and 443? Briefly describe the difference between a capture filter and a display filter. In what way do they serve different purposes? Paste in the first 10 lines of Wikipedia's server's response from the ncat output. Paste in the first 10 lines of NeverSSL's server's response from the ncat output.","title":"Report"},{"location":"assignments/wireshark04/#part-ii-plaintext-http-analysis-neverssl","text":"Perform a search in Wireshark ( CMD-F or CTRL-F ) to find the string neverssl.com in packet details . Note You'll need to adjust the options for your search via dropdowns This search should lead you to the reassembled HTTP session. Review the summary of the reassembled TCP segments provided inside the Packet Details . For an alternate perspective, right click on any frame belonging to the connection and select Follow -> TCP Stream . Finally, right click on any frame in the connection and select Prepare Conversation Filter -> TCP","title":"Part II - Plaintext (http) Analysis - NeverSSL"},{"location":"assignments/wireshark04/#report_1","text":"Fill out the table in the lab report template for the first 10 frames of the NeverSSL connection in Wireshark by identifying each frame's: Frame # Source ( client or server ) Flags Sequence number Acknowledgement number Length of payload (additional data) (If you are confused about table syntax in Markdown, go here and scroll to to \"Tables\") Which information is used by the client to identify messages from the connection? Which information is used by the server to identify messages from the connection? Fill out the table in the lab report template for the last 5 frames of the NeverSSL connection in Wireshark","title":"Report"},{"location":"assignments/wireshark04/#part-iii-encrypted-https-analysis-wikipedia","text":"Perform a new search in Wireshark to find wikipedia.org . Be careful with this search since the search term appears in the page content from neverssl.com . Once you have identified the a frame from this TCP connection, prepare a new conversation filter so that you can take a closer look at the session. Hint We are looking for the term to appear in a Transport Layer Security option. We won't actually see the contents of our HTTPS session since the connection is encrypted by the time we enter it. Note It may be helpful to create a table or illustration that lists significant frames and their role in the session.","title":"Part III - Encrypted (https) Analysis - Wikipedia"},{"location":"assignments/wireshark04/#report_2","text":"Fill out the table in the lab report template for the first 10 frames of the Wikipedia connection in Wireshark Fill out the table in the lab report template for the last 5 frames of the Wikipedia connection in Wireshark What is the frame number of the first frame to contain a Transport Layer Security header? Looking at the first frames of the SSL/TLS session, identify the messages sent in the TLS handshake (hint: look for Handshake Type in the packet details). Create a display filter to show the server side of the conversation only. Can you find any stream anomalies, e.g., duplicate data, out-of-order segments, or duplicate ACK numbers? (Hint: These are labeled in the Info field of the packet list)","title":"Report"},{"location":"assignments/wireshark04/#part-iv-general-tcp-analysis","text":"","title":"Part IV - General TCP Analysis"},{"location":"assignments/wireshark04/#report_3","text":"What function does the opening handshake of TCP accomplish? Describe how you would identify stream anomalies by using sequence and acknowledgement numbers of TCP segments.","title":"Report"},{"location":"assignments/wireshark04/#bonus-optional","text":"","title":"Bonus (Optional)"},{"location":"assignments/wireshark04/#report_4","text":"(5 points) Create a basic sequence diagram of the TCP segments sent in wikipedia.org session. Do not diagram all 100+ Do not diagram all 100+ frames of the wikipedia.org session, but you should include enough to illustrate the TLS handshake, the first few frames of encrypted data, and the closing of the TCP socket. You can draw this out on paper and submit a scan or use any other tool capable of building diagrams. Take a look at https://websequencediagrams.com . Your diagram should include annotations for the following details: Frame # (on each message) TCP Flags (on the setup/teardown handshake) TLS Handshake Protocol steps (if applicable) # of bytes transferred (messages carrying data) Hint: Be careful to exclude reassembled messages from your diagram (e.g., frames labeled HTTP or TLS that represent multiple TCP segments).","title":"Report"},{"location":"labs/misc/lab1/","text":"Lab 1 - Core Technical Skills \u00b6 Lab 1 Assignment page on Canvas Overview \u00b6 In this lab you will be introduced to working with a headless Linux server. The work you do in this lab will be extremely helpful in becoming more comfortable with your Raspberry Pi. We will walk you through all of the required steps in lab, but all the required steps are also in this webpage. Before you start \u00b6 Everyone \u00b6 Confirm that you have created a DigitalOcean account, and that on the top right of the website it says you have $100.00 of credits. This will allow you to create virtual machine \u201cDroplets\u201d on DigitalOcean without incurring any direct cost. In addition to the email we sent on Sunday, instructions to complete this task can be found in here . Windows \u00b6 Determine which build of Windows 10 they have installed by running Get-ComputerInfo -Property WindowsVersion in PowerShell. The minimum version of Windows 10 required for this course is 1809, but you may proceed with this lab as long as you are running 1803. For any prior version of Windows (older than 1803), please install Git for Windows from https://gitforwindows.org/ and use the Git Bash environment to complete the following set of exercises instead of PowerShell. Create SSH client keys \u00b6 To use the DigitalOcean server we will soon create, you'll need a way to authenticate yourself and login to your server. While you might think a password will suffice, we will be using a more secure method of authentication through SSH keys. SSH stands for 'Secure Shell'. A 'shell' is a command line interface, such as the one's you've seen in Terminal, PowerShell, or Git Bash. Throughout this course, you'll be using the shell, remotely, to configure Linux. SSH makes the shell 'secure' by create a pair of keys that you use to authenticate yourself to a remote shell. These 'keys' are simply long strings of characters that are tied together with some complex mathematics. We will use a program called ssh-keygen to create this pair of keys. ssh-keygen will generate a private key, and a public key. Your public key can be given out, to say, DigitalOcean, while your private key remains only on your computer. In short, SSH works as follows in our scenario: Your computer connects to the DigitalOcean-hosted server via a remote shell The DigitalOcean-hosted server encrypts a file with your public key (sort of like creating a hash for it) and sends the encrypted file to you. Only your private key will be able to decrypt the file (sort of like getting back the original data that wash hashed). Your computer uses your private key to decrypt the file, then sends back the decrypted file to the server. You have now proved that you have the private key that matched the public key. To create your SSH keypair, use ssh-keygen as follows: With either Terminal (for Mac) or PowerShell/Git Bash (for Windows) run the following command with your own email address: ssh-keygen -t ed25519 -C <YOUR@EMAIL> You will be prompted for a file name for the private SSH key. Accept the default by pressing the Enter key. You will be prompted for a passphrase. This is important as it is used to protect your private SSH key. Make it something strong, like you would a password, and commit it to memory or write it down somewhere. If you are prompted to overwrite anything, type n and press the Enter key (OPTIONAL STEP) To avoid having to enter the passphrase every time you use your private key, set up ssh-agent as describe in this tutorial . Create a Debian 9 Server on DigitalOcean \u00b6 Log into your DigitalOcean account, go to the 'Droplet' tab on the left, and click 'Create Droplet'. Then set the Droplet up based on the following parameters: Image Debian 9.12 x64 Plan Starter / $5 per month Authentication SSH keys Right under the 'SSH keys' option in the 'Authentication' section, you'll see a button that says 'New SSH Key'. Press it, and you'll be prompted for your public SSH key. To get your public SSH key, enter the following in either Terminal (for Mac) or PowerShell/Git Bash (for Windows) cat ~/.ssh/id_ed25519.pub Warning Make sure to enter the .pub extension at the end of this line! Without the extension, you will get back your private key instead of your public key! You should then see a string like this: Copy the string (from the ssh-ed25519 all the way to the end of your email) and paste it into the 'Add public SSH key' window in DigitalOcean like so: Then type a name for the key (something like 'My Macbook Pro') and press 'Add SSH Key' Now you are all set to create the Droplet. Scroll down to and press 'Create Droplet'. If you want, you can create a name for this server in the 'Choose a hostname' section. Wait for the droplet to be created. When it's finished, copy the IP address of the server for the next section. It's the number right next to the server's name. Connect and Manage your Server \u00b6 Log in to the droplet as the root user via SSH \u00b6 In order to manage our remote server, we\u2019ll use SSH to connect remotely. Since we have already associated a set of SSH keys with the server, we will be able to log in the the server as the 'root' user without directly entering a password. The 'root' user is the default user on a Linux system, and it has permission to do anything . This is much different from a standard user account, say 'John', who only has permission to write, read, or execute certain files, like his user directory. We will begin this lab by logging in as the 'root' user, but we will soon create another user on the server and use that instead. It's typically not advised to use the root user on a Linux system unless what you're doing requires it. The syntax for ssh is: ssh <USERNAME>@<SERVER> We'll log in as the 'root' user, and use the IP address we copied earlier: e.g., ssh root@<SERVER_IP> for me that's ssh root@104.248.59.220 If you entered the command correctly, you should see something like: The authenticity of host '104.248.59.220 (104.248.59.220)' can't be established. ECDSA key fingerprint is SHA256:... Are you sure you want to continue connecting (yes/no)? This is your computer letting you know it's never connected to this server before. That's okay, so: Type yes and press enter. You will then be prompted with something like: Warning: Permanently added '104.248.59.220' (ECDSA) to the list of known hosts. Linux debian-info314-sp20 4.9.0-12-amd64 #1 SMP Debian 4.9.210-1 (2020-01-20) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. And finally you see something like this: root@debian-fdk542-432kgs:~# To receive credit for this lab, you need to create a transcript of all the commands you issue to the server. To do this, we will use the script command to capture your session. Enter: script root-session This will use the script program to create a log of all your shell input and save it to a file named root-session You should see this message: Script started, file is root-session Now, everything you type in this shell will now be captured in a file named root-session within your home directory. If you need to exit the server anytime, just type exit . The first time you exit you'll get the output: Script done, file is root-session This lets you know that script has finished recording and have saved the transcript. Next, type exit once more and you will be logged out of the SSH session, receving the message: logout Connection to 104.248.59.220 closed. Warning It's important that if you exit from the server and then reconnect to it (via ssh ) that you continue your script. This will ensure everything keeps being recorded and you will get full credit for the lab. To continue the script, type: script -a root-session after you SSH back into the server. You'll again be prompted with: Script started, file is root-session which ensures that your next commands will be appended to the root-session file Create a second user account \u00b6 In most situations, we will not work directly as the root user, since this would pose additional security risks. In fact, many Linux distributions will prevent direct root login. Let\u2019s create a new user and practice working with this configuration. Add a new user by entering this (where is your name or something else you'll remember) adduser <YOUR_USERNAME> you'll be prompted for other information, such as a password and a name. Give the account a password you'll remember, and skip the other fields (such as name) by pressing 'Enter'. Then, add the user to the sudo group: usermod -aG sudo <YOUR_USERNAME> This allows the new user to use sudo before commands. Using sudo allows a user who is not root to use root privaleges on a per-command basis. By default, DigitalOcean prevents users from connecting via SSH without an SSH key. This is the correct decision from the security perspective, but we will disable it temporarily in order to explore beneath the hood. Modify /etc/ssh/sshd_config to enable password-based login by editing it as follows: First, open sshd_config in nano by using: nano /etc/ssh/sshd_config This will open nano . nano is a terminal-based editor, and is very simple. You can only move the cursor by using the arrow keys. To copy text from a file using nano , select it using your mouse and then copy it as usual (Control+C on Windows, Command + C on Mac) In nano , Find the: PasswordAuthentication no setting and prefix it with a # comment character, so it should read: #PasswordAuthentication no Then save the document in nano by pressing: Control + X in Windows, Command + X in Mac. Settings don\u2019t take effect automatically. Use the systemctl tool to restart the sshd service: systemctl restart sshd Log in as your new user \u00b6 In a new terminal window , log in as the new user via SSH using the password you created above. Capture a script of your session by calling: script user-session The results of this command will be saved in a file named user-session. When you log in, run: pwd and make note of the directory. This is your home directory. Notice that the home directory for each user is different. Try listing the contents of the root user\u2019s home directory by typing: ls -al /root You should receive a permission denied error. The /root path is owned by the root user and has permissions restricted so that other users cannot read, write, or execute the directory or anything else it contains. Since root is a special user, the restriction does not apply in the other direction. Demonstrate this difference in permissions by listing the contents of the new user\u2019s home directory from the root user\u2019s shell , e.g., ls -al /home/clinton from your root login and view the contents of my user\u2019s home directory. By default in basic Linux distributions, the root user has complete control over all system and user resources and is even able to take on the identity of other users without knowing their passwords. Running Administrative Commands \u00b6 Many of the administration tasks we need to complete throughout the quarter require root level permissions. Since we\u2019ve already established that we will deliberately work as a non-root user, we should determine a method to elevate our privileges. In Linux and other Unix-based operating systems, the command that allows us to do this is called sudo . By prefixing any valid shell command or program name with sudo , we will assume the identity of root at runtime. Test this out by comparing the results of ( within the new user's shell ) whoami with the results of sudo whoami The next step will require us to log out of our current ssh session. Before you do this, type exit to end the current script session. You should see a message stating that the script is complete. You may now log out of ssh by running the exit command. Add SSH keys for your user \u00b6 As you\u2019ve seen, we can log into the root account without entering a password because of the SSH keys that we created at the beginning of this lab, but logging into our new user account requires a password (which is a much weaker configuration from a security perspective). Let\u2019s resolve this by adding our public SSH key to the new user account on our Droplet. First switch back to your root shell and examine the files saved in the .ssh folder of root\u2019s home directory. To do this, we'll switch to the .ssh directory using cd . cd stands for 'Change Directory' and will let you switch the folder you are in. To change to the .ssh folder type: cd .ssh Now you can use ls -al to view the contents of the folder once you are in it. What you should see in the specified path is a file named authorized_keys that contains a copy of your SSH public key on a line by itself. We\u2019ll be creating a similar file in the home directory of our new user. On each login attempt, the SSH server checks for authorized_keys designated for the user and loads. First, within a new terminal window , type: ssh <YOUR_USERNAME>@<SERVER_IP> 'mkdir -p ~/.ssh' This creates a quick SSH session into your user, and makes a new directory called .ssh for that user. Next, you'll copy your public key ( $HOME/.ssh/id_ed25519.pub ) to the Droplet using the scp command. scp is part of the OpenSSH client package and is used to copy files between paths on local and remote hosts. You will notice that it uses ssh syntax to identify the remote location followed by a colon and the actual source or target path at the remote location: NOTE: The following command is entered as one line but is wrapped due to the constraints of the editor. scp $HOME/.ssh/id_ed25519.pub <YOUR_USERNAME>@<SERVER_IP>:.ssh/authorized_keys Be aware that scp respects file permissions. When connecting as my non-root user, I cannot read or write to locations that are restricted to other users or root. Install a web server \u00b6 Test that you successfully copied your public key to the server and can access the Droplet as your non-root user without having to enter a server password: ssh <YOUR_USERNAME>@<SERVER_IP> You should not be prompted for your UNIX/Linux user password you set, it should instead use the SSH key as before, and if you set it, ask for the SSH passphrase. Once you are logged back in, resume your script by running script -a user-session Install the nginx web service using the command: sudo apt install nginx Verify that the service installed correctly by running systemctl status nginx and confirming that the nginx service is loaded and running. Use a web browser to navigate to your IP address and load the default nginx site, e.g., > , in my case http://134.209.4.234 Once you have completed these tasks, please close out the scripts from your root and user shell by typing exit twice on each shell. Now on your computer (no longer on the server!) , use scp to copy the scripts over by typing: scp root@<SERVER_IP>:root-session $HOME/Desktop and scp <YOUR_USERNAME>@<SERVER_IP>:user-session $HOME/Desktop They will be on your desktop. Deliverables \u00b6 For your deliverables, you will need to submit three files. Your user-session file (user-session) Your root-session file (root-session) A completed lab report using the markdown template provided above, exported to PDF. The lab report can be found at Lab 1 Assignment page on Canvas","title":"Lab 1 - Core Technical Skills"},{"location":"labs/misc/lab1/#lab-1-core-technical-skills","text":"Lab 1 Assignment page on Canvas","title":"Lab 1 - Core Technical Skills"},{"location":"labs/misc/lab1/#overview","text":"In this lab you will be introduced to working with a headless Linux server. The work you do in this lab will be extremely helpful in becoming more comfortable with your Raspberry Pi. We will walk you through all of the required steps in lab, but all the required steps are also in this webpage.","title":"Overview"},{"location":"labs/misc/lab1/#before-you-start","text":"","title":"Before you start"},{"location":"labs/misc/lab1/#everyone","text":"Confirm that you have created a DigitalOcean account, and that on the top right of the website it says you have $100.00 of credits. This will allow you to create virtual machine \u201cDroplets\u201d on DigitalOcean without incurring any direct cost. In addition to the email we sent on Sunday, instructions to complete this task can be found in here .","title":"Everyone"},{"location":"labs/misc/lab1/#windows","text":"Determine which build of Windows 10 they have installed by running Get-ComputerInfo -Property WindowsVersion in PowerShell. The minimum version of Windows 10 required for this course is 1809, but you may proceed with this lab as long as you are running 1803. For any prior version of Windows (older than 1803), please install Git for Windows from https://gitforwindows.org/ and use the Git Bash environment to complete the following set of exercises instead of PowerShell.","title":"Windows"},{"location":"labs/misc/lab1/#create-ssh-client-keys","text":"To use the DigitalOcean server we will soon create, you'll need a way to authenticate yourself and login to your server. While you might think a password will suffice, we will be using a more secure method of authentication through SSH keys. SSH stands for 'Secure Shell'. A 'shell' is a command line interface, such as the one's you've seen in Terminal, PowerShell, or Git Bash. Throughout this course, you'll be using the shell, remotely, to configure Linux. SSH makes the shell 'secure' by create a pair of keys that you use to authenticate yourself to a remote shell. These 'keys' are simply long strings of characters that are tied together with some complex mathematics. We will use a program called ssh-keygen to create this pair of keys. ssh-keygen will generate a private key, and a public key. Your public key can be given out, to say, DigitalOcean, while your private key remains only on your computer. In short, SSH works as follows in our scenario: Your computer connects to the DigitalOcean-hosted server via a remote shell The DigitalOcean-hosted server encrypts a file with your public key (sort of like creating a hash for it) and sends the encrypted file to you. Only your private key will be able to decrypt the file (sort of like getting back the original data that wash hashed). Your computer uses your private key to decrypt the file, then sends back the decrypted file to the server. You have now proved that you have the private key that matched the public key. To create your SSH keypair, use ssh-keygen as follows: With either Terminal (for Mac) or PowerShell/Git Bash (for Windows) run the following command with your own email address: ssh-keygen -t ed25519 -C <YOUR@EMAIL> You will be prompted for a file name for the private SSH key. Accept the default by pressing the Enter key. You will be prompted for a passphrase. This is important as it is used to protect your private SSH key. Make it something strong, like you would a password, and commit it to memory or write it down somewhere. If you are prompted to overwrite anything, type n and press the Enter key (OPTIONAL STEP) To avoid having to enter the passphrase every time you use your private key, set up ssh-agent as describe in this tutorial .","title":"Create SSH client keys"},{"location":"labs/misc/lab1/#create-a-debian-9-server-on-digitalocean","text":"Log into your DigitalOcean account, go to the 'Droplet' tab on the left, and click 'Create Droplet'. Then set the Droplet up based on the following parameters: Image Debian 9.12 x64 Plan Starter / $5 per month Authentication SSH keys Right under the 'SSH keys' option in the 'Authentication' section, you'll see a button that says 'New SSH Key'. Press it, and you'll be prompted for your public SSH key. To get your public SSH key, enter the following in either Terminal (for Mac) or PowerShell/Git Bash (for Windows) cat ~/.ssh/id_ed25519.pub Warning Make sure to enter the .pub extension at the end of this line! Without the extension, you will get back your private key instead of your public key! You should then see a string like this: Copy the string (from the ssh-ed25519 all the way to the end of your email) and paste it into the 'Add public SSH key' window in DigitalOcean like so: Then type a name for the key (something like 'My Macbook Pro') and press 'Add SSH Key' Now you are all set to create the Droplet. Scroll down to and press 'Create Droplet'. If you want, you can create a name for this server in the 'Choose a hostname' section. Wait for the droplet to be created. When it's finished, copy the IP address of the server for the next section. It's the number right next to the server's name.","title":"Create a Debian 9 Server on DigitalOcean"},{"location":"labs/misc/lab1/#connect-and-manage-your-server","text":"","title":"Connect and Manage your Server"},{"location":"labs/misc/lab1/#log-in-to-the-droplet-as-the-root-user-via-ssh","text":"In order to manage our remote server, we\u2019ll use SSH to connect remotely. Since we have already associated a set of SSH keys with the server, we will be able to log in the the server as the 'root' user without directly entering a password. The 'root' user is the default user on a Linux system, and it has permission to do anything . This is much different from a standard user account, say 'John', who only has permission to write, read, or execute certain files, like his user directory. We will begin this lab by logging in as the 'root' user, but we will soon create another user on the server and use that instead. It's typically not advised to use the root user on a Linux system unless what you're doing requires it. The syntax for ssh is: ssh <USERNAME>@<SERVER> We'll log in as the 'root' user, and use the IP address we copied earlier: e.g., ssh root@<SERVER_IP> for me that's ssh root@104.248.59.220 If you entered the command correctly, you should see something like: The authenticity of host '104.248.59.220 (104.248.59.220)' can't be established. ECDSA key fingerprint is SHA256:... Are you sure you want to continue connecting (yes/no)? This is your computer letting you know it's never connected to this server before. That's okay, so: Type yes and press enter. You will then be prompted with something like: Warning: Permanently added '104.248.59.220' (ECDSA) to the list of known hosts. Linux debian-info314-sp20 4.9.0-12-amd64 #1 SMP Debian 4.9.210-1 (2020-01-20) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. And finally you see something like this: root@debian-fdk542-432kgs:~# To receive credit for this lab, you need to create a transcript of all the commands you issue to the server. To do this, we will use the script command to capture your session. Enter: script root-session This will use the script program to create a log of all your shell input and save it to a file named root-session You should see this message: Script started, file is root-session Now, everything you type in this shell will now be captured in a file named root-session within your home directory. If you need to exit the server anytime, just type exit . The first time you exit you'll get the output: Script done, file is root-session This lets you know that script has finished recording and have saved the transcript. Next, type exit once more and you will be logged out of the SSH session, receving the message: logout Connection to 104.248.59.220 closed. Warning It's important that if you exit from the server and then reconnect to it (via ssh ) that you continue your script. This will ensure everything keeps being recorded and you will get full credit for the lab. To continue the script, type: script -a root-session after you SSH back into the server. You'll again be prompted with: Script started, file is root-session which ensures that your next commands will be appended to the root-session file","title":"Log in to the droplet as the root user via SSH"},{"location":"labs/misc/lab1/#create-a-second-user-account","text":"In most situations, we will not work directly as the root user, since this would pose additional security risks. In fact, many Linux distributions will prevent direct root login. Let\u2019s create a new user and practice working with this configuration. Add a new user by entering this (where is your name or something else you'll remember) adduser <YOUR_USERNAME> you'll be prompted for other information, such as a password and a name. Give the account a password you'll remember, and skip the other fields (such as name) by pressing 'Enter'. Then, add the user to the sudo group: usermod -aG sudo <YOUR_USERNAME> This allows the new user to use sudo before commands. Using sudo allows a user who is not root to use root privaleges on a per-command basis. By default, DigitalOcean prevents users from connecting via SSH without an SSH key. This is the correct decision from the security perspective, but we will disable it temporarily in order to explore beneath the hood. Modify /etc/ssh/sshd_config to enable password-based login by editing it as follows: First, open sshd_config in nano by using: nano /etc/ssh/sshd_config This will open nano . nano is a terminal-based editor, and is very simple. You can only move the cursor by using the arrow keys. To copy text from a file using nano , select it using your mouse and then copy it as usual (Control+C on Windows, Command + C on Mac) In nano , Find the: PasswordAuthentication no setting and prefix it with a # comment character, so it should read: #PasswordAuthentication no Then save the document in nano by pressing: Control + X in Windows, Command + X in Mac. Settings don\u2019t take effect automatically. Use the systemctl tool to restart the sshd service: systemctl restart sshd","title":"Create a second user account"},{"location":"labs/misc/lab1/#log-in-as-your-new-user","text":"In a new terminal window , log in as the new user via SSH using the password you created above. Capture a script of your session by calling: script user-session The results of this command will be saved in a file named user-session. When you log in, run: pwd and make note of the directory. This is your home directory. Notice that the home directory for each user is different. Try listing the contents of the root user\u2019s home directory by typing: ls -al /root You should receive a permission denied error. The /root path is owned by the root user and has permissions restricted so that other users cannot read, write, or execute the directory or anything else it contains. Since root is a special user, the restriction does not apply in the other direction. Demonstrate this difference in permissions by listing the contents of the new user\u2019s home directory from the root user\u2019s shell , e.g., ls -al /home/clinton from your root login and view the contents of my user\u2019s home directory. By default in basic Linux distributions, the root user has complete control over all system and user resources and is even able to take on the identity of other users without knowing their passwords.","title":"Log in as your new user"},{"location":"labs/misc/lab1/#running-administrative-commands","text":"Many of the administration tasks we need to complete throughout the quarter require root level permissions. Since we\u2019ve already established that we will deliberately work as a non-root user, we should determine a method to elevate our privileges. In Linux and other Unix-based operating systems, the command that allows us to do this is called sudo . By prefixing any valid shell command or program name with sudo , we will assume the identity of root at runtime. Test this out by comparing the results of ( within the new user's shell ) whoami with the results of sudo whoami The next step will require us to log out of our current ssh session. Before you do this, type exit to end the current script session. You should see a message stating that the script is complete. You may now log out of ssh by running the exit command.","title":"Running Administrative Commands"},{"location":"labs/misc/lab1/#add-ssh-keys-for-your-user","text":"As you\u2019ve seen, we can log into the root account without entering a password because of the SSH keys that we created at the beginning of this lab, but logging into our new user account requires a password (which is a much weaker configuration from a security perspective). Let\u2019s resolve this by adding our public SSH key to the new user account on our Droplet. First switch back to your root shell and examine the files saved in the .ssh folder of root\u2019s home directory. To do this, we'll switch to the .ssh directory using cd . cd stands for 'Change Directory' and will let you switch the folder you are in. To change to the .ssh folder type: cd .ssh Now you can use ls -al to view the contents of the folder once you are in it. What you should see in the specified path is a file named authorized_keys that contains a copy of your SSH public key on a line by itself. We\u2019ll be creating a similar file in the home directory of our new user. On each login attempt, the SSH server checks for authorized_keys designated for the user and loads. First, within a new terminal window , type: ssh <YOUR_USERNAME>@<SERVER_IP> 'mkdir -p ~/.ssh' This creates a quick SSH session into your user, and makes a new directory called .ssh for that user. Next, you'll copy your public key ( $HOME/.ssh/id_ed25519.pub ) to the Droplet using the scp command. scp is part of the OpenSSH client package and is used to copy files between paths on local and remote hosts. You will notice that it uses ssh syntax to identify the remote location followed by a colon and the actual source or target path at the remote location: NOTE: The following command is entered as one line but is wrapped due to the constraints of the editor. scp $HOME/.ssh/id_ed25519.pub <YOUR_USERNAME>@<SERVER_IP>:.ssh/authorized_keys Be aware that scp respects file permissions. When connecting as my non-root user, I cannot read or write to locations that are restricted to other users or root.","title":"Add SSH keys for your user"},{"location":"labs/misc/lab1/#install-a-web-server","text":"Test that you successfully copied your public key to the server and can access the Droplet as your non-root user without having to enter a server password: ssh <YOUR_USERNAME>@<SERVER_IP> You should not be prompted for your UNIX/Linux user password you set, it should instead use the SSH key as before, and if you set it, ask for the SSH passphrase. Once you are logged back in, resume your script by running script -a user-session Install the nginx web service using the command: sudo apt install nginx Verify that the service installed correctly by running systemctl status nginx and confirming that the nginx service is loaded and running. Use a web browser to navigate to your IP address and load the default nginx site, e.g., > , in my case http://134.209.4.234 Once you have completed these tasks, please close out the scripts from your root and user shell by typing exit twice on each shell. Now on your computer (no longer on the server!) , use scp to copy the scripts over by typing: scp root@<SERVER_IP>:root-session $HOME/Desktop and scp <YOUR_USERNAME>@<SERVER_IP>:user-session $HOME/Desktop They will be on your desktop.","title":"Install a web server"},{"location":"labs/misc/lab1/#deliverables","text":"For your deliverables, you will need to submit three files. Your user-session file (user-session) Your root-session file (root-session) A completed lab report using the markdown template provided above, exported to PDF. The lab report can be found at Lab 1 Assignment page on Canvas","title":"Deliverables"},{"location":"labs/sockets/lab10/","text":"Lab 10 - proxy part IV \u00b6 Lab 10 Assignment page on Canvas In this lab, we'll wire together the remaining components of a proxy based on the functionality we have built to parse / reconstruct messages. Getting Started \u00b6 Create a new branch called final-proxy-submission dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . In the last lab, we extended the parse_message function to recognize HTTP response messages and completed the second half of the request/response forwarding connection flow. HTTP Version Please confirm that you have followed the instructions in previous labs to downgrade the HTTP version to HTTP/1.0. Newer versions of HTTP have more complicated connection management, where as HTTP/1.0 connections are used for just one request/response. Our goal in this last lab is to complete any debugging and cleanup of the code and to replace the current printed output with a one-line summary from each connection. HTTP Headers Revisited \u00b6 We have previously implemented an oversimplified version of the HTTP header, and on occasion, we may encounter a header that our proxy will be unable to parse due to the concept of continuation lines in RFC 1945. HTTP/1.0 headers may be folded onto multiple lines if each continuation line begins with a space or horizontal tab. Extend your header parsing logic so that it can recognize a continuation line (prefixed with one or more space/tab characters) and append it's contents to the value section of the most recently parsed header. Testing and Debugging \u00b6 Test your proxy thoroughly within the browser (Firefox recommended for this task). You should be able to visit a variety of HTTP-based (non-encrypted) websites and see that pages can load without causing any unexpected exceptions within the proxy. Academic institutions tend to be good candidates for this task since they are much more likely to work over HTTP without redirecting to a secure version of the site. If you encounter any crashes or sites that will not load, attempt to debug the issue. Quite often, this is an indication that you forgot to handle the necessary edge cases in the HTTP message format, such as zero-length responses. Standardize Output \u00b6 In previous labs, we focused more on the functionality of the proxy rather than the output. Before submitting your final work, clean up your existing output and print a single-line summary of each connection as described here. The format we will use for this log is consistent with the HTTP access logs seen in popular web servers like nginx and Apache. Log Entry Format \u00b6 Each line of the log contains the following entries separated by spaces: Requester host (client IP address) Timestamp of when your proxy received the HTTP request wrapped in square brackets Hint: how to get time stamp in Python import datetime now = datetime . datetime . now () now . strftime ( ' %d /%b/%Y:%H:%M:%S' ) The actual request-line received from the client (wrapped in double quotes) The HTTP status code returned by the target server in its response Content-Length of the HTTP response, i.e., the number of bytes in the payload zero if the payload is not present Referer header wrap the header in double quotes replace with a single dash (no quotes) if Referer is not present User-Agent header (contains information about the client's browser/OS/etc) wrap the header in double quotes replace with a single dash (no quotes) if the User-Agent is not present Examples 127.0.0.1 [10/Oct/2000:13:55:36 -0700] \"GET /apache_pb.gif HTTP/1.0\" 200 2326 \"http://www.example.com/start.html\" \"Mozilla/4.08 [en] (Win98; I ;Nav)\" More information about the Apache access log is available at scalyr detailed apache access log .","title":"Lab 10 - proxy part IV"},{"location":"labs/sockets/lab10/#lab-10-proxy-part-iv","text":"Lab 10 Assignment page on Canvas In this lab, we'll wire together the remaining components of a proxy based on the functionality we have built to parse / reconstruct messages.","title":"Lab 10 - proxy part IV"},{"location":"labs/sockets/lab10/#getting-started","text":"Create a new branch called final-proxy-submission dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . In the last lab, we extended the parse_message function to recognize HTTP response messages and completed the second half of the request/response forwarding connection flow. HTTP Version Please confirm that you have followed the instructions in previous labs to downgrade the HTTP version to HTTP/1.0. Newer versions of HTTP have more complicated connection management, where as HTTP/1.0 connections are used for just one request/response. Our goal in this last lab is to complete any debugging and cleanup of the code and to replace the current printed output with a one-line summary from each connection.","title":"Getting Started"},{"location":"labs/sockets/lab10/#http-headers-revisited","text":"We have previously implemented an oversimplified version of the HTTP header, and on occasion, we may encounter a header that our proxy will be unable to parse due to the concept of continuation lines in RFC 1945. HTTP/1.0 headers may be folded onto multiple lines if each continuation line begins with a space or horizontal tab. Extend your header parsing logic so that it can recognize a continuation line (prefixed with one or more space/tab characters) and append it's contents to the value section of the most recently parsed header.","title":"HTTP Headers Revisited"},{"location":"labs/sockets/lab10/#testing-and-debugging","text":"Test your proxy thoroughly within the browser (Firefox recommended for this task). You should be able to visit a variety of HTTP-based (non-encrypted) websites and see that pages can load without causing any unexpected exceptions within the proxy. Academic institutions tend to be good candidates for this task since they are much more likely to work over HTTP without redirecting to a secure version of the site. If you encounter any crashes or sites that will not load, attempt to debug the issue. Quite often, this is an indication that you forgot to handle the necessary edge cases in the HTTP message format, such as zero-length responses.","title":"Testing and Debugging"},{"location":"labs/sockets/lab10/#standardize-output","text":"In previous labs, we focused more on the functionality of the proxy rather than the output. Before submitting your final work, clean up your existing output and print a single-line summary of each connection as described here. The format we will use for this log is consistent with the HTTP access logs seen in popular web servers like nginx and Apache.","title":"Standardize Output"},{"location":"labs/sockets/lab10/#log-entry-format","text":"Each line of the log contains the following entries separated by spaces: Requester host (client IP address) Timestamp of when your proxy received the HTTP request wrapped in square brackets Hint: how to get time stamp in Python import datetime now = datetime . datetime . now () now . strftime ( ' %d /%b/%Y:%H:%M:%S' ) The actual request-line received from the client (wrapped in double quotes) The HTTP status code returned by the target server in its response Content-Length of the HTTP response, i.e., the number of bytes in the payload zero if the payload is not present Referer header wrap the header in double quotes replace with a single dash (no quotes) if Referer is not present User-Agent header (contains information about the client's browser/OS/etc) wrap the header in double quotes replace with a single dash (no quotes) if the User-Agent is not present Examples 127.0.0.1 [10/Oct/2000:13:55:36 -0700] \"GET /apache_pb.gif HTTP/1.0\" 200 2326 \"http://www.example.com/start.html\" \"Mozilla/4.08 [en] (Win98; I ;Nav)\" More information about the Apache access log is available at scalyr detailed apache access log .","title":"Log Entry Format"},{"location":"labs/sockets/lab6/","text":"Lab 6 - Socket Basics in Python \u00b6 Lab 6 Assignment page on Canvas Overview \u00b6 In the remaining weeks of the quarter, we will create a network service using the Python sockets API. In this lab, we will explore the basic use of the sockets API along with some related topics about text and data representation in network protocols. If you need help with getting started with Python, Jarett has created a video tutorial with timestamps for each section here: https://uw.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=685386aa-3431-4e2a-a46a-ab600050535b Instructions \u00b6 Accept the Github Classroom assignment and clone the base repository for the assignment using git clone <URL> . This repository contains a markdown template for your lab report and starter code for the projects we will work on during the remaining weeks of the course. Create a new branch called lab6-echo-server with git checkout -b lab6-echo-server . Review the first few sections of Real Python: Sockets Programming in Python (through Echo Client and Server ). Complete the questions in the report section below, referencing additional materials as needed. The report template is in the Github repository. Complete the programming tasks: Use the provided code for echo_server.py and echo_client.py to complete the following tasks: Create a server based on the RealPython echo server that implements the four modes of operation described below. Echo input back to client Send a personalized welcome back to the client, e.g., \"world\" => \"Hello, world!\" (1:15:21 in the Python Tutorial video may help with command-line arguments) Parse the first line of an arbitrary HTTP request into a Python dictionary (16:39 in the Python Tutorial video may help with dictionaries) Parse a single HTTP header into a Python dictionary Create a client based on the RealPython echo client and use it to test your server implementation. Test your code to ensure that all parts work as intended. Report \u00b6 Questions 1 - 5 are focused on the Python Sockets library and intended to help you better understand the sample code you are building from. Pay close attention to the reading and cite additional resources as needed. What two values are returned by the accept() function in the Python socket library? Briefly describe the difference between bind(), listen(), and accept()? How can we get a server socket to listen and accept connections on all available IPv4 interfaces and addresses? How do we create a server socket that restricts communication to processes running on the same host? What happens if a client or server calls recv() on a connection, but there isn't any data waiting to be processed? Questions 6 - 10 are focused on character encoding as discussed in the lab. Cite additional resources as needed. How many characters are in the basic ASCII character set? How many bits are required to represent an ASCII character value? How many bytes are used to encode an ASCII value in UTF-8? What is the UTF-8 encoding of your favorite emoji (provide the answer in hex)? Which character encoding is specified by the RFCs for HTTP/1.0 and HTTP/1.1? What line ending is used to delimit request and response headers in HTTP/1.0 and HTTP/1.1? Resources \u00b6 Real Python: Sockets Programming in Python Strings, Unicode, and Bytes in Python 3 Real Python: Python Encodings Guide Line Endings (Wikipedia) CRLF (Mozilla Developer Glossary How HTTP Works under the Hood Hypertext Transfer Protocol -- HTTP/1.0 Hypertext Transfer Protocol -- HTTP/1.1","title":"**Lab 6 - Socket Basics in Python**"},{"location":"labs/sockets/lab6/#lab-6-socket-basics-in-python","text":"Lab 6 Assignment page on Canvas","title":"Lab 6 - Socket Basics in Python"},{"location":"labs/sockets/lab6/#overview","text":"In the remaining weeks of the quarter, we will create a network service using the Python sockets API. In this lab, we will explore the basic use of the sockets API along with some related topics about text and data representation in network protocols. If you need help with getting started with Python, Jarett has created a video tutorial with timestamps for each section here: https://uw.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=685386aa-3431-4e2a-a46a-ab600050535b","title":"Overview"},{"location":"labs/sockets/lab6/#instructions","text":"Accept the Github Classroom assignment and clone the base repository for the assignment using git clone <URL> . This repository contains a markdown template for your lab report and starter code for the projects we will work on during the remaining weeks of the course. Create a new branch called lab6-echo-server with git checkout -b lab6-echo-server . Review the first few sections of Real Python: Sockets Programming in Python (through Echo Client and Server ). Complete the questions in the report section below, referencing additional materials as needed. The report template is in the Github repository. Complete the programming tasks: Use the provided code for echo_server.py and echo_client.py to complete the following tasks: Create a server based on the RealPython echo server that implements the four modes of operation described below. Echo input back to client Send a personalized welcome back to the client, e.g., \"world\" => \"Hello, world!\" (1:15:21 in the Python Tutorial video may help with command-line arguments) Parse the first line of an arbitrary HTTP request into a Python dictionary (16:39 in the Python Tutorial video may help with dictionaries) Parse a single HTTP header into a Python dictionary Create a client based on the RealPython echo client and use it to test your server implementation. Test your code to ensure that all parts work as intended.","title":"Instructions"},{"location":"labs/sockets/lab6/#report","text":"Questions 1 - 5 are focused on the Python Sockets library and intended to help you better understand the sample code you are building from. Pay close attention to the reading and cite additional resources as needed. What two values are returned by the accept() function in the Python socket library? Briefly describe the difference between bind(), listen(), and accept()? How can we get a server socket to listen and accept connections on all available IPv4 interfaces and addresses? How do we create a server socket that restricts communication to processes running on the same host? What happens if a client or server calls recv() on a connection, but there isn't any data waiting to be processed? Questions 6 - 10 are focused on character encoding as discussed in the lab. Cite additional resources as needed. How many characters are in the basic ASCII character set? How many bits are required to represent an ASCII character value? How many bytes are used to encode an ASCII value in UTF-8? What is the UTF-8 encoding of your favorite emoji (provide the answer in hex)? Which character encoding is specified by the RFCs for HTTP/1.0 and HTTP/1.1? What line ending is used to delimit request and response headers in HTTP/1.0 and HTTP/1.1?","title":"Report"},{"location":"labs/sockets/lab6/#resources","text":"Real Python: Sockets Programming in Python Strings, Unicode, and Bytes in Python 3 Real Python: Python Encodings Guide Line Endings (Wikipedia) CRLF (Mozilla Developer Glossary How HTTP Works under the Hood Hypertext Transfer Protocol -- HTTP/1.0 Hypertext Transfer Protocol -- HTTP/1.1","title":"Resources"},{"location":"labs/sockets/lab7/","text":"Lab 7 - proxy part 1 \u00b6 TODO Lab 7 Assignment page on Canvas Python concepts \u00b6 program structure find(), split(), strip() slicing lists / strings try / except dictionary control characters, e.g., \\r\\n Instructions \u00b6 Getting Started \u00b6 As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . HTTP proxies incorporate server and client functionality into a single daemon. As a server, your proxy listens and process the requests it receives from browsers and other HTTP clients. As a client, your proxy will pass the clients' requests on to the intended destination and handle the responses in return. We can implement this behavior by creating both types of sockets within the same application and passing the relevant information between them. In this task, we will work exclusively on the server functionality of the proxy. Specifically, we'll build a server that processes the incoming TCP stream and parses out HTTP GET requests. In future assignments, we'll extend our code to handle other message types and implement the client functionality. Main Loop (Event Loop) \u00b6 To start out this lab, it will be helpful to reference the server logic you created in the main function of your echo server. On the server side, our proxy will build on connection and communication flow we established in that task. Namely, we want to provide a way for a web browser to repeatedly open new connections in order to send HTTP requests and receive the corresponding response (one request/response per connection). Within the echo server, you wrote a loop that would receive the next connection from accept() and begin to process it. This loop is the basis for handling the connections that will be made from web browsers that are configured to speak through the proxy. You should be aware, however, that the connection handling process for a proxy is more complex than what we created for the echo server. To provide a minimally functional echo server, we could get away with making a single call to Socket.recv() per connection. This would accept the first chunk of data received and enable us to echo it back from the client. There are limitations on this approach since it doesn't take advantage of the stream -based nature of a TCP connection (or even fully recognize its constraints). The benefit to us, however, is that we didn't have to think to critically about how to recognize the end of an echo request . Stream-Oriented Protocols and the Sockets API \u00b6 As you move forward in the next few labs, you will need to wrestle with what it means to work with a stream-oriented protocol and the way in which that is implemented within the Sockets API. The main implication of the stream metaphor is that we don't have an easy way to recognize where messages (like HTTP requests and responses) start and end. The only thing we can take for granted when we call Socket.recv() , is that we received a new chunk of data from the stream. Depending on the behavior of the TCP client and server, the chunk of data could represent an entire message (as we assumed for our echo), part of a message, or even multiple messages. Likewise, we need to be aware that a call to Socket.recv() when we have already received everything from the other side will hang until a timeout occurs and the connection is closed. Further discussion of this can be found in the latter sections of the Real Python tutorial In order to read from a stream, you will need to wrap Socket.recv() within an infinite loop, breaking out only when you can determine that you've received a complete message -or- when you detect that the connection is closed from the other side. In order to know where messages begin and end, we have to inspect the incoming bytes based on HTTP message syntax, which will be the primary goal of this lab. This is worth repeating one more time: Important Don't assume that recv() will return a complete HTTP message in one call. The Sockets API does not even guarantee that it will return the full number of bytes you requested, i.e., Socket.recv(1024) returns up to 1024 bytes of data from the stream. Store Incomplete Messages in a Buffer \u00b6 Since it is up to you to identify and reconstruct messages out of the stream, you should create a buffer that will hold your data while you work to identify complete HTTP messages. A buffer in this case is nothing more than a python bytes object that you append to each time a recv() returns successfully, for example: # Declare an empty buffer buffer = b '' while True : data = conn . recv ( 1024 ) # break if the connection was closed if not data : break # add new data to the buffer. buffer = buffer + data Working HTTP Messages \u00b6 In order to recognize HTTP messages, we will attempt to parse our buffer each time we add new data in order to test whether we can read the message through to its proper end. When this operation succeeds, we will be able to move forward into the client portion of the proxy that we'll explore in upcoming labs. While this operation fails, we will continue to receive new data and add it to our buffer as discussed in the previous section. Your main task for this lab is to build a simple HTTP parser that accepts a byte buffer and attempts to parse the most basic type of HTTP message, i.e., an HTTP/1.0 GET request (ignore other types of requests for now). In order to parse a GET request, you will read through the message a line at a time until you receive back-to-back CRLF (HTTP end-of-line) sequences indicating that you've reached the end of the HTTP headers. This task may require a small amount of research into RFC-1945 to review the HTTP/1.0 specification, but it builds directly off of the string and byte manipulation operations you practiced in the previous lab. From a code standpoint, please encapsulate your parsing logic in a function called parse_message . This message should accept a buffer of bytes as input and return two values, i.e., a parsed message stored in a python dictionary and a byte buffer containing data that was left after parsing the message (which could be part of another request). If you are not able to parse the message completely, you can indicate this by returning None and the original byte buffer. Based on this description, your parsing function should resemble: def parse_message ( data ) # initialize an empty dictionary message = {} # parse bytes and assign key / value pairs such as ... message [ 'method' ] = # HTTP method name such as GET message [ 'uri' ] = # address or resource name from the request, such as www.uw.edu message [ 'version' ] = # HTTP version such as HTTP/1.0 message [ 'headers' ] = [] # List of headers # If parsing is successful, return a completed message (if applicable) and unused bytes return message , unparsed_data # If parsing fails, return the entire buffer and an indicator that parsing was incomplete return None , data Parsing \u00b6 HTTP messages follow a relatively simple syntax that can be used to make decisions about how to break the message into smaller parts (using tools like Python slicing and the functions find() , strip() , and split() ). Assume that all messages are conformant with HTTP/1.0 and encoded as ISO-8859-1. For GET requests, the message structure is based entirely around lines and the Carriage Return / New Line line separators (think back to previous labs in which we sent GET requests using netcat). It's tempting for many students to read this and start parsing with a data.split('\\r\\n') . This strategy rarely works. Instead, we recommend that you create a dedicated function to split a single line off the buffer. You can do this with find() , strip() , and slices . Before you go any further, make sure you have a basic understanding of HTTP/1.0 message structure. RFC-1945 is the ultimate authority for message structure, but I recommend checking out the other resources as well for a concise overview of the request/response format. RFC-1945 How HTTP Works under the Hood HTTP syntax overview Output \u00b6 After successfully parsing a request, you should print the following summary and close the connection (return to the start of your loop to listen for new requests). Request summary Connection Source: \\<IP address returned from the call to Socket.accept()> HTTP Method: \\<Name of method, e.g., GET, OPTION, or POST> Destination: \\<URI extracted from the request> Headers: \\<Comma delimited list of header names> Producing a comma-delimited list of header names If you're unfamiliar with python, you might find it challenging to produce the final part of this summary. The following method assumes you've stored your headers in a list, and that each header is parsed into a dictionary with a name and value as presented in the previous lab, i.e., [{'name': 'Host', 'value': 'www.google.com'}, ...] header_names = [ h [ 'name' ] for h in headers ] # loop over all headers and save the name field in a list out = ', ' . join ( header_names ) # join a list of strings with a comma Testing your code with test.py \u00b6 The resources directory of the project repository contains a simple python script called test.py that you can use to send HTTP requests from a file into your proxy code. # Send the request from sample-request.txt # one line at a time with a short delay between python3 test.py 9999 sample-request.txt # Send the request from sample-request.txt 250 bytes at a time # with a short delay between python3 test.py 9999 sample-request.txt 250 Capturing proxied requests for testing \u00b6 A couple of sample requests are included in the directory, but the following method may be helpful if you would like to capture valid requests that you can use for testing: Open ncat to listen for incoming connections, e.g., ncat -o <FILENAME> -l <PORT> Configure Firefox with an HTTP proxy on 127.0.0.1 <PORT> Enter the URL of an HTTP-only site into the FF address bar (the request will hang) Manually stop the request from the browser Verify that the request was captured in ncat (ncat will close automatically)","title":"Lab 7 - proxy part 1"},{"location":"labs/sockets/lab7/#lab-7-proxy-part-1","text":"TODO Lab 7 Assignment page on Canvas","title":"Lab 7 - proxy part 1"},{"location":"labs/sockets/lab7/#python-concepts","text":"program structure find(), split(), strip() slicing lists / strings try / except dictionary control characters, e.g., \\r\\n","title":"Python concepts"},{"location":"labs/sockets/lab7/#instructions","text":"","title":"Instructions"},{"location":"labs/sockets/lab7/#getting-started","text":"As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . HTTP proxies incorporate server and client functionality into a single daemon. As a server, your proxy listens and process the requests it receives from browsers and other HTTP clients. As a client, your proxy will pass the clients' requests on to the intended destination and handle the responses in return. We can implement this behavior by creating both types of sockets within the same application and passing the relevant information between them. In this task, we will work exclusively on the server functionality of the proxy. Specifically, we'll build a server that processes the incoming TCP stream and parses out HTTP GET requests. In future assignments, we'll extend our code to handle other message types and implement the client functionality.","title":"Getting Started"},{"location":"labs/sockets/lab7/#main-loop-event-loop","text":"To start out this lab, it will be helpful to reference the server logic you created in the main function of your echo server. On the server side, our proxy will build on connection and communication flow we established in that task. Namely, we want to provide a way for a web browser to repeatedly open new connections in order to send HTTP requests and receive the corresponding response (one request/response per connection). Within the echo server, you wrote a loop that would receive the next connection from accept() and begin to process it. This loop is the basis for handling the connections that will be made from web browsers that are configured to speak through the proxy. You should be aware, however, that the connection handling process for a proxy is more complex than what we created for the echo server. To provide a minimally functional echo server, we could get away with making a single call to Socket.recv() per connection. This would accept the first chunk of data received and enable us to echo it back from the client. There are limitations on this approach since it doesn't take advantage of the stream -based nature of a TCP connection (or even fully recognize its constraints). The benefit to us, however, is that we didn't have to think to critically about how to recognize the end of an echo request .","title":"Main Loop (Event Loop)"},{"location":"labs/sockets/lab7/#stream-oriented-protocols-and-the-sockets-api","text":"As you move forward in the next few labs, you will need to wrestle with what it means to work with a stream-oriented protocol and the way in which that is implemented within the Sockets API. The main implication of the stream metaphor is that we don't have an easy way to recognize where messages (like HTTP requests and responses) start and end. The only thing we can take for granted when we call Socket.recv() , is that we received a new chunk of data from the stream. Depending on the behavior of the TCP client and server, the chunk of data could represent an entire message (as we assumed for our echo), part of a message, or even multiple messages. Likewise, we need to be aware that a call to Socket.recv() when we have already received everything from the other side will hang until a timeout occurs and the connection is closed. Further discussion of this can be found in the latter sections of the Real Python tutorial In order to read from a stream, you will need to wrap Socket.recv() within an infinite loop, breaking out only when you can determine that you've received a complete message -or- when you detect that the connection is closed from the other side. In order to know where messages begin and end, we have to inspect the incoming bytes based on HTTP message syntax, which will be the primary goal of this lab. This is worth repeating one more time: Important Don't assume that recv() will return a complete HTTP message in one call. The Sockets API does not even guarantee that it will return the full number of bytes you requested, i.e., Socket.recv(1024) returns up to 1024 bytes of data from the stream.","title":"Stream-Oriented Protocols and the Sockets API"},{"location":"labs/sockets/lab7/#store-incomplete-messages-in-a-buffer","text":"Since it is up to you to identify and reconstruct messages out of the stream, you should create a buffer that will hold your data while you work to identify complete HTTP messages. A buffer in this case is nothing more than a python bytes object that you append to each time a recv() returns successfully, for example: # Declare an empty buffer buffer = b '' while True : data = conn . recv ( 1024 ) # break if the connection was closed if not data : break # add new data to the buffer. buffer = buffer + data","title":"Store Incomplete Messages in a Buffer"},{"location":"labs/sockets/lab7/#working-http-messages","text":"In order to recognize HTTP messages, we will attempt to parse our buffer each time we add new data in order to test whether we can read the message through to its proper end. When this operation succeeds, we will be able to move forward into the client portion of the proxy that we'll explore in upcoming labs. While this operation fails, we will continue to receive new data and add it to our buffer as discussed in the previous section. Your main task for this lab is to build a simple HTTP parser that accepts a byte buffer and attempts to parse the most basic type of HTTP message, i.e., an HTTP/1.0 GET request (ignore other types of requests for now). In order to parse a GET request, you will read through the message a line at a time until you receive back-to-back CRLF (HTTP end-of-line) sequences indicating that you've reached the end of the HTTP headers. This task may require a small amount of research into RFC-1945 to review the HTTP/1.0 specification, but it builds directly off of the string and byte manipulation operations you practiced in the previous lab. From a code standpoint, please encapsulate your parsing logic in a function called parse_message . This message should accept a buffer of bytes as input and return two values, i.e., a parsed message stored in a python dictionary and a byte buffer containing data that was left after parsing the message (which could be part of another request). If you are not able to parse the message completely, you can indicate this by returning None and the original byte buffer. Based on this description, your parsing function should resemble: def parse_message ( data ) # initialize an empty dictionary message = {} # parse bytes and assign key / value pairs such as ... message [ 'method' ] = # HTTP method name such as GET message [ 'uri' ] = # address or resource name from the request, such as www.uw.edu message [ 'version' ] = # HTTP version such as HTTP/1.0 message [ 'headers' ] = [] # List of headers # If parsing is successful, return a completed message (if applicable) and unused bytes return message , unparsed_data # If parsing fails, return the entire buffer and an indicator that parsing was incomplete return None , data","title":"Working HTTP Messages"},{"location":"labs/sockets/lab7/#parsing","text":"HTTP messages follow a relatively simple syntax that can be used to make decisions about how to break the message into smaller parts (using tools like Python slicing and the functions find() , strip() , and split() ). Assume that all messages are conformant with HTTP/1.0 and encoded as ISO-8859-1. For GET requests, the message structure is based entirely around lines and the Carriage Return / New Line line separators (think back to previous labs in which we sent GET requests using netcat). It's tempting for many students to read this and start parsing with a data.split('\\r\\n') . This strategy rarely works. Instead, we recommend that you create a dedicated function to split a single line off the buffer. You can do this with find() , strip() , and slices . Before you go any further, make sure you have a basic understanding of HTTP/1.0 message structure. RFC-1945 is the ultimate authority for message structure, but I recommend checking out the other resources as well for a concise overview of the request/response format. RFC-1945 How HTTP Works under the Hood HTTP syntax overview","title":"Parsing"},{"location":"labs/sockets/lab7/#output","text":"After successfully parsing a request, you should print the following summary and close the connection (return to the start of your loop to listen for new requests). Request summary Connection Source: \\<IP address returned from the call to Socket.accept()> HTTP Method: \\<Name of method, e.g., GET, OPTION, or POST> Destination: \\<URI extracted from the request> Headers: \\<Comma delimited list of header names> Producing a comma-delimited list of header names If you're unfamiliar with python, you might find it challenging to produce the final part of this summary. The following method assumes you've stored your headers in a list, and that each header is parsed into a dictionary with a name and value as presented in the previous lab, i.e., [{'name': 'Host', 'value': 'www.google.com'}, ...] header_names = [ h [ 'name' ] for h in headers ] # loop over all headers and save the name field in a list out = ', ' . join ( header_names ) # join a list of strings with a comma","title":"Output"},{"location":"labs/sockets/lab7/#testing-your-code-with-testpy","text":"The resources directory of the project repository contains a simple python script called test.py that you can use to send HTTP requests from a file into your proxy code. # Send the request from sample-request.txt # one line at a time with a short delay between python3 test.py 9999 sample-request.txt # Send the request from sample-request.txt 250 bytes at a time # with a short delay between python3 test.py 9999 sample-request.txt 250","title":"Testing your code with test.py"},{"location":"labs/sockets/lab7/#capturing-proxied-requests-for-testing","text":"A couple of sample requests are included in the directory, but the following method may be helpful if you would like to capture valid requests that you can use for testing: Open ncat to listen for incoming connections, e.g., ncat -o <FILENAME> -l <PORT> Configure Firefox with an HTTP proxy on 127.0.0.1 <PORT> Enter the URL of an HTTP-only site into the FF address bar (the request will hang) Manually stop the request from the browser Verify that the request was captured in ncat (ncat will close automatically)","title":"Capturing proxied requests for testing"},{"location":"labs/sockets/lab8/","text":"Lab 8 - proxy part II \u00b6 TODO Lab 8 Assignment page on Canvas Python concepts \u00b6 Slicing lists / strings Converting strings to/from numbers Creating and using enumerations Format strings, e.g., \"{}: {}\\r\\n\".format(header_name, header_value) Instructions \u00b6 Getting Started \u00b6 As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . In the previous lab, we started to build the server component of your proxy. This component is designed to receive incoming requests from web clients and then eventually forward responses that were received from an upstream web server. The core of the server is established on a request parser, which we also started to develop in the last assignment. In this lab, we'll extend our proxy to recognize more complex HTTP requests and build the logic to forward these requests to the intended target. This will require us to: a) create a new function that can rebuild an HTTP request in byte form based on the dictionary representation generated by your parsing code and b) open a new client socket to a dynamic location each time we receive a request. Parsing Requests (cont.) \u00b6 Extend your parsing function built in the previous lab to handle more complex HTTP requests, such as the POST or PUT type. You'll recall that the GET request structure allows a variable number of CRLF terminated header lines followed by an empty CRLF line. The full HTTP specification allows for an additional message body following the HTTP headers, however there are some important points you need to observe as you handle this part of the HTTP request: While the header portion of the message is ISO-8859-1 encoded per specification, the body/payload should be treated as raw, binary data (even when it looks like standard text-based HTML). Always handle this portion of the request in Python byte form. DO NOT DECODE THE PAYLOAD TO STRING. This will have side effects that can make it impossible to recognize the end of the message. Unlike the header portion of the message, line-endings occuring in the data/payload portion of the HTTP request are coincidental. They do not imply anything about the structure of the message from an HTTP point-of-view. DO NOT SPLIT/STRIP NEWLINES IN THE PAYLOAD. As before, any changes you make to this portion of the message will impact your ability to recognize the message boundary. The structure of a POST, PUT, and other HTTP requests expands on the GET request, allowing a chunk of raw data to be appended after the CRLF that signals the end of the HTTP headers. Unlike the lines that came before, this data is raw, i.e., unstructured, and it will require a different approach based on the expected length of the data. As such, we need to find out the length of the body component before we can determine whether it's been received completely. In HTTP 1.0, the body length is defined by an HTTP header called Content-Length . 1 The value of Content-Length will be a numeric string that defines the length of the body payload. If you see this field while you are parsing your headers, you should record it's value within a variable and add it to your message dictionary, e.g., if header [ 'name' ] == 'Content-Length' : message [ 'Content-Length' ] = int ( header [ 'value' ]) Taking into account that a message may contain a payload, we need to make sure that parse_message waits for the complete payload before returning a valid message back to the main recv() loop. You will need to check for several possible edge cases in order to handle this correctly. If content-length is defined and greater than zero, you need to look at the unparsed portion of the buffer for the message body. If the unparsed portion of the buffer is shorter (see len() ) than content-length, you should return to the recv() loop and wait for the remaining data. If the unparsed portion of the buffer is longer than content-length, the extra bytes should remain in the buffer. If you succeed in parsing a complete message, save the bytes into the message dictionary that contains the other fields you've parsed. Remove all of the correctly parsed bytes from the buffer and return to your main function. As in the previous lab, you should leave the buffer untouched if parsing fails. Return control to your connection handling loop in main and continue to wait for the rest of the message. Get Destination URL \u00b6 Our HTTP/1.0 proxy will expect exactly one HTTP request to be delivered per connection. After our parsing logic determines that we have received a complete/valid message, we can break out of our receiving loop and continue processing the request. Our next step in processing a request is to determine where the browser intended to send the message. We'll use this information in order to open a client socket to the destination server. The information we need to locate the destination is contained in the URI of the request. If you followed the sample code from the previous lab, this value should have been saved as the 'uri' element of the message dictionary. Parsing this field with the Python urllib library will provide us with a host name/address and port that you can use to establish a client socket with the target (see echo-client.py for syntax to open a client socket). Since Python provides a URL parsing module, this is theoretically an easy task. However, it turns out that real browsers produce a variety of edge cases that will cause urllib to choke. In order to constrain the difficulty of this lab, we are providing you with the following function to complete this section. # Be sure to add the import to the top of your code from urllib.parse import urlparse # returns the host and port # run by doing: h, p = parse_uri(dest) def parse_uri ( uri ): uri_parts = urlparse ( uri ) scheme = uri_parts . scheme host = uri_parts . hostname # urlparse can't deal with partial URI's that don't include the # protocol, e.g., push.services.mozilla.com:443 if host : # correctly parsed if uri_parts . port : port = uri_parts . port else : port = socket . getservbyname ( scheme ) else : # incorrectly parsed uri_parts = uri . split ( ':' ) host = uri_parts [ 0 ] if len ( uri ) > 1 : port = int ( uri_parts [ 1 ]) else : port = 80 return host , port Build Message \u00b6 At this point, we have a request, and we know it's destination. The last objective for this week is to create a new function that takes a decomposed message (the dictionary returned from your parser) and generates a new message in byte form. This function is the inverse of the parsing logic you wrote in the last two labs (with one modification for now). 2 The easiest way to rebuild a message from it's parts is to use Python3 format strings, as shown in the example below. At this point, we would like you to make one change to the original request. Regardless of which HTTP version is defined, rebuild the message as an HTTP/1.0 request. def build_message ( message ): # Please note that we are replacing the original version (this is intentional) message_header = ' {} {} {} \\r\\n ' . format ( message [ 'method' ], message [ 'uri' ], 'HTTP/1.0' ) for header in message [ 'headers' ]: data = data + ' {} \\r\\n ' . format ( 'TODO' ) # Format each header properly # Don't forget to add a terminating CRLF # Encode the header portion of the message as bytes # Do you have a message body? Add it back now Client Socket \u00b6 We'll conclude this sequence of tasks by establishing our outbound client socket and sending the request to it's destination. The most important point to remember at this point is how the end-to-end connection flow works. Your main code block should contain a loop to accept connections from browsers. Each connection that you accept will be used to service one outbound request and a corresponding inbound response. The request is received over the server socket you've already established. You used a second loop to call Socket.recv() until you could parse a valid request. Using the parse_uri(request['uri']) function from above, determine the host and port for the outbound client socket. Follow the pattern established in the echo_client to open the connection to this destination. Use build_message(request) to convert the parsed request back into byte form and send it with the Socket.sendall(data) function demonstrated in the echo_client and RealPython guides. Finally, attempt one call to Socket.recv() to try and receive the first part of the response. If you have been successful in receiving and rebuilding the request, you should receive a response immediately from the server. Errors in the preceeding step may result in your proxy hanging (while waiting for a response) or the server resetting the connection due to bad data. We have two more weeks to debug your code. If it breaks here, comment out the final recv() and print a summary of the request you've received as shown below. Output \u00b6 Once all parts of your code are working, print the following summary (replace the output from the previous lab) and close the connection. This will return to the start of your loop to listen for new connections. Request summary Connection Source: < IP address returned from the call to Socket.accept() > HTTP Method: < Name of method, e.g., GET, OPTION, or POST > Destination: < URI extracted from the request > Headers: < Comma delimited list of header names > Target: < Hostname of server obtained from request > Message: < Raw bytes of the rebuilt request > Reponse: < First 50 bytes of the response (if working) > What are these diamonds \"< >\" ? These are placeholders. When you see these it means you should fill in information that is between them and then delete the symbols. It's a quick way of saying \"hey something needs to be filled in\" for the developer world. Testing your code with test.py \u00b6 The resources directory of the project repository contains a simple python script called test.py that you can use to send HTTP requests from a file into your proxy code. # Send the request from sample-request.txt on port 9999 250 bytes at a time with a short delay between python3 test.py 9999 get_request.http 250 Note: Testing at this stage can be more challenging. Please ask for help via the course Slack if you need it. Capturing proxied requests for testing \u00b6 Use the following method to capture valid requests that you can use for testing: Open ncat to listen for incoming connections, e.g., ncat -o <FILENAME> -l <PORT> Configure Firefox with an HTTP proxy on 127.0.0.1 <PORT> Enter the URL of an HTTP-only site into the FF address bar (the request will hang) Manually stop the request from the browser Verify that the request was captured in ncat (ncat will close automatically) This is an oversimplification of the RFC for HTTP/1.0, but it will be sufficient for our purposes. \u21a9 I realize it seems strange to rebuild the message you just spent time tearing apart, but this approach gives you more leverage in terms of what functions your proxy can provide. For example, notice how easily we can modify the HTTP version and add new headers. \u21a9","title":"Lab 8 - proxy part II"},{"location":"labs/sockets/lab8/#lab-8-proxy-part-ii","text":"TODO Lab 8 Assignment page on Canvas","title":"Lab 8 - proxy part II"},{"location":"labs/sockets/lab8/#python-concepts","text":"Slicing lists / strings Converting strings to/from numbers Creating and using enumerations Format strings, e.g., \"{}: {}\\r\\n\".format(header_name, header_value)","title":"Python concepts"},{"location":"labs/sockets/lab8/#instructions","text":"","title":"Instructions"},{"location":"labs/sockets/lab8/#getting-started","text":"As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . In the previous lab, we started to build the server component of your proxy. This component is designed to receive incoming requests from web clients and then eventually forward responses that were received from an upstream web server. The core of the server is established on a request parser, which we also started to develop in the last assignment. In this lab, we'll extend our proxy to recognize more complex HTTP requests and build the logic to forward these requests to the intended target. This will require us to: a) create a new function that can rebuild an HTTP request in byte form based on the dictionary representation generated by your parsing code and b) open a new client socket to a dynamic location each time we receive a request.","title":"Getting Started"},{"location":"labs/sockets/lab8/#parsing-requests-cont","text":"Extend your parsing function built in the previous lab to handle more complex HTTP requests, such as the POST or PUT type. You'll recall that the GET request structure allows a variable number of CRLF terminated header lines followed by an empty CRLF line. The full HTTP specification allows for an additional message body following the HTTP headers, however there are some important points you need to observe as you handle this part of the HTTP request: While the header portion of the message is ISO-8859-1 encoded per specification, the body/payload should be treated as raw, binary data (even when it looks like standard text-based HTML). Always handle this portion of the request in Python byte form. DO NOT DECODE THE PAYLOAD TO STRING. This will have side effects that can make it impossible to recognize the end of the message. Unlike the header portion of the message, line-endings occuring in the data/payload portion of the HTTP request are coincidental. They do not imply anything about the structure of the message from an HTTP point-of-view. DO NOT SPLIT/STRIP NEWLINES IN THE PAYLOAD. As before, any changes you make to this portion of the message will impact your ability to recognize the message boundary. The structure of a POST, PUT, and other HTTP requests expands on the GET request, allowing a chunk of raw data to be appended after the CRLF that signals the end of the HTTP headers. Unlike the lines that came before, this data is raw, i.e., unstructured, and it will require a different approach based on the expected length of the data. As such, we need to find out the length of the body component before we can determine whether it's been received completely. In HTTP 1.0, the body length is defined by an HTTP header called Content-Length . 1 The value of Content-Length will be a numeric string that defines the length of the body payload. If you see this field while you are parsing your headers, you should record it's value within a variable and add it to your message dictionary, e.g., if header [ 'name' ] == 'Content-Length' : message [ 'Content-Length' ] = int ( header [ 'value' ]) Taking into account that a message may contain a payload, we need to make sure that parse_message waits for the complete payload before returning a valid message back to the main recv() loop. You will need to check for several possible edge cases in order to handle this correctly. If content-length is defined and greater than zero, you need to look at the unparsed portion of the buffer for the message body. If the unparsed portion of the buffer is shorter (see len() ) than content-length, you should return to the recv() loop and wait for the remaining data. If the unparsed portion of the buffer is longer than content-length, the extra bytes should remain in the buffer. If you succeed in parsing a complete message, save the bytes into the message dictionary that contains the other fields you've parsed. Remove all of the correctly parsed bytes from the buffer and return to your main function. As in the previous lab, you should leave the buffer untouched if parsing fails. Return control to your connection handling loop in main and continue to wait for the rest of the message.","title":"Parsing Requests (cont.)"},{"location":"labs/sockets/lab8/#get-destination-url","text":"Our HTTP/1.0 proxy will expect exactly one HTTP request to be delivered per connection. After our parsing logic determines that we have received a complete/valid message, we can break out of our receiving loop and continue processing the request. Our next step in processing a request is to determine where the browser intended to send the message. We'll use this information in order to open a client socket to the destination server. The information we need to locate the destination is contained in the URI of the request. If you followed the sample code from the previous lab, this value should have been saved as the 'uri' element of the message dictionary. Parsing this field with the Python urllib library will provide us with a host name/address and port that you can use to establish a client socket with the target (see echo-client.py for syntax to open a client socket). Since Python provides a URL parsing module, this is theoretically an easy task. However, it turns out that real browsers produce a variety of edge cases that will cause urllib to choke. In order to constrain the difficulty of this lab, we are providing you with the following function to complete this section. # Be sure to add the import to the top of your code from urllib.parse import urlparse # returns the host and port # run by doing: h, p = parse_uri(dest) def parse_uri ( uri ): uri_parts = urlparse ( uri ) scheme = uri_parts . scheme host = uri_parts . hostname # urlparse can't deal with partial URI's that don't include the # protocol, e.g., push.services.mozilla.com:443 if host : # correctly parsed if uri_parts . port : port = uri_parts . port else : port = socket . getservbyname ( scheme ) else : # incorrectly parsed uri_parts = uri . split ( ':' ) host = uri_parts [ 0 ] if len ( uri ) > 1 : port = int ( uri_parts [ 1 ]) else : port = 80 return host , port","title":"Get Destination URL"},{"location":"labs/sockets/lab8/#build-message","text":"At this point, we have a request, and we know it's destination. The last objective for this week is to create a new function that takes a decomposed message (the dictionary returned from your parser) and generates a new message in byte form. This function is the inverse of the parsing logic you wrote in the last two labs (with one modification for now). 2 The easiest way to rebuild a message from it's parts is to use Python3 format strings, as shown in the example below. At this point, we would like you to make one change to the original request. Regardless of which HTTP version is defined, rebuild the message as an HTTP/1.0 request. def build_message ( message ): # Please note that we are replacing the original version (this is intentional) message_header = ' {} {} {} \\r\\n ' . format ( message [ 'method' ], message [ 'uri' ], 'HTTP/1.0' ) for header in message [ 'headers' ]: data = data + ' {} \\r\\n ' . format ( 'TODO' ) # Format each header properly # Don't forget to add a terminating CRLF # Encode the header portion of the message as bytes # Do you have a message body? Add it back now","title":"Build Message"},{"location":"labs/sockets/lab8/#client-socket","text":"We'll conclude this sequence of tasks by establishing our outbound client socket and sending the request to it's destination. The most important point to remember at this point is how the end-to-end connection flow works. Your main code block should contain a loop to accept connections from browsers. Each connection that you accept will be used to service one outbound request and a corresponding inbound response. The request is received over the server socket you've already established. You used a second loop to call Socket.recv() until you could parse a valid request. Using the parse_uri(request['uri']) function from above, determine the host and port for the outbound client socket. Follow the pattern established in the echo_client to open the connection to this destination. Use build_message(request) to convert the parsed request back into byte form and send it with the Socket.sendall(data) function demonstrated in the echo_client and RealPython guides. Finally, attempt one call to Socket.recv() to try and receive the first part of the response. If you have been successful in receiving and rebuilding the request, you should receive a response immediately from the server. Errors in the preceeding step may result in your proxy hanging (while waiting for a response) or the server resetting the connection due to bad data. We have two more weeks to debug your code. If it breaks here, comment out the final recv() and print a summary of the request you've received as shown below.","title":"Client Socket"},{"location":"labs/sockets/lab8/#output","text":"Once all parts of your code are working, print the following summary (replace the output from the previous lab) and close the connection. This will return to the start of your loop to listen for new connections. Request summary Connection Source: < IP address returned from the call to Socket.accept() > HTTP Method: < Name of method, e.g., GET, OPTION, or POST > Destination: < URI extracted from the request > Headers: < Comma delimited list of header names > Target: < Hostname of server obtained from request > Message: < Raw bytes of the rebuilt request > Reponse: < First 50 bytes of the response (if working) > What are these diamonds \"< >\" ? These are placeholders. When you see these it means you should fill in information that is between them and then delete the symbols. It's a quick way of saying \"hey something needs to be filled in\" for the developer world.","title":"Output"},{"location":"labs/sockets/lab8/#testing-your-code-with-testpy","text":"The resources directory of the project repository contains a simple python script called test.py that you can use to send HTTP requests from a file into your proxy code. # Send the request from sample-request.txt on port 9999 250 bytes at a time with a short delay between python3 test.py 9999 get_request.http 250 Note: Testing at this stage can be more challenging. Please ask for help via the course Slack if you need it.","title":"Testing your code with test.py"},{"location":"labs/sockets/lab8/#capturing-proxied-requests-for-testing","text":"Use the following method to capture valid requests that you can use for testing: Open ncat to listen for incoming connections, e.g., ncat -o <FILENAME> -l <PORT> Configure Firefox with an HTTP proxy on 127.0.0.1 <PORT> Enter the URL of an HTTP-only site into the FF address bar (the request will hang) Manually stop the request from the browser Verify that the request was captured in ncat (ncat will close automatically) This is an oversimplification of the RFC for HTTP/1.0, but it will be sufficient for our purposes. \u21a9 I realize it seems strange to rebuild the message you just spent time tearing apart, but this approach gives you more leverage in terms of what functions your proxy can provide. For example, notice how easily we can modify the HTTP version and add new headers. \u21a9","title":"Capturing proxied requests for testing"},{"location":"labs/sockets/lab9/","text":"Lab 9 - proxy part III \u00b6 Lab 9 Assignment page on Canvas In this lab, we'll wire together the remaining components of a proxy based on the functionality we have built to parse / reconstruct messages. Instructions \u00b6 Getting Started \u00b6 As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . In the last lab, we completed three major tasks: a) extended our parse_message function to handle different types of HTTP requests, b) created a function to build a message based on the dictionary structure created by the parser, and c) opened a new client socket based for each request received by the proxy. The main objectives of this lab will be to extend parsing functionality to handle HTTP responses as well as requests and to complete our end-to-end message flow. HTTP Version Please confirm that you have followed the instructions in previous labs to downgrade the HTTP version to HTTP/1.0. Newer versions of HTTP have more complicated connection management, where as HTTP/1.0 connections are used for just one request/response. Parsing Responses \u00b6 Structurally, there is almost no difference between an HTTP request with a message body and an HTTP response. In fact, the only difference from your parser's perspective is the order of fields in the first line of the message. 1 If we know the type of message we're parsing before we start, it's easy to extend your parse_message() function to handle HTTP requests and responses. For our needs, this is an easy requirement since the proxy will always know whether it's receiving a request vs. a response based on which socket is in use. To build this functionality for yourself, add a message_type argument to your parser function. Modify the behavior of the function to parse the first line properly based on this argument, and include the message_type in the parsed message. Once you're confident that this is working, update your build_message function to check the type field and produce the appropriate bytes. There are many ways to handle a field like message_type. The most obvious, though inefficient, approach is to simply pass a string value such as REQUEST or RESPONSE and to test for the value when it is used. From a software engineering perspective, we prefer (but don't require) you to use a data type that is built for this purpose, i.e., the enumeration. Enumerations are data types that map a fixed set of values to numeric constants, and they're useful for any type where we need to compare to a predefined list such as the type of socket or the bit flags of a TCP header. While they require a little more effort, enumerations provide advantages in terms of compile-time error detection and run-time efficiency (over string comparisons). The code below demonstrates how to create and use a MessageType enumeration within your code. # Required imports from enum import Enum , auto # Enumeration to represent message types class MessageType ( Enum ): REQUEST = auto () # constant values are auto-assigned RESPONSE = auto () # constant values are auto-assigned # Use the is operator rather than == to test an enumeration \u2026 def parse_message ( data , message_type ): ... message [ 'type' ] = message_type if message [ 'type' ] is MessageType . REQUEST : # parse request fields ... def main (): ... # parse an incoming request parse_message ( buffer , MessageType . REQUEST ) Connection Flow \u00b6 With your parse/build code working correctly, your proxy is almost complete. Turn you attention to completing the connection flow between a browser and the final destination of a request. A summary of this message flow for a single request/response appears below. Upon receipt of a valid request, parse the URI to determine the host and port for the destination server that's been requested by the client. Within your event handling loop, create a client socket to the destination associated with the new request. The host and port are provided by the previous step. Reconstruct the request using the build_message function from the previous lab and send it out over your new client socket. Set up a new loop to listen on this socket until you have received the HTTP response coming back from the web server. As with the original HTTP request, you'll need to keep trying until you can parse the complete request. The browser is still waiting for a response to its request. Reconstruct the response and send it back to the browser over the original server socket. Close the connection to the client and resume waiting for new connections. Testing \u00b6 You may wish to start out using the test.py function for testing purposes in this lab, though its capabilities are limited. In particular, test.py cannot properly send a response in \"line mode\" (you have to provide an integer argument to tell it to break the message into fixed size chunks). When you reach the point that your code returns a successful HTTP response to the test script, you should move on to testing with the browser. Firefox is the easiest browser to use for testing since it provides standalone proxy configuration. Other common browsers rely on OS level configuration for proxies and tend to cause more issues for students. Open Firefox's general preferences/settings page Scroll to the bottom of the page and select Network Settings -> Settings Under Configure Proxy Access to the Internet , select Manual proxy configuration Set the HTTP Proxy to 127.0.0.1 with Port 9999 (match the port you used to run your proxy) Apply your settings and open a new tab to navigate to an HTTP-based site, e.g., http://www.washington.edu/ http://neverssl.com http://mit.edu Output \u00b6 Upon completing this task successfully, your code should proxy a request to a server and return the response back to the client over the existing network connection. If you've done this successfully, the pages should load successfully in your browser when you view a site via unencrypted HTTP. You should also print out a brief summary of each request and response received for troubleshooting purposes. The exact format does not matter -- we will refine the output in the next lab. More information available at HTTP syntax overview \u21a9","title":"Lab 9 - proxy part III"},{"location":"labs/sockets/lab9/#lab-9-proxy-part-iii","text":"Lab 9 Assignment page on Canvas In this lab, we'll wire together the remaining components of a proxy based on the functionality we have built to parse / reconstruct messages.","title":"Lab 9 - proxy part III"},{"location":"labs/sockets/lab9/#instructions","text":"","title":"Instructions"},{"location":"labs/sockets/lab9/#getting-started","text":"As always, create a new branch dedicated to this lab within your http-proxy repository. All code development for this task should take place in http-proxy.py . In the last lab, we completed three major tasks: a) extended our parse_message function to handle different types of HTTP requests, b) created a function to build a message based on the dictionary structure created by the parser, and c) opened a new client socket based for each request received by the proxy. The main objectives of this lab will be to extend parsing functionality to handle HTTP responses as well as requests and to complete our end-to-end message flow. HTTP Version Please confirm that you have followed the instructions in previous labs to downgrade the HTTP version to HTTP/1.0. Newer versions of HTTP have more complicated connection management, where as HTTP/1.0 connections are used for just one request/response.","title":"Getting Started"},{"location":"labs/sockets/lab9/#parsing-responses","text":"Structurally, there is almost no difference between an HTTP request with a message body and an HTTP response. In fact, the only difference from your parser's perspective is the order of fields in the first line of the message. 1 If we know the type of message we're parsing before we start, it's easy to extend your parse_message() function to handle HTTP requests and responses. For our needs, this is an easy requirement since the proxy will always know whether it's receiving a request vs. a response based on which socket is in use. To build this functionality for yourself, add a message_type argument to your parser function. Modify the behavior of the function to parse the first line properly based on this argument, and include the message_type in the parsed message. Once you're confident that this is working, update your build_message function to check the type field and produce the appropriate bytes. There are many ways to handle a field like message_type. The most obvious, though inefficient, approach is to simply pass a string value such as REQUEST or RESPONSE and to test for the value when it is used. From a software engineering perspective, we prefer (but don't require) you to use a data type that is built for this purpose, i.e., the enumeration. Enumerations are data types that map a fixed set of values to numeric constants, and they're useful for any type where we need to compare to a predefined list such as the type of socket or the bit flags of a TCP header. While they require a little more effort, enumerations provide advantages in terms of compile-time error detection and run-time efficiency (over string comparisons). The code below demonstrates how to create and use a MessageType enumeration within your code. # Required imports from enum import Enum , auto # Enumeration to represent message types class MessageType ( Enum ): REQUEST = auto () # constant values are auto-assigned RESPONSE = auto () # constant values are auto-assigned # Use the is operator rather than == to test an enumeration \u2026 def parse_message ( data , message_type ): ... message [ 'type' ] = message_type if message [ 'type' ] is MessageType . REQUEST : # parse request fields ... def main (): ... # parse an incoming request parse_message ( buffer , MessageType . REQUEST )","title":"Parsing Responses"},{"location":"labs/sockets/lab9/#connection-flow","text":"With your parse/build code working correctly, your proxy is almost complete. Turn you attention to completing the connection flow between a browser and the final destination of a request. A summary of this message flow for a single request/response appears below. Upon receipt of a valid request, parse the URI to determine the host and port for the destination server that's been requested by the client. Within your event handling loop, create a client socket to the destination associated with the new request. The host and port are provided by the previous step. Reconstruct the request using the build_message function from the previous lab and send it out over your new client socket. Set up a new loop to listen on this socket until you have received the HTTP response coming back from the web server. As with the original HTTP request, you'll need to keep trying until you can parse the complete request. The browser is still waiting for a response to its request. Reconstruct the response and send it back to the browser over the original server socket. Close the connection to the client and resume waiting for new connections.","title":"Connection Flow"},{"location":"labs/sockets/lab9/#testing","text":"You may wish to start out using the test.py function for testing purposes in this lab, though its capabilities are limited. In particular, test.py cannot properly send a response in \"line mode\" (you have to provide an integer argument to tell it to break the message into fixed size chunks). When you reach the point that your code returns a successful HTTP response to the test script, you should move on to testing with the browser. Firefox is the easiest browser to use for testing since it provides standalone proxy configuration. Other common browsers rely on OS level configuration for proxies and tend to cause more issues for students. Open Firefox's general preferences/settings page Scroll to the bottom of the page and select Network Settings -> Settings Under Configure Proxy Access to the Internet , select Manual proxy configuration Set the HTTP Proxy to 127.0.0.1 with Port 9999 (match the port you used to run your proxy) Apply your settings and open a new tab to navigate to an HTTP-based site, e.g., http://www.washington.edu/ http://neverssl.com http://mit.edu","title":"Testing"},{"location":"labs/sockets/lab9/#output","text":"Upon completing this task successfully, your code should proxy a request to a server and return the response back to the client over the existing network connection. If you've done this successfully, the pages should load successfully in your browser when you view a site via unencrypted HTTP. You should also print out a brief summary of each request and response received for troubleshooting purposes. The exact format does not matter -- we will refine the output in the next lab. More information available at HTTP syntax overview \u21a9","title":"Output"},{"location":"notes/dns-overview/","text":"Domain Name System \u00b6 Overview \u00b6 The domain name system (DNS) is a distributed, hierarchical data store and name resolution service that is used primarily to resolve IP addresses based on much more user-friendly domain names. DNS is a powerful and rather complex system that plays a variety of crucial roles in modern systems and applications. It is so central to these systems that any degradation of service will severely impact the usability of a network-connected computer or mobile device (e.g., resulting in extremely slow boot and application launch times). Our objective is to gain a functional understanding of the system, which we can apply broadly to our work in other areas of the informatics domain. The following videos provide a highly accessible starting point. Pieter Explains Tech https://www.youtube.com/watch?v=GlZC4Jwf3xQ Khan Academy https://www.khanacademy.org/computing/computer-science/internet-intro/internet-works-intro/v/the-internet-ip-addresses-and-dns DNS Namespace and Zones \u00b6 As you've seen, domain names are structured in a hierarchical manner that reflects the decentralized nature of the domain name system. The DNS namespace can be represented by a tree, with branches descending from a common root. A fully-qualified domain name (FQDN) is written by concatenating labels from left-to-right, tracing the path from a leaf node to the root by way of the parent nodes. A trailing dot, representative of the root, is appended to the FQDN for DNS operations though it is omitted in most user-facing applications. Below the root, the top-most level of the graph represents top-level domains (TLD), such as com, net, and edu, that appear at the end of every FQDN. IANA and its parent organization ICANN oversee the governance of the DNS root and top-level domains, though it delegates registration functions and operation of root and TLD name servers to independent organizations. Names appearing as children of each TLD are assigned to organizations through the domain registration process. An organization registers a domain name by working with an ICANN-accredited registrar or a reseller subcontracted by an accredited registrar. https://whois.icann.org/en/domain-name-registration-process Further subdivisions of the registered namespace can be created by the registrant. These subdomains appear as children of the registrant domains in the DNS tree described previously. DNS Zones \u00b6 The hierarchical structure of DNS lends to dividing administrative responsibility of the global namespace. The term \"zone\" refers to these administrative divisions. Each zone in DNS is a contiguous portion of the namespace under the administrative responsibility of a single manager. While zones are often aligned with individual domain registrations, the relationship is not one-to-one. A zone may include multiple domains. Likewise, a domain may be divided into additional zones encapsulating distinct subtrees. The root zone database is managed by IANA and contains the authority records for the TLDs. Likewise, IANA assigns operators for the TLDs. These operators maintain the authoritative database of all domain names and authority records registered in the TLD. These databases are referred to as the DNS registries and can be queried to identify the authoritative nameservers for child zones. DNS Name Servers \u00b6 Each zone, including the root, is hosted by one or more name servers that store collection of resource records associated with the corresponding subset of the DNS namespace. The primary service of root name servers and TLD name servers is to provide information about where to query the next level of the namespace. Roots point to TLD name servers and TLDs point to authoritative name servers for second-level domains. The primary records served by these servers are NS records along with A/AAAA glue records that identify the IP addresses for the provided servers. Likewise, the root and TLD servers distribute records related to DNS Security (DNSSEC) mechanisms. In addition to the root servers and TLD servers described above, resource records for each zone are hosted by at least one authoritative name server. These authoritative name servers may be hosted by the registrant itself or by a third-party DNS hosting service. Many organizations maintain internal, private zones serving records that are only available within well-defined network boundaries. Not all name servers are authoritative for a zone. Plenty of servers are created to satisfy service requirements for performance, redundancy, or security. Recursive name servers are used by clients to resolve DNS requests without having to perform iterative queries of root, TLD, and registrant name servers. When a recursive name server receives a query that it cannot resolve independently, it queries the upper-level zones to find the answer that it returns to the original client. This process can be sped up significantly by caching results, though care must be observed to prevent serving stale records from a cache. https://www.lifewire.com/dns-root-name-servers-3971336 https://www.iana.org/domains/root/servers http://root-servers.org Redundancy and Reliability \u00b6 The modern internet is heavily dependent on DNS, so much so that DNS disruptions and failures can take businesses and users offline. Even seemingly minor performance issues can multiply and cause noticeable delays for networking operations. To combat these issues, many DNS service providers rely heavily on IPv4/v6 Anycast to ensure that a fleet of servers are available to answer queries. These service providers leverage BGP, the dynamic routing protocol of the Internet to assign the same IP address, e.g., 1.1.1.1, to each of their servers scattered around the world. Each DNS request that passes through the Internet will be routed to exactly one of these servers, typically the server that is closest to the sender. http://dyn.com/blog/unicast-vs-anycast-dns-nameserver-routing/ http://blog.catchpoint.com/2015/06/16/dns-anycast/ Protocol \u00b6 As the prior sections have suggested, the DNS protocol is a query response protocol that is used to resolve IP addresses and other metadata stored in resource records based on DNS names. The protocol can be run atop both UDP and TCP for transport and uses port 53 in both cases. Basic DNS queries are most likely to be served over UDP, as this protocol provides the most efficient transport mechanism by avoiding the multi-round trip cost associated with the TCP handshake. The connection-oriented TCP protocol is most likely to be used for responses over 512 bytes to ensure that the message fits in a single datagram. Zone transfers used to transfer domain information between primary and secondary name servers are a common example of TCP-based DNS transactions. The DNS protocol itself is unicast, though a multicast version (mDNS) has been defined to support communication on local networks without the need for supporting infrastructure. Multicast DNS is served on port 5353 of the 224.0.0.251 multicast address. The mDNS protocol was popularized by Apple under the Bonjour trademark, but it has more recently made its way into the most popular mobile and desktop operating systems by way of zeroconf initiatives. Common Resource Record (RR) Types \u00b6 DNS-related RFCs define many different record types for general use and specific applications. We address the most common records here: Start of Authority (SOA) records identify the primary name server and administrator responsible for a given zone as well as version information and base parameters that impact communication between servers in a zone and caching of records related to the zone. Name Server (NS) records indicate which name servers are authoritative for a given zone. These records are also accompanied by so-called glue records that store the IP addresses associated with the server name stored in an NS. Address (A) records are among the most familiar DNS records. Their role is simple in that they associate the IPv4 address of a resource with the server's name. Address records are structured for forward lookup, i.e., resolving the address given the name. A similar, yet separate address record (AAAA) is defined to support IPv6-related queries. Canonical Name (CNAME) records are used to set aliases for existing DNS names rather than directly associating a name with an IP address. These records are commonly used when a resource is hosted by an organization other than the registrant itself and to avoid the necessity of maintaining static IP addresses for these resources. The hostname of a web site that runs on a service like SquareSpace or Wix is likely to point to a CNAME alias that can be resolved to an IP within the parent (service-provider's) domain. Text (TXT) records store additional information required by other protocols. Quite often, TXT records are created to demonstrate ownership of a certain namespace. This action is required, e.g., when attaching a private domain to a hosted service such as Office 365 or GSuite mail. TXT records are also used to store Sender Policy Framework (SPF) records leveraged by SMTP servers to combat email spam. Mail Exchange (MX) records point to SMTP servers for a domain, enabling other SMTP servers to locate and route mail between domains. Each MX record contains the FQDN for a mail host. An associated A (or AAAA) record must exist to resolve the hostname to an IP address. The MX record also contains a preference field, which is used to determine priority among multiple MX records. It is quite common to provide multiple MX records to balance load between mail servers and gain redundancy. Servers with smaller preference values are tried first, while clients are expected to choose randomly between servers with equal preference. The MX record is the starting point for mail configuration. To combat spam and fraud, most organizations will configure SMTP to check for additional records, such as the TXT-based SPF records. Read https://www.rackaid.com/blog/email-dns-records/ to learn more about these applications. Reverse DNS Pointer (PTR) records enable lookups from IPv4 address to hostnames. These reverse lookups are required, or at least recommended, for the proper operation of certain application-level protocols such as email. Additional Topics \u00b6 Tools \u00b6 Dig - https://help.dyn.com/how-to-use-binds-dig-tool/ Nslookup - https://en.wikipedia.org/wiki/Nslookup Whois - https://whois.icann.org/en/dns-and-whois-how-it-works Service Discovery \u00b6 Service (SRV) records are used in conjunction with application layer protocols to identify resources based on role or function rather than hostname. This application is known as Service Discovery (DNS-SD) and is described in RFC 6763. SRV records can be queried just like any other record, though they are identified by a distinct convention of _service._transport in place of a standard host name. Practically speaking, SRV records function much like a general purpose MX pointing to named address records that can be further queried to obtain the IP address for a resource. $ dig -t srv _sip._tls.microsoft.com ; <<>> DiG 9.8.3-P1 <<>> srv _sip._tls.microsoft.com ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 33094 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; QUESTION SECTION: ;_sip._tls.microsoft.com. IN SRV ;; ANSWER SECTION: _sip._tls.microsoft.com. 3600 IN SRV 0 0 443 sip.microsoft.com. ;; ADDITIONAL SECTION: sip.microsoft.com. 895 IN A 167.220.67.163 ;; Query time: 15 msec ;; SERVER: 199.66.140.50#53(199.66.140.50) ;; WHEN: Tue May 9 16:19:39 2017 ;; MSG SIZE rcvd: 98 The preceding query highlights the use of SRV by the session initiation protocol (SIP), a component in voice-over-IP and other types of real-time communication systems that is used to establish connections between peers. https://en.wikipedia.org/wiki/SRV_record https://www.onsip.com/blog/dns-srv-records-sip Security and Privacy \u00b6 The distributed nature of DNS infrastructure offers many benefits. The database is independent of any single network or entity. The load of DNS queries is distributed broadly across many different servers. Clients can query servers that are geographically close to them, reducing overall time for name resolution. Moreover, DNS can withstand many types of failures and disruptions and resists many types of broad scale interference. Nevertheless, DNS has some significant limitations in the realm of security and privacy that are important to understand. In standard DNS, queries and responses are neither encrypted nor authenticated. Targeted manipulation of DNS responses, e.g., spoofing, can be used to direct victims to attacker-controlled resources or to inject advertisements into user traffic. http://erichelgeson.github.io/blog/2013/12/31/i-fought-my-isps-bad-behavior-and-won/ Likewise, passive monitoring reveals significant amounts of information about a victim's identity, beyond just telling us which server they have visited. This type of monitoring is often conducted by network administrators, ISPs, governments, passive observers on wireless networks, and hackers who have managed to hijack network traffic through a MITM attack. https://nakedsecurity.sophos.com/2016/10/05/unmasking-tor-users-with-dns/ https://dnsprivacy.org/wiki/display/DP/DNS+Privacy+-+The+Problem This is a double-edged sword. The same properties of DNS can make it a powerful tool for detecting and preventing malicious attacks. The Cisco Umbrella service (originally OpenDNS), for example, can detect malware infections, phishing scams, and more through sophisticated analysis of DNS queries ( https://umbrella.cisco.com/ ). One approach to securing DNS against privacy incursions is to use a resolver that encrypts connections between clients and recursive servers. The dnscrypt project ( https://dnscrypt.org/ ) provides such a tool, though it is not supported by the vast majority of public DNS servers. More than privacy, the integrity of DNS is arguably the primary concern for most applications. DNSSEC provides a basic integrity mechanism akin to the public key infrastructure and X.509 certificates that underly SSL. DNSSEC is a complex topic and controversial topic. https://www.cloudflare.com/dns/dnssec/how-dnssec-works/ For most users, the most important thing to remember about DNS security is to take steps to protect records under their own purview. Basic DNS security hygiene involves the following tasks: Choosing trustworthy and secure DNS providers Keep DNS registrations active so that attackers cannot hijack the expired domain Limiting access to zone management accounts Implementing strong passwords and secondary authentication mechanisms It's difficult to overstate the importance of these practices. Attackers target DNS to hijack web traffic, entire email systems, and more. For this reason, applications are often deployed with higher-layer integrity mechanisms, e.g., X.509 certificates used in SSL and fingerprinting / key pinning in SSH. These systems, however, are not foolproof. Each has its limitations, therefore DNS security remains a top priority.","title":"Domain Name System (DNS)"},{"location":"notes/dns-overview/#domain-name-system","text":"","title":"Domain Name System"},{"location":"notes/dns-overview/#overview","text":"The domain name system (DNS) is a distributed, hierarchical data store and name resolution service that is used primarily to resolve IP addresses based on much more user-friendly domain names. DNS is a powerful and rather complex system that plays a variety of crucial roles in modern systems and applications. It is so central to these systems that any degradation of service will severely impact the usability of a network-connected computer or mobile device (e.g., resulting in extremely slow boot and application launch times). Our objective is to gain a functional understanding of the system, which we can apply broadly to our work in other areas of the informatics domain. The following videos provide a highly accessible starting point. Pieter Explains Tech https://www.youtube.com/watch?v=GlZC4Jwf3xQ Khan Academy https://www.khanacademy.org/computing/computer-science/internet-intro/internet-works-intro/v/the-internet-ip-addresses-and-dns","title":"Overview"},{"location":"notes/dns-overview/#dns-namespace-and-zones","text":"As you've seen, domain names are structured in a hierarchical manner that reflects the decentralized nature of the domain name system. The DNS namespace can be represented by a tree, with branches descending from a common root. A fully-qualified domain name (FQDN) is written by concatenating labels from left-to-right, tracing the path from a leaf node to the root by way of the parent nodes. A trailing dot, representative of the root, is appended to the FQDN for DNS operations though it is omitted in most user-facing applications. Below the root, the top-most level of the graph represents top-level domains (TLD), such as com, net, and edu, that appear at the end of every FQDN. IANA and its parent organization ICANN oversee the governance of the DNS root and top-level domains, though it delegates registration functions and operation of root and TLD name servers to independent organizations. Names appearing as children of each TLD are assigned to organizations through the domain registration process. An organization registers a domain name by working with an ICANN-accredited registrar or a reseller subcontracted by an accredited registrar. https://whois.icann.org/en/domain-name-registration-process Further subdivisions of the registered namespace can be created by the registrant. These subdomains appear as children of the registrant domains in the DNS tree described previously.","title":"DNS Namespace and Zones"},{"location":"notes/dns-overview/#dns-zones","text":"The hierarchical structure of DNS lends to dividing administrative responsibility of the global namespace. The term \"zone\" refers to these administrative divisions. Each zone in DNS is a contiguous portion of the namespace under the administrative responsibility of a single manager. While zones are often aligned with individual domain registrations, the relationship is not one-to-one. A zone may include multiple domains. Likewise, a domain may be divided into additional zones encapsulating distinct subtrees. The root zone database is managed by IANA and contains the authority records for the TLDs. Likewise, IANA assigns operators for the TLDs. These operators maintain the authoritative database of all domain names and authority records registered in the TLD. These databases are referred to as the DNS registries and can be queried to identify the authoritative nameservers for child zones.","title":"DNS Zones"},{"location":"notes/dns-overview/#dns-name-servers","text":"Each zone, including the root, is hosted by one or more name servers that store collection of resource records associated with the corresponding subset of the DNS namespace. The primary service of root name servers and TLD name servers is to provide information about where to query the next level of the namespace. Roots point to TLD name servers and TLDs point to authoritative name servers for second-level domains. The primary records served by these servers are NS records along with A/AAAA glue records that identify the IP addresses for the provided servers. Likewise, the root and TLD servers distribute records related to DNS Security (DNSSEC) mechanisms. In addition to the root servers and TLD servers described above, resource records for each zone are hosted by at least one authoritative name server. These authoritative name servers may be hosted by the registrant itself or by a third-party DNS hosting service. Many organizations maintain internal, private zones serving records that are only available within well-defined network boundaries. Not all name servers are authoritative for a zone. Plenty of servers are created to satisfy service requirements for performance, redundancy, or security. Recursive name servers are used by clients to resolve DNS requests without having to perform iterative queries of root, TLD, and registrant name servers. When a recursive name server receives a query that it cannot resolve independently, it queries the upper-level zones to find the answer that it returns to the original client. This process can be sped up significantly by caching results, though care must be observed to prevent serving stale records from a cache. https://www.lifewire.com/dns-root-name-servers-3971336 https://www.iana.org/domains/root/servers http://root-servers.org","title":"DNS Name Servers"},{"location":"notes/dns-overview/#redundancy-and-reliability","text":"The modern internet is heavily dependent on DNS, so much so that DNS disruptions and failures can take businesses and users offline. Even seemingly minor performance issues can multiply and cause noticeable delays for networking operations. To combat these issues, many DNS service providers rely heavily on IPv4/v6 Anycast to ensure that a fleet of servers are available to answer queries. These service providers leverage BGP, the dynamic routing protocol of the Internet to assign the same IP address, e.g., 1.1.1.1, to each of their servers scattered around the world. Each DNS request that passes through the Internet will be routed to exactly one of these servers, typically the server that is closest to the sender. http://dyn.com/blog/unicast-vs-anycast-dns-nameserver-routing/ http://blog.catchpoint.com/2015/06/16/dns-anycast/","title":"Redundancy and Reliability"},{"location":"notes/dns-overview/#protocol","text":"As the prior sections have suggested, the DNS protocol is a query response protocol that is used to resolve IP addresses and other metadata stored in resource records based on DNS names. The protocol can be run atop both UDP and TCP for transport and uses port 53 in both cases. Basic DNS queries are most likely to be served over UDP, as this protocol provides the most efficient transport mechanism by avoiding the multi-round trip cost associated with the TCP handshake. The connection-oriented TCP protocol is most likely to be used for responses over 512 bytes to ensure that the message fits in a single datagram. Zone transfers used to transfer domain information between primary and secondary name servers are a common example of TCP-based DNS transactions. The DNS protocol itself is unicast, though a multicast version (mDNS) has been defined to support communication on local networks without the need for supporting infrastructure. Multicast DNS is served on port 5353 of the 224.0.0.251 multicast address. The mDNS protocol was popularized by Apple under the Bonjour trademark, but it has more recently made its way into the most popular mobile and desktop operating systems by way of zeroconf initiatives.","title":"Protocol"},{"location":"notes/dns-overview/#common-resource-record-rr-types","text":"DNS-related RFCs define many different record types for general use and specific applications. We address the most common records here: Start of Authority (SOA) records identify the primary name server and administrator responsible for a given zone as well as version information and base parameters that impact communication between servers in a zone and caching of records related to the zone. Name Server (NS) records indicate which name servers are authoritative for a given zone. These records are also accompanied by so-called glue records that store the IP addresses associated with the server name stored in an NS. Address (A) records are among the most familiar DNS records. Their role is simple in that they associate the IPv4 address of a resource with the server's name. Address records are structured for forward lookup, i.e., resolving the address given the name. A similar, yet separate address record (AAAA) is defined to support IPv6-related queries. Canonical Name (CNAME) records are used to set aliases for existing DNS names rather than directly associating a name with an IP address. These records are commonly used when a resource is hosted by an organization other than the registrant itself and to avoid the necessity of maintaining static IP addresses for these resources. The hostname of a web site that runs on a service like SquareSpace or Wix is likely to point to a CNAME alias that can be resolved to an IP within the parent (service-provider's) domain. Text (TXT) records store additional information required by other protocols. Quite often, TXT records are created to demonstrate ownership of a certain namespace. This action is required, e.g., when attaching a private domain to a hosted service such as Office 365 or GSuite mail. TXT records are also used to store Sender Policy Framework (SPF) records leveraged by SMTP servers to combat email spam. Mail Exchange (MX) records point to SMTP servers for a domain, enabling other SMTP servers to locate and route mail between domains. Each MX record contains the FQDN for a mail host. An associated A (or AAAA) record must exist to resolve the hostname to an IP address. The MX record also contains a preference field, which is used to determine priority among multiple MX records. It is quite common to provide multiple MX records to balance load between mail servers and gain redundancy. Servers with smaller preference values are tried first, while clients are expected to choose randomly between servers with equal preference. The MX record is the starting point for mail configuration. To combat spam and fraud, most organizations will configure SMTP to check for additional records, such as the TXT-based SPF records. Read https://www.rackaid.com/blog/email-dns-records/ to learn more about these applications. Reverse DNS Pointer (PTR) records enable lookups from IPv4 address to hostnames. These reverse lookups are required, or at least recommended, for the proper operation of certain application-level protocols such as email.","title":"Common Resource Record (RR) Types"},{"location":"notes/dns-overview/#additional-topics","text":"","title":"Additional Topics"},{"location":"notes/dns-overview/#tools","text":"Dig - https://help.dyn.com/how-to-use-binds-dig-tool/ Nslookup - https://en.wikipedia.org/wiki/Nslookup Whois - https://whois.icann.org/en/dns-and-whois-how-it-works","title":"Tools"},{"location":"notes/dns-overview/#service-discovery","text":"Service (SRV) records are used in conjunction with application layer protocols to identify resources based on role or function rather than hostname. This application is known as Service Discovery (DNS-SD) and is described in RFC 6763. SRV records can be queried just like any other record, though they are identified by a distinct convention of _service._transport in place of a standard host name. Practically speaking, SRV records function much like a general purpose MX pointing to named address records that can be further queried to obtain the IP address for a resource. $ dig -t srv _sip._tls.microsoft.com ; <<>> DiG 9.8.3-P1 <<>> srv _sip._tls.microsoft.com ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 33094 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; QUESTION SECTION: ;_sip._tls.microsoft.com. IN SRV ;; ANSWER SECTION: _sip._tls.microsoft.com. 3600 IN SRV 0 0 443 sip.microsoft.com. ;; ADDITIONAL SECTION: sip.microsoft.com. 895 IN A 167.220.67.163 ;; Query time: 15 msec ;; SERVER: 199.66.140.50#53(199.66.140.50) ;; WHEN: Tue May 9 16:19:39 2017 ;; MSG SIZE rcvd: 98 The preceding query highlights the use of SRV by the session initiation protocol (SIP), a component in voice-over-IP and other types of real-time communication systems that is used to establish connections between peers. https://en.wikipedia.org/wiki/SRV_record https://www.onsip.com/blog/dns-srv-records-sip","title":"Service Discovery"},{"location":"notes/dns-overview/#security-and-privacy","text":"The distributed nature of DNS infrastructure offers many benefits. The database is independent of any single network or entity. The load of DNS queries is distributed broadly across many different servers. Clients can query servers that are geographically close to them, reducing overall time for name resolution. Moreover, DNS can withstand many types of failures and disruptions and resists many types of broad scale interference. Nevertheless, DNS has some significant limitations in the realm of security and privacy that are important to understand. In standard DNS, queries and responses are neither encrypted nor authenticated. Targeted manipulation of DNS responses, e.g., spoofing, can be used to direct victims to attacker-controlled resources or to inject advertisements into user traffic. http://erichelgeson.github.io/blog/2013/12/31/i-fought-my-isps-bad-behavior-and-won/ Likewise, passive monitoring reveals significant amounts of information about a victim's identity, beyond just telling us which server they have visited. This type of monitoring is often conducted by network administrators, ISPs, governments, passive observers on wireless networks, and hackers who have managed to hijack network traffic through a MITM attack. https://nakedsecurity.sophos.com/2016/10/05/unmasking-tor-users-with-dns/ https://dnsprivacy.org/wiki/display/DP/DNS+Privacy+-+The+Problem This is a double-edged sword. The same properties of DNS can make it a powerful tool for detecting and preventing malicious attacks. The Cisco Umbrella service (originally OpenDNS), for example, can detect malware infections, phishing scams, and more through sophisticated analysis of DNS queries ( https://umbrella.cisco.com/ ). One approach to securing DNS against privacy incursions is to use a resolver that encrypts connections between clients and recursive servers. The dnscrypt project ( https://dnscrypt.org/ ) provides such a tool, though it is not supported by the vast majority of public DNS servers. More than privacy, the integrity of DNS is arguably the primary concern for most applications. DNSSEC provides a basic integrity mechanism akin to the public key infrastructure and X.509 certificates that underly SSL. DNSSEC is a complex topic and controversial topic. https://www.cloudflare.com/dns/dnssec/how-dnssec-works/ For most users, the most important thing to remember about DNS security is to take steps to protect records under their own purview. Basic DNS security hygiene involves the following tasks: Choosing trustworthy and secure DNS providers Keep DNS registrations active so that attackers cannot hijack the expired domain Limiting access to zone management accounts Implementing strong passwords and secondary authentication mechanisms It's difficult to overstate the importance of these practices. Attackers target DNS to hijack web traffic, entire email systems, and more. For this reason, applications are often deployed with higher-layer integrity mechanisms, e.g., X.509 certificates used in SSL and fingerprinting / key pinning in SSH. These systems, however, are not foolproof. Each has its limitations, therefore DNS security remains a top priority.","title":"Security and Privacy"},{"location":"notes/ethernet-switches/","text":"Key concepts: Shared transmission medium, topology, hub, congestion, collision domain, broadcast domain, segment (layer-2), bridge, switch, forwarding information base (FIB) Introduction \u00b6 Ethernet switches are one of the most widely deployed network components, providing physical ports for attaching other network components or endpoints at the data-link layer of the TCP/IP stack. Barring advanced configurations, devices that are attached through switching infrastructure are part of the same layer-2 network and can communicate directy through the switch using layer-2 addresses. Collisions and Media Access Control \u00b6 Switches are not the only layer-2 game in town for wired Ethernet, though they are one of the few you should even consider in 2020. Once upon a time we connected devices in a bus configuration, where each node would tap into a segment of coaxial cable or other suitable transmission medium. In this configuration, the bus provides a resource that must be shared between all nodes attached to it. One consequence of this configuration is that data frames are visible to every other node since the signal is transmitted across the entire bus. Likewise, since the bus is shared, collisions between data frames may occur when nodes try to use the resource at the same time. For this reason, we say that bus represents a single collision domain . Ethernet copes with collisions using a media access control (MAC) mechanism that allows the NIC to identify a failure and make another attempt after a variable delay. This mechanism is known as Carrier Sense Multiple Access with Collision Detection (CSMA/CD) . While CSMA/CD enables the network to continue functioning despite collisions, congestion occur as the shared medium becomes more contested. A highly congested network is inefficient since failures and retransmission consume an increasing amount of its bandwidth. Star Topology \u00b6 Congestion is not the only architectural concern associated with the bus topology. Physical challenges such as signal interference and attenuation limit the overall length of a bus. As such, the layout of the bus relative to the physical location of each node must be carefully planned. Hubs alleviated these latter concerns by offering a more flexible topology. In a star topology , multiple nodes connect back to a central point through dedicated, indepenent links, e.g., lengths of CAT-5 cable. Beneath the hood, hubs still operate on the underlying principle of transmitting signals across an entire network segment. In fact, each port of a hub acts as a repeater for the physical signals that were received on other ports. As such, hubs do not eliminate the concern of congestion and collisions or snooping on communication within a segment since endpoints connected by hubs are still members of a single collision domain. Bridging and Switches \u00b6 Bridging provide a layer-2 solution to the congestion problem by splitting a network into independent collision domains and intelligently forwarding frames between these layer-2 segments . When a bridge observes a frame on one of its ports, it inspects Ethernet headers to learn about the topology of the network based on the MAC address of the sender. The bridge uses the information it learns about the topology to optimize forwarding, which is only necessary when the recipient and sender are on different segments. xxx NO CHANGES TO ETHERNET Classic Ethernet bridges provides two ports/collision domains and are rarely seen in modern networks. A switch combines multiple bridges in a device that physically resembles a hub. Unlike a hub, however, each switch port represents a distinct segment on its own collision domain. From a performance perspective, a well-placed bridge can reduce the amount of activity on a domain by about half (discounting for broadcast traffic). Adding more bridges further improves the situation. In a switched network, every link is isolated within an independent collision domain, allowing a much greater level of overall throughput on the network. Forwarding Mechanics \u00b6 The forwarding mechanics of a switch are identical to a bridge. As switches learn the topology of a layer-2 network, they populate a Forwarding Information Base (FIB) with MAC/port associations. Until a switch knows which port is associated with a particular destination MAC address, a frame received on one port will be flooded over every other port on the switch. Broadcast Domains \u00b6 As we've seen, switches support standard Ethernet modes of communication between all nodes of the layer-2 network based on MAC address. Virtual LAN (VLAN) \u00b6 VLANs provide a solution to isolate broadcast domains from one another without requiring an investment of dedicated hardware for each domain. In the simplest sense, VLANs provide virtual separation of broadcast domains by identifying switch ports as VLAN members and referencing this configuration to enforce the separation of ethernet traffic. A switch configured with more than one VLAN behaves like multiple standalone switches. The ports assigned to a given VLAN maintain their own view of the FIB that is based only on the MAC addresses seen on those ports. In port-based VLANs, which use the mode of operation described above, a router would need to be attached to each set of ports to assign forwarding across the VLAN boundary. Many switches, support a more dynamic mode that enables network-attached devices to distinguish between traffic from multiple VLANs running over a single link. Links that carry traffic for multiple VLANs are called trunks (the associated switch ports are called trunk ports). With trunking, connections between infrastructure components is simplified since multiple broadcast domains can be collapsed onto a single physical link. Trunks generally rely on tags (as specified in 802.1q) to control distribution of frames over VLANs. Despite implementation differences, tag and port-based VLANs obey the same rules. Layer-2 frames received on any port/tag are only distributed within the associated VLAN. Switch Architecture Planning \u00b6 Larger networks require multi-tier switch deployments to satisfy the requirements of core communication, distribution, and network access. Switches at the access tier need to provide enough port density to support endpoints in the network. Switches participating in the distribution tier of the network architecture may prioritize VLAN trunking, basic redundancy, and incorporate layer-3 functionality to handle routing and security policies internally. Core functionality will likely incorporate multiple levels of redundancy and higher capacity links. Redundancy and Switch Loops \u00b6 Redundancy is a common requirement in network infrastructure for the corporate world. Organizations have a greater dependence on information technology and a low threshold for system outages that disrupt operations or productivity. In LAN design, we need to plan for redundant components and links based on the impact of a failure at a given point in the network. Redundancy at this layer has an interesting effect with regard to forwarding behavior. A frame that passes through one side of a redundant connection is expected to return to the switch through the other side of the connection. This situation is commonly known as a switching loop. Frames that are caught in a loop degrade the performance of the switches involved. Broadcast traffic exacerbates the problem and may create a broadcast storm. Spanning tree protocol (STP) is present on many business-grade switches to alleviate this problem. FIBs sometimes referred to as a MAC address table or a CAM table. CAM stands for content addressable memory, which is the implementation mechanism used for the FIB on many switches. \u21a9","title":"Ethernet Switches"},{"location":"notes/ethernet-switches/#introduction","text":"Ethernet switches are one of the most widely deployed network components, providing physical ports for attaching other network components or endpoints at the data-link layer of the TCP/IP stack. Barring advanced configurations, devices that are attached through switching infrastructure are part of the same layer-2 network and can communicate directy through the switch using layer-2 addresses.","title":"Introduction"},{"location":"notes/ethernet-switches/#collisions-and-media-access-control","text":"Switches are not the only layer-2 game in town for wired Ethernet, though they are one of the few you should even consider in 2020. Once upon a time we connected devices in a bus configuration, where each node would tap into a segment of coaxial cable or other suitable transmission medium. In this configuration, the bus provides a resource that must be shared between all nodes attached to it. One consequence of this configuration is that data frames are visible to every other node since the signal is transmitted across the entire bus. Likewise, since the bus is shared, collisions between data frames may occur when nodes try to use the resource at the same time. For this reason, we say that bus represents a single collision domain . Ethernet copes with collisions using a media access control (MAC) mechanism that allows the NIC to identify a failure and make another attempt after a variable delay. This mechanism is known as Carrier Sense Multiple Access with Collision Detection (CSMA/CD) . While CSMA/CD enables the network to continue functioning despite collisions, congestion occur as the shared medium becomes more contested. A highly congested network is inefficient since failures and retransmission consume an increasing amount of its bandwidth.","title":"Collisions and Media Access Control"},{"location":"notes/ethernet-switches/#star-topology","text":"Congestion is not the only architectural concern associated with the bus topology. Physical challenges such as signal interference and attenuation limit the overall length of a bus. As such, the layout of the bus relative to the physical location of each node must be carefully planned. Hubs alleviated these latter concerns by offering a more flexible topology. In a star topology , multiple nodes connect back to a central point through dedicated, indepenent links, e.g., lengths of CAT-5 cable. Beneath the hood, hubs still operate on the underlying principle of transmitting signals across an entire network segment. In fact, each port of a hub acts as a repeater for the physical signals that were received on other ports. As such, hubs do not eliminate the concern of congestion and collisions or snooping on communication within a segment since endpoints connected by hubs are still members of a single collision domain.","title":"Star Topology"},{"location":"notes/ethernet-switches/#bridging-and-switches","text":"Bridging provide a layer-2 solution to the congestion problem by splitting a network into independent collision domains and intelligently forwarding frames between these layer-2 segments . When a bridge observes a frame on one of its ports, it inspects Ethernet headers to learn about the topology of the network based on the MAC address of the sender. The bridge uses the information it learns about the topology to optimize forwarding, which is only necessary when the recipient and sender are on different segments. xxx NO CHANGES TO ETHERNET Classic Ethernet bridges provides two ports/collision domains and are rarely seen in modern networks. A switch combines multiple bridges in a device that physically resembles a hub. Unlike a hub, however, each switch port represents a distinct segment on its own collision domain. From a performance perspective, a well-placed bridge can reduce the amount of activity on a domain by about half (discounting for broadcast traffic). Adding more bridges further improves the situation. In a switched network, every link is isolated within an independent collision domain, allowing a much greater level of overall throughput on the network.","title":"Bridging and Switches"},{"location":"notes/ethernet-switches/#forwarding-mechanics","text":"The forwarding mechanics of a switch are identical to a bridge. As switches learn the topology of a layer-2 network, they populate a Forwarding Information Base (FIB) with MAC/port associations. Until a switch knows which port is associated with a particular destination MAC address, a frame received on one port will be flooded over every other port on the switch.","title":"Forwarding Mechanics"},{"location":"notes/ethernet-switches/#broadcast-domains","text":"As we've seen, switches support standard Ethernet modes of communication between all nodes of the layer-2 network based on MAC address.","title":"Broadcast Domains"},{"location":"notes/ethernet-switches/#virtual-lan-vlan","text":"VLANs provide a solution to isolate broadcast domains from one another without requiring an investment of dedicated hardware for each domain. In the simplest sense, VLANs provide virtual separation of broadcast domains by identifying switch ports as VLAN members and referencing this configuration to enforce the separation of ethernet traffic. A switch configured with more than one VLAN behaves like multiple standalone switches. The ports assigned to a given VLAN maintain their own view of the FIB that is based only on the MAC addresses seen on those ports. In port-based VLANs, which use the mode of operation described above, a router would need to be attached to each set of ports to assign forwarding across the VLAN boundary. Many switches, support a more dynamic mode that enables network-attached devices to distinguish between traffic from multiple VLANs running over a single link. Links that carry traffic for multiple VLANs are called trunks (the associated switch ports are called trunk ports). With trunking, connections between infrastructure components is simplified since multiple broadcast domains can be collapsed onto a single physical link. Trunks generally rely on tags (as specified in 802.1q) to control distribution of frames over VLANs. Despite implementation differences, tag and port-based VLANs obey the same rules. Layer-2 frames received on any port/tag are only distributed within the associated VLAN.","title":"Virtual LAN (VLAN)"},{"location":"notes/ethernet-switches/#switch-architecture-planning","text":"Larger networks require multi-tier switch deployments to satisfy the requirements of core communication, distribution, and network access. Switches at the access tier need to provide enough port density to support endpoints in the network. Switches participating in the distribution tier of the network architecture may prioritize VLAN trunking, basic redundancy, and incorporate layer-3 functionality to handle routing and security policies internally. Core functionality will likely incorporate multiple levels of redundancy and higher capacity links.","title":"Switch Architecture Planning"},{"location":"notes/ethernet-switches/#redundancy-and-switch-loops","text":"Redundancy is a common requirement in network infrastructure for the corporate world. Organizations have a greater dependence on information technology and a low threshold for system outages that disrupt operations or productivity. In LAN design, we need to plan for redundant components and links based on the impact of a failure at a given point in the network. Redundancy at this layer has an interesting effect with regard to forwarding behavior. A frame that passes through one side of a redundant connection is expected to return to the switch through the other side of the connection. This situation is commonly known as a switching loop. Frames that are caught in a loop degrade the performance of the switches involved. Broadcast traffic exacerbates the problem and may create a broadcast storm. Spanning tree protocol (STP) is present on many business-grade switches to alleviate this problem. FIBs sometimes referred to as a MAC address table or a CAM table. CAM stands for content addressable memory, which is the implementation mechanism used for the FIB on many switches. \u21a9","title":"Redundancy and Switch Loops"},{"location":"notes/router-overview/","text":"Routers \u00b6 Routers and routing are frequent topics when we discuss networking, and it is all too easy for newcomers to overlook or misunderstand some of the assumptions we make about these terms. Let\u2019s take a step back and review the fundamentals. What is a Router \u00b6 A router is a computing device that is attached to two or more networks and is set up so that it can forward packets from one network to another. Both of these conditions are necessary in order for us to call something a router. You might think that all routers are special purpose, embedded devices like the ones you see on most home or office networks. In reality, most computers 1 are capable of routing, so long as the hardware supports multiple network connections and the software supports forwarding between networks. Routers vs Multi-homed Hosts \u00b6 It is not uncommon for a device to be connected to multiple networks without being configured to route traffic. A device with this configuration, e.g., your Pi prior to checkpoint #3, is known as a multi-homed host. A non-routing, multi-homed hosts will drop packets that aren\u2019t directly addressed to it at both Layer-2 (MAC address) and Layer-3 (IP address). This behavior is exactly the same as an ordinary host attached to a single network. Routers and Incoming Packets \u00b6 On an ethernet-based network, a router will process any frame for which the destination MAC address matches the MAC of the NIC on which the frame was received. After processing Layer-2, the router examines the packet\u2019s IP headers. Assuming that the destination IP address is not a match for the router\u2019s IP address, the router will consult its route table in order to forward the packet closer to its final destination. Packets addressed directly to the router will continue to be processed so that they can be delivered to an internal process via a socket. Routers and Outgoing Packets \u00b6 Most of the unique magic that distinguishes routers from ordinary hosts takes place on inbound packets. You might be surprised to learn that the process of sending a packet is the same for packets from local applications as it is for packets forwarded between networks. No matter where a packet comes from or where it is going, packet-communication occurs on a hop-by-hop basis. Every host starts this process by comparing its destination address to entries defined in its own routing table. Matches are identified when the network bits of the destination match a network id in the based on the correspondence netmask or CIDR defined in the routing table 2 . After finding a match, the network stack can start the process of forwarding to the next hop. If the final destination is on a directly attached network, ARP is used to determine the MAC address of the destination and the packet will be forwarded directly. Otherwise, the routing table can be used to find a next hop IP address for a directly attached network. Once again, with the next hop IP, ARP can be used to determine the MAC address so that the packet can be forwarded directly. Terminology \u00b6 Routing terminology is a common sticking point for many students and professionals. In particular, it can be useful to understand the finer distinctions between the terms routing and forwarding . At Layer-3, the word forwarding describes the mechanics of passing an inbound packet from its origin interface back onto a different network through an outbound interface. The mechanics of finding a matching route and pushing the packet out the appropriate interface are all part of the forwarding process. In contrast, routing refers to the entire end-to-end process that gets a packet to the right place. When we say most computers, we mean it. Have you ever used your mobile phone as a hotspot for your tablet or computer? Give it a shot, and if you\u2019re able, use traceroute or tracert to observe the routing process in action. \u21a9 It is possible for a routing table to find multiple matches. In this case, ties are broken by looking for the most specific entry, i.e., the longest matching network prefix. Other metrics may be used if there are multiple entries for a given network ID. \u21a9","title":"Routers"},{"location":"notes/router-overview/#routers","text":"Routers and routing are frequent topics when we discuss networking, and it is all too easy for newcomers to overlook or misunderstand some of the assumptions we make about these terms. Let\u2019s take a step back and review the fundamentals.","title":"Routers"},{"location":"notes/router-overview/#what-is-a-router","text":"A router is a computing device that is attached to two or more networks and is set up so that it can forward packets from one network to another. Both of these conditions are necessary in order for us to call something a router. You might think that all routers are special purpose, embedded devices like the ones you see on most home or office networks. In reality, most computers 1 are capable of routing, so long as the hardware supports multiple network connections and the software supports forwarding between networks.","title":"What is a Router"},{"location":"notes/router-overview/#routers-vs-multi-homed-hosts","text":"It is not uncommon for a device to be connected to multiple networks without being configured to route traffic. A device with this configuration, e.g., your Pi prior to checkpoint #3, is known as a multi-homed host. A non-routing, multi-homed hosts will drop packets that aren\u2019t directly addressed to it at both Layer-2 (MAC address) and Layer-3 (IP address). This behavior is exactly the same as an ordinary host attached to a single network.","title":"Routers vs Multi-homed Hosts"},{"location":"notes/router-overview/#routers-and-incoming-packets","text":"On an ethernet-based network, a router will process any frame for which the destination MAC address matches the MAC of the NIC on which the frame was received. After processing Layer-2, the router examines the packet\u2019s IP headers. Assuming that the destination IP address is not a match for the router\u2019s IP address, the router will consult its route table in order to forward the packet closer to its final destination. Packets addressed directly to the router will continue to be processed so that they can be delivered to an internal process via a socket.","title":"Routers and Incoming Packets"},{"location":"notes/router-overview/#routers-and-outgoing-packets","text":"Most of the unique magic that distinguishes routers from ordinary hosts takes place on inbound packets. You might be surprised to learn that the process of sending a packet is the same for packets from local applications as it is for packets forwarded between networks. No matter where a packet comes from or where it is going, packet-communication occurs on a hop-by-hop basis. Every host starts this process by comparing its destination address to entries defined in its own routing table. Matches are identified when the network bits of the destination match a network id in the based on the correspondence netmask or CIDR defined in the routing table 2 . After finding a match, the network stack can start the process of forwarding to the next hop. If the final destination is on a directly attached network, ARP is used to determine the MAC address of the destination and the packet will be forwarded directly. Otherwise, the routing table can be used to find a next hop IP address for a directly attached network. Once again, with the next hop IP, ARP can be used to determine the MAC address so that the packet can be forwarded directly.","title":"Routers and Outgoing Packets"},{"location":"notes/router-overview/#terminology","text":"Routing terminology is a common sticking point for many students and professionals. In particular, it can be useful to understand the finer distinctions between the terms routing and forwarding . At Layer-3, the word forwarding describes the mechanics of passing an inbound packet from its origin interface back onto a different network through an outbound interface. The mechanics of finding a matching route and pushing the packet out the appropriate interface are all part of the forwarding process. In contrast, routing refers to the entire end-to-end process that gets a packet to the right place. When we say most computers, we mean it. Have you ever used your mobile phone as a hotspot for your tablet or computer? Give it a shot, and if you\u2019re able, use traceroute or tracert to observe the routing process in action. \u21a9 It is possible for a routing table to find multiple matches. In this case, ties are broken by looking for the most specific entry, i.e., the longest matching network prefix. Other metrics may be used if there are multiple entries for a given network ID. \u21a9","title":"Terminology"},{"location":"resources/address-planning/","text":"Basic IP Address Planning (2022-04-04) \u00b6 Don't try to build a network without a plan. A good network design is built on parameters and constraints that are appropriate for the intended use-cases. This guide offers a simple procedure that can serve as a starting point for basic planning with a single subnet network. Private versus Public \u00b6 We can't pull addresses from thin air. The laws of the TCP/IP universe restrict what addresses we can use on networks we can control. Make sure that you understand where addresses come from and can distinguish between private and public address space. Private Address Ranges Within the boundaries of our own network, we are relatively free to set our rules as long as we use addresses that are reserved for private use. Your reference point for these addresses is RFC-1918 . Public Address Ranges For packets we send on the public Internet, we must use public addresses that are in our control. These addresses will either be leased (short-term or long-term reservation) to us by an ISP or allocated on a more permanent basis by a Regional Internet Registry (RIR) 1 . A contiguous group of addresses allocated in this way is referred to as a block . Special Address Ranges Beyond these two ranges, we frequently encounter other address ranges that are reserved for special use-cases, e.g., the loopback (127.0.0.0/8) and link-local (169.254.0.0/16) address ranges. RFC-6890 Configuration Strategies \u00b6 As you get started, you will need to make decisions about how you will configure devices on your network with appropriate IP addresses and network parameters. Before you proceed, make sure that you understand the following classifications. Leased Addresses As much as possible, you'll want to avoid the need for manual configuration when a new device joins the network. DHCP allows you to allocate a range of addresses that the server can use to issue address leases to hosts that request them. Leased addresses are dynamic in the sense that they aren't determined until a host joins the network and initiates the DHCP process. Static Addresses Dynamic address assignment won't work for every scenario, e.g., when an address should be fixed and a dependency on DHCP isn't possible. Some devices, including your network gateway and the DHCP server itself should be manually configured. We describe their addresses as static because they are defined through the network node's own configuration and won't change based on external factors. Procedure \u00b6 Step 1 - Examine address needs \u00b6 Determine the size of your network, i.e., the number of devices that will need addresses at any given point in time, and document the types of devices you expect to service as well as their address requirements. Don't forget to account for network infrastructure and additional growth. Not all devices on a network are the same, and so you will often have clients with different address needs. End users on their computers and mobile devices will almost always receive dynamic (leased) addresses, but you might need to reserve some address space for static addresses to acommodate web servers, mail servers, or even (sometimes) printers. Your network infrastructure consists of routers, essential services like DHCP and DNS, as well as managed switches and access points. In very simple networks, these services may live on the same device and share a single IP address. More sophisticated networks will split these services onto dedicated devices, or at the very least, assign them dedicated IP addresses. Always assume that your network will grow over time. Allocate additional address space in anticipation of this growth. If you have believe that you will need 30 addresses today, it's probably safer to plan for at least 60 addresses. Step 2 - Identify the base address range \u00b6 Identify the base address range from which you will be subnetting. If you do not have a permanent allocation, select a block from the RFC-1918 address range. Step 3 - Select subnet parameters \u00b6 Based on the inventory you conducted in step #1, determine the number of address bits that are required in order to give an address to each host on your LAN. You can use this number to determine the CIDR length and network mask for your Subnet. Given a base network and a CIDR length, choose an available subnet id for your network. 2 To complete the set of basic configuration parameters, compute the broadcast address associated with your chosen subnet ID and CIDR. Step 4 - Document important addresses and ranges \u00b6 Finally, identify how you plan to allocate the addresses in your network among devices based on the requirements you identified in Step #1. Static addresses will usually be assigned to core network devices, such as your router, DHCP, and DNS servers. If you identified any other devices that need consistent addresses, assign those addresses now. When you operate multiple networks, it is helpful to be consistent with your static assignments. For example, most network administrators will assign the router to either the first or last address in the subnet. Don't deviate from convention unless you have a good reason. Once you've documented your static addresses, identify a range of addresses within your subnet that can be used for the DHCP address pool. This should be a contiguous block of addresses that does not overlap with your a) network ID, b) subnet's broadcast address, or c) static addresses that you already defined. More information about RIRs can be found at https://www.nro.net/about/rirs/ . \u21a9 The subnet ID or network prefix is the portion of the address that stays the same for all hosts on the same layer-2 network segment. \u21a9","title":"Basic IP Address Planning"},{"location":"resources/address-planning/#basic-ip-address-planning-2022-04-04","text":"Don't try to build a network without a plan. A good network design is built on parameters and constraints that are appropriate for the intended use-cases. This guide offers a simple procedure that can serve as a starting point for basic planning with a single subnet network.","title":"Basic IP Address Planning (2022-04-04)"},{"location":"resources/address-planning/#private-versus-public","text":"We can't pull addresses from thin air. The laws of the TCP/IP universe restrict what addresses we can use on networks we can control. Make sure that you understand where addresses come from and can distinguish between private and public address space. Private Address Ranges Within the boundaries of our own network, we are relatively free to set our rules as long as we use addresses that are reserved for private use. Your reference point for these addresses is RFC-1918 . Public Address Ranges For packets we send on the public Internet, we must use public addresses that are in our control. These addresses will either be leased (short-term or long-term reservation) to us by an ISP or allocated on a more permanent basis by a Regional Internet Registry (RIR) 1 . A contiguous group of addresses allocated in this way is referred to as a block . Special Address Ranges Beyond these two ranges, we frequently encounter other address ranges that are reserved for special use-cases, e.g., the loopback (127.0.0.0/8) and link-local (169.254.0.0/16) address ranges. RFC-6890","title":"Private versus Public"},{"location":"resources/address-planning/#configuration-strategies","text":"As you get started, you will need to make decisions about how you will configure devices on your network with appropriate IP addresses and network parameters. Before you proceed, make sure that you understand the following classifications. Leased Addresses As much as possible, you'll want to avoid the need for manual configuration when a new device joins the network. DHCP allows you to allocate a range of addresses that the server can use to issue address leases to hosts that request them. Leased addresses are dynamic in the sense that they aren't determined until a host joins the network and initiates the DHCP process. Static Addresses Dynamic address assignment won't work for every scenario, e.g., when an address should be fixed and a dependency on DHCP isn't possible. Some devices, including your network gateway and the DHCP server itself should be manually configured. We describe their addresses as static because they are defined through the network node's own configuration and won't change based on external factors.","title":"Configuration Strategies"},{"location":"resources/address-planning/#procedure","text":"","title":"Procedure"},{"location":"resources/address-planning/#step-1-examine-address-needs","text":"Determine the size of your network, i.e., the number of devices that will need addresses at any given point in time, and document the types of devices you expect to service as well as their address requirements. Don't forget to account for network infrastructure and additional growth. Not all devices on a network are the same, and so you will often have clients with different address needs. End users on their computers and mobile devices will almost always receive dynamic (leased) addresses, but you might need to reserve some address space for static addresses to acommodate web servers, mail servers, or even (sometimes) printers. Your network infrastructure consists of routers, essential services like DHCP and DNS, as well as managed switches and access points. In very simple networks, these services may live on the same device and share a single IP address. More sophisticated networks will split these services onto dedicated devices, or at the very least, assign them dedicated IP addresses. Always assume that your network will grow over time. Allocate additional address space in anticipation of this growth. If you have believe that you will need 30 addresses today, it's probably safer to plan for at least 60 addresses.","title":"Step 1 - Examine address needs"},{"location":"resources/address-planning/#step-2-identify-the-base-address-range","text":"Identify the base address range from which you will be subnetting. If you do not have a permanent allocation, select a block from the RFC-1918 address range.","title":"Step 2 - Identify the base address range"},{"location":"resources/address-planning/#step-3-select-subnet-parameters","text":"Based on the inventory you conducted in step #1, determine the number of address bits that are required in order to give an address to each host on your LAN. You can use this number to determine the CIDR length and network mask for your Subnet. Given a base network and a CIDR length, choose an available subnet id for your network. 2 To complete the set of basic configuration parameters, compute the broadcast address associated with your chosen subnet ID and CIDR.","title":"Step 3 - Select subnet parameters"},{"location":"resources/address-planning/#step-4-document-important-addresses-and-ranges","text":"Finally, identify how you plan to allocate the addresses in your network among devices based on the requirements you identified in Step #1. Static addresses will usually be assigned to core network devices, such as your router, DHCP, and DNS servers. If you identified any other devices that need consistent addresses, assign those addresses now. When you operate multiple networks, it is helpful to be consistent with your static assignments. For example, most network administrators will assign the router to either the first or last address in the subnet. Don't deviate from convention unless you have a good reason. Once you've documented your static addresses, identify a range of addresses within your subnet that can be used for the DHCP address pool. This should be a contiguous block of addresses that does not overlap with your a) network ID, b) subnet's broadcast address, or c) static addresses that you already defined. More information about RIRs can be found at https://www.nro.net/about/rirs/ . \u21a9 The subnet ID or network prefix is the portion of the address that stays the same for all hosts on the same layer-2 network segment. \u21a9","title":"Step 4 - Document important addresses and ranges"},{"location":"resources/bash/","text":"Intro to Bash \u00b6 Bash command, terminal command, command line command, for the purpose of our class these all mean the same things. You should already be familiar with bash from INFO 201 and INFO 340. This following section will help you refresh some of the basics. Huh, Bash? If you feel completely lost and have never seen terminal commands we recommend watching these two videos: Beginner's Guide to the Bash Terminal Udacity Shell Workshop Directories \u00b6 cd to change directories ls to show files and directories at your current path ls -a to also show hidden files Editing files \u00b6 If you are editing a file on a remote server such as your Pi, you will not have the luxury of using a nice editor such as VS Code, Atom, or Sublime. Nevertheless, there are many powerful terminal editors. Use nano or vim to edit files through your terminal. How to edit a file that's on a linux server/your Pi: Use nano <fileName> or vim <filename> Nano is beginner friendly. If you are unfamiliar with these I recommend looking up a nano tutorial. Command documentation \u00b6 If you don't know what a command does or how to use it simply use the man command! man <commandName> will print out an documentation. Once you're done reading hit q on your keyboard to quit out. In the following screenshots I enter man nslookup which provides me with more information on what nslookup does and how it's used. Services: starting, stopping, status \u00b6 Control services by using the systemctl command. The format is sudo systemctl <action> <service name> . Most used Example Restart NGINX service: sudo systemctl restart nginx Copying Files Across Servers with scp \u00b6 You can copy files from your laptop to a server or a server to your laptop by using scp . It uses our ssh tunnel to securely transfer your files back and forth. You can find great examples at hyperx.org . Copy all of the contents of a folder: scp -r ava/* root@157.230.163.231:/var/www/html/ This copies everything in the ava folder to the html folder. Local vs Remote \u00b6 A typical confusion for students when deadling with scp is whether their current terminal session is doing work on their local machine (your laptop), or on a remote machine (your Raspberry Pi or another server). You can tell which device your terminal session is doing work in by checking the hostname, that is whatever is after the @ symbol. Take a look at the two example tabs below. ``` bash tab=\"Local\" hostname = macbook-pro \u00b6 This tells me I'm on my laptop. \u00b6 ben@macbook-pro:~/Desktop/info-314/ ``` bash tab=\"Remote\" # hostname = debian-lab1 # I must be on my server now. ben@debian-lab1:~$ Logs \u00b6 Check a service's logs. This is a great way to see if it ran into any errors. If for some reason a service keeps crashing or behaving strangely you'd want to dig into its logs and see if it's unhappy with something. sudo journcalctl -u <service name> If you specifically only want to see the most recent parts of the log, you can pipe the information it gives you into the tail command, which only shows any files' ending lines. sudo journalctl -u <service name here>.service | tail -n 100","title":"Intro to Bash"},{"location":"resources/bash/#intro-to-bash","text":"Bash command, terminal command, command line command, for the purpose of our class these all mean the same things. You should already be familiar with bash from INFO 201 and INFO 340. This following section will help you refresh some of the basics. Huh, Bash? If you feel completely lost and have never seen terminal commands we recommend watching these two videos: Beginner's Guide to the Bash Terminal Udacity Shell Workshop","title":"Intro to Bash"},{"location":"resources/bash/#directories","text":"cd to change directories ls to show files and directories at your current path ls -a to also show hidden files","title":"Directories"},{"location":"resources/bash/#editing-files","text":"If you are editing a file on a remote server such as your Pi, you will not have the luxury of using a nice editor such as VS Code, Atom, or Sublime. Nevertheless, there are many powerful terminal editors. Use nano or vim to edit files through your terminal. How to edit a file that's on a linux server/your Pi: Use nano <fileName> or vim <filename> Nano is beginner friendly. If you are unfamiliar with these I recommend looking up a nano tutorial.","title":"Editing files"},{"location":"resources/bash/#command-documentation","text":"If you don't know what a command does or how to use it simply use the man command! man <commandName> will print out an documentation. Once you're done reading hit q on your keyboard to quit out. In the following screenshots I enter man nslookup which provides me with more information on what nslookup does and how it's used.","title":"Command documentation"},{"location":"resources/bash/#services-starting-stopping-status","text":"Control services by using the systemctl command. The format is sudo systemctl <action> <service name> . Most used Example Restart NGINX service: sudo systemctl restart nginx","title":"Services: starting, stopping, status"},{"location":"resources/bash/#copying-files-across-servers-with-scp","text":"You can copy files from your laptop to a server or a server to your laptop by using scp . It uses our ssh tunnel to securely transfer your files back and forth. You can find great examples at hyperx.org . Copy all of the contents of a folder: scp -r ava/* root@157.230.163.231:/var/www/html/ This copies everything in the ava folder to the html folder.","title":"Copying Files Across Servers with scp"},{"location":"resources/bash/#local-vs-remote","text":"A typical confusion for students when deadling with scp is whether their current terminal session is doing work on their local machine (your laptop), or on a remote machine (your Raspberry Pi or another server). You can tell which device your terminal session is doing work in by checking the hostname, that is whatever is after the @ symbol. Take a look at the two example tabs below. ``` bash tab=\"Local\"","title":"Local vs Remote"},{"location":"resources/bash/#hostname-macbook-pro","text":"","title":"hostname = macbook-pro"},{"location":"resources/bash/#this-tells-me-im-on-my-laptop","text":"ben@macbook-pro:~/Desktop/info-314/ ``` bash tab=\"Remote\" # hostname = debian-lab1 # I must be on my server now. ben@debian-lab1:~$","title":"This tells me  I'm on my laptop."},{"location":"resources/bash/#logs","text":"Check a service's logs. This is a great way to see if it ran into any errors. If for some reason a service keeps crashing or behaving strangely you'd want to dig into its logs and see if it's unhappy with something. sudo journcalctl -u <service name> If you specifically only want to see the most recent parts of the log, you can pipe the information it gives you into the tail command, which only shows any files' ending lines. sudo journalctl -u <service name here>.service | tail -n 100","title":"Logs"},{"location":"resources/configure-routing-links/","text":"Configure a Routing Link for BGP Peers \u00b6 Determine Requirements \u00b6 In order to configure your router to peer with other BGP routers, you will need to identify several parameters associated with the routing configuration. These parameters can differ somewhat depending on the type of link you use, i.e., physical or tunnel-based, and other constraints. This guide presents two different scenarios: a) VLANs over a physical Ethernet connection and b) WireGuard to establish a tunnel-link between two routers. In all cases, we need an Autonomous System Number (ASN) for each Autonomous System and we need a unique IP address that will identify each router (regardless of which interface is used). This latter parameter is called the router ID. For each routing link, we also need to provide a way for the routing peers to deliver packets from host-to-host -- implying the use of IP addresses. Free Range Routing (FRR) supports an \"unnumbered\" address configuration which saves us the trouble of planning out addresses on the links; however, this configuration depends on link-local IPv6 capabilities that won't work as expected over a WireGuard tunnel. In these cases, BGP can make use of peer-to-peer addresses configured on the WireGuard network interfaces. Peering Configuration for Examples \u00b6 VLAN-based peers over Ethernet VPN-based peers over Wireguard Parameter Value Routing interface vlan10 Router ID 172.27.2.1 Local/Remote ASN 65009 / 65000 Advertised Network(s) 172.27.2.0/24 Parameter Value Routing interface vpn0 Router ID 172.27.2.1 Local/Remote Tunnel IP 10.99.0.3 / 10.99.0.2 Local/Remote ASN 65009 / 65000 Advertised Network(s) 172.27.2.0/24 Preparing Interfaces for the \"Unnumbered\" BGP Configuration \u00b6 Ethernet Only This section does not apply to routing configuration over WireGuard VPN links To begin, we need to prepare the interface that we'll be using to peer with neighboring routers. In the past, this would have meant configuring IPv4 addresses for each side of the connection; however, we will be taking advantage of unnumbered BGP to identify and connect to our peers based on auto-configured IPv6 addresses. This simplification is welcome since the addresses we assign on point-to-point routing links generally serve no purpose other than facilitating communication between the adjacent routers. Our main task is to enable auto-configuration for IPv6 and to disable auto-configuration privacy extensions so that our MAC address will be encoded into the link-local IPv6 address for the interface. We also need to ensure that the routing interface will listen for and accept ICMPv6 router advertisements from its peer. Configure interface \u00b6 Create or edit a networkd .network configuration for the routing link, e.g., /etc/systemd/network/24-vlan10.network and ensure that the following IPv6 settings are in place. No IPv4 configuration will be performed on this link. [Match] Name=vlan10 [Network] # Enable link local addressing for IPv6 only LinkLocalAddressing=ipv6 # Watch for router advertisements so that we can learn about neighboring routers IPv6AcceptRA=yes # Required due to a bug in FRR (https://github.com/FRRouting/frr/issues/2205) IPv6PrivacyExtensions=no Configure FRRouting \u00b6 Set up address for BGP router ID \u00b6 The router can use any locally defined address as a router ID attached to BGP advertisements. Though we could use any one of our directly attached addresses, it is common to configure an ID on the loopback interface of the network device to ensure that it is available regardless of link status -- static addresses attached to physical interfaces are offline when the link is down. We'll perform this configuration within the FRR VTY shell ( launch using vtysh ): configure terminal interface lo ip address 172.27.2.128/32 quit Additional \"unnumbered\" routing configuration \u00b6 Ethernet Only This section does not apply to routing configuration over WireGuard VPN links Routers in an unnumbered peering relationship rely on ICMPv6 router advertisements to discover peers on a routing link. We previously configured our interface to accept these messages, but we still need to set up the routing daemon to generate the messages on the specified interface. The following commands will turn on ICMPv6 router advertisements and set an interval of one advertisement every 5 seconds (as recommended by FRR documentation). Enter the following commands in the VTY shell: configure terminal interface vlan10 ipv6 nd ra-interval 5 no ipv6 nd suppress-ra quit Configure BGP Routing \u00b6 Once the preliminary configuration is complete, we can setup the BGP daemon to peer on the specified interface. The following examples provide the VTYSH commands needed to enable a new router in ASN 65009 to peer with a neighboring autonomous system and advertises routes for 172.27.2.0/24. Each example follows a common pattern: Enter the configuration mode of VTYSH using configure terminal Configure the BGP routing features by specifying your local ASN e.g., router bgp 65009 Set the router ID using bgp router-id 172.27.2.128 . We set this address up earlier as a loopback since it will be seen on all routing links Issue one or more neighbor statements, specifying either the interface (for unnumbered links) or the remote peer's address for other links. Issue one or more network statements, enabling FRR to advertise routes associated with the given prefix. Standard peer configuration (works w/ Wireguard) Unnumbered peer configuration (Ethernet-only) configure terminal router bgp 65009 bgp router-id 172.27.2.128 neighbor 10.99.0.2 remote-as 65000 network 172.27.2.0/24 quit configure terminal router bgp 65009 bgp router-id 172.27.2.128 neighbor vlan10 interface remote-as external network 172.27.2.0/24 quit Finalizing your Configuration \u00b6 Save Your Changes \u00b6 Don't forget that live updates to FRR are not persistent. Rebooting the router or restarting frr will dispose of any settings that are not written to the startup config. To save your changes, you need to be in enable mode. Exit out of configure mode, if necessary, and call copy running-config startup-config or write memory . Making Further Updates \u00b6 Supporting multiple routing links on a single router requires a simple modification to this script to add additional neighbor statements. If you've already configured other details, you don't need to repeat them to add an aditional neighbor. Enter the following commands to resume editing your existing router: configure terminal router bgp 65009 From the Linux commandline, you can view the current startup configuration within /etc/frr/frr.conf . Be careful making edits directly to this configuration. VTYSH is preferred since it will prevent you from creating an invalid setting that breaks the service. If you do make a direct edit, you will need to restart the frr service manually using systemctl .","title":"Configuring Routing Links"},{"location":"resources/configure-routing-links/#configure-a-routing-link-for-bgp-peers","text":"","title":"Configure a Routing Link for BGP Peers"},{"location":"resources/configure-routing-links/#determine-requirements","text":"In order to configure your router to peer with other BGP routers, you will need to identify several parameters associated with the routing configuration. These parameters can differ somewhat depending on the type of link you use, i.e., physical or tunnel-based, and other constraints. This guide presents two different scenarios: a) VLANs over a physical Ethernet connection and b) WireGuard to establish a tunnel-link between two routers. In all cases, we need an Autonomous System Number (ASN) for each Autonomous System and we need a unique IP address that will identify each router (regardless of which interface is used). This latter parameter is called the router ID. For each routing link, we also need to provide a way for the routing peers to deliver packets from host-to-host -- implying the use of IP addresses. Free Range Routing (FRR) supports an \"unnumbered\" address configuration which saves us the trouble of planning out addresses on the links; however, this configuration depends on link-local IPv6 capabilities that won't work as expected over a WireGuard tunnel. In these cases, BGP can make use of peer-to-peer addresses configured on the WireGuard network interfaces.","title":"Determine Requirements"},{"location":"resources/configure-routing-links/#peering-configuration-for-examples","text":"VLAN-based peers over Ethernet VPN-based peers over Wireguard Parameter Value Routing interface vlan10 Router ID 172.27.2.1 Local/Remote ASN 65009 / 65000 Advertised Network(s) 172.27.2.0/24 Parameter Value Routing interface vpn0 Router ID 172.27.2.1 Local/Remote Tunnel IP 10.99.0.3 / 10.99.0.2 Local/Remote ASN 65009 / 65000 Advertised Network(s) 172.27.2.0/24","title":"Peering Configuration for Examples"},{"location":"resources/configure-routing-links/#preparing-interfaces-for-the-unnumbered-bgp-configuration","text":"Ethernet Only This section does not apply to routing configuration over WireGuard VPN links To begin, we need to prepare the interface that we'll be using to peer with neighboring routers. In the past, this would have meant configuring IPv4 addresses for each side of the connection; however, we will be taking advantage of unnumbered BGP to identify and connect to our peers based on auto-configured IPv6 addresses. This simplification is welcome since the addresses we assign on point-to-point routing links generally serve no purpose other than facilitating communication between the adjacent routers. Our main task is to enable auto-configuration for IPv6 and to disable auto-configuration privacy extensions so that our MAC address will be encoded into the link-local IPv6 address for the interface. We also need to ensure that the routing interface will listen for and accept ICMPv6 router advertisements from its peer.","title":"Preparing Interfaces for the \"Unnumbered\" BGP Configuration"},{"location":"resources/configure-routing-links/#configure-interface","text":"Create or edit a networkd .network configuration for the routing link, e.g., /etc/systemd/network/24-vlan10.network and ensure that the following IPv6 settings are in place. No IPv4 configuration will be performed on this link. [Match] Name=vlan10 [Network] # Enable link local addressing for IPv6 only LinkLocalAddressing=ipv6 # Watch for router advertisements so that we can learn about neighboring routers IPv6AcceptRA=yes # Required due to a bug in FRR (https://github.com/FRRouting/frr/issues/2205) IPv6PrivacyExtensions=no","title":"Configure interface"},{"location":"resources/configure-routing-links/#configure-frrouting","text":"","title":"Configure FRRouting"},{"location":"resources/configure-routing-links/#set-up-address-for-bgp-router-id","text":"The router can use any locally defined address as a router ID attached to BGP advertisements. Though we could use any one of our directly attached addresses, it is common to configure an ID on the loopback interface of the network device to ensure that it is available regardless of link status -- static addresses attached to physical interfaces are offline when the link is down. We'll perform this configuration within the FRR VTY shell ( launch using vtysh ): configure terminal interface lo ip address 172.27.2.128/32 quit","title":"Set up address for BGP router ID"},{"location":"resources/configure-routing-links/#additional-unnumbered-routing-configuration","text":"Ethernet Only This section does not apply to routing configuration over WireGuard VPN links Routers in an unnumbered peering relationship rely on ICMPv6 router advertisements to discover peers on a routing link. We previously configured our interface to accept these messages, but we still need to set up the routing daemon to generate the messages on the specified interface. The following commands will turn on ICMPv6 router advertisements and set an interval of one advertisement every 5 seconds (as recommended by FRR documentation). Enter the following commands in the VTY shell: configure terminal interface vlan10 ipv6 nd ra-interval 5 no ipv6 nd suppress-ra quit","title":"Additional \"unnumbered\" routing configuration"},{"location":"resources/configure-routing-links/#configure-bgp-routing","text":"Once the preliminary configuration is complete, we can setup the BGP daemon to peer on the specified interface. The following examples provide the VTYSH commands needed to enable a new router in ASN 65009 to peer with a neighboring autonomous system and advertises routes for 172.27.2.0/24. Each example follows a common pattern: Enter the configuration mode of VTYSH using configure terminal Configure the BGP routing features by specifying your local ASN e.g., router bgp 65009 Set the router ID using bgp router-id 172.27.2.128 . We set this address up earlier as a loopback since it will be seen on all routing links Issue one or more neighbor statements, specifying either the interface (for unnumbered links) or the remote peer's address for other links. Issue one or more network statements, enabling FRR to advertise routes associated with the given prefix. Standard peer configuration (works w/ Wireguard) Unnumbered peer configuration (Ethernet-only) configure terminal router bgp 65009 bgp router-id 172.27.2.128 neighbor 10.99.0.2 remote-as 65000 network 172.27.2.0/24 quit configure terminal router bgp 65009 bgp router-id 172.27.2.128 neighbor vlan10 interface remote-as external network 172.27.2.0/24 quit","title":"Configure BGP Routing"},{"location":"resources/configure-routing-links/#finalizing-your-configuration","text":"","title":"Finalizing your Configuration"},{"location":"resources/configure-routing-links/#save-your-changes","text":"Don't forget that live updates to FRR are not persistent. Rebooting the router or restarting frr will dispose of any settings that are not written to the startup config. To save your changes, you need to be in enable mode. Exit out of configure mode, if necessary, and call copy running-config startup-config or write memory .","title":"Save Your Changes"},{"location":"resources/configure-routing-links/#making-further-updates","text":"Supporting multiple routing links on a single router requires a simple modification to this script to add additional neighbor statements. If you've already configured other details, you don't need to repeat them to add an aditional neighbor. Enter the following commands to resume editing your existing router: configure terminal router bgp 65009 From the Linux commandline, you can view the current startup configuration within /etc/frr/frr.conf . Be careful making edits directly to this configuration. VTYSH is preferred since it will prevent you from creating an invalid setting that breaks the service. If you do make a direct edit, you will need to restart the frr service manually using systemctl .","title":"Making Further Updates"},{"location":"resources/digital-ocean/","text":"Digital Ocean Signup \u00b6 In our first lab, you will learn how to interact with a headless (no monitor, only a terminal) Linux server. We will interact with Linux a lot in this class, as your Raspberry Pi will run only as a headless Linux server. To dive into Linux servers, we will have you use DigitalOcean, a web hosting platform, to create a virtual machine. Please follow these instructions to sign up for DigitalOcean. Warning Please use our link to sign-up or you will not get any free credits! In order to be able to complete week 1's lab, you will need to complete the following steps before class Make a new account in DigitalOcean: Sign-up Link Please use our link to sign-up or you will not get any free credits! You can sign up with Google or GitHub if you'd like, or create new credentials, it doesn't matter Note: Some students were having issues using their @uw.edu email, I would suggest using something else, like a gmail account Confirm your DigitalOcean account by clicking the link you are emailed after signing up Next, you'll be taken to a billing page for DigitalOcean. You will need to add a credit or debit card. Don't worry, we'll only be using free credits, you won't be charged on your card. As long as you close your virtual machine when we email you in a few weeks, you will be fine and spend nothing. Please don't use PayPal, because that requires you making an initial deposit of $5 in your account. Next, you'll be taken to a page to create your first project. Skip this step by clicking your user icon in the top right of the screen and selecting 'Account' You should now see '$100.00 Credit Remaining' at the top-right of your window. If you do, you're good to go! On Tuesday (3/31), we will set up a server in DigitalOcean and introduce you to the tools that allow you to work remotely.","title":"Digital Ocean Signup"},{"location":"resources/digital-ocean/#digital-ocean-signup","text":"In our first lab, you will learn how to interact with a headless (no monitor, only a terminal) Linux server. We will interact with Linux a lot in this class, as your Raspberry Pi will run only as a headless Linux server. To dive into Linux servers, we will have you use DigitalOcean, a web hosting platform, to create a virtual machine. Please follow these instructions to sign up for DigitalOcean. Warning Please use our link to sign-up or you will not get any free credits! In order to be able to complete week 1's lab, you will need to complete the following steps before class Make a new account in DigitalOcean: Sign-up Link Please use our link to sign-up or you will not get any free credits! You can sign up with Google or GitHub if you'd like, or create new credentials, it doesn't matter Note: Some students were having issues using their @uw.edu email, I would suggest using something else, like a gmail account Confirm your DigitalOcean account by clicking the link you are emailed after signing up Next, you'll be taken to a billing page for DigitalOcean. You will need to add a credit or debit card. Don't worry, we'll only be using free credits, you won't be charged on your card. As long as you close your virtual machine when we email you in a few weeks, you will be fine and spend nothing. Please don't use PayPal, because that requires you making an initial deposit of $5 in your account. Next, you'll be taken to a page to create your first project. Skip this step by clicking your user icon in the top right of the screen and selecting 'Account' You should now see '$100.00 Credit Remaining' at the top-right of your window. If you do, you're good to go! On Tuesday (3/31), we will set up a server in DigitalOcean and introduce you to the tools that allow you to work remotely.","title":"Digital Ocean Signup"},{"location":"resources/dns-clients/","text":"Managing DNS clients \u00b6 View or clear your local DNS cache \u00b6 As applications make DNS queries to obtain the IP addresses of remote resources, your operating system will start to maintain a cache of previous responses. These cached responses are used on subsequent lookups in order to reduce network overhead and speed up the process of loading the applicable resources. Clearing your DNS cache is an operating system dependent operation: Windows 10 \u00b6 Open PowerShell as an administrator and run clear-dnsclientcache . macOS 10.11+: \u00b6 Run sudo killall -HUP mDNSResponder from Terminal 1 . Linux \u00b6 As an open source operating system with that comes in a variety of flavors, Linux users may find that some research is necessary to determine how DNS is managed in their distribution of choice and whether the system maintains a cache that can be cleared. Linux DNS caches may be incorporated into a resolver (systemd-resolved), provided by a standalone service (nscd), or built into a name server (bind9) running on localhost. A few of the most common options are listed below, along with the relevant command to restart the service and/or clear the cache directly. Service Description Command systemd-resolved DNS Resolver (distributed with systemd) sudo systemd-resolve --flush-caches nscd DNS Cache sudo systemctl restart nscd dnsmasq Name Server sudo systemctl restart dnsmasq bind9 Name Server sudo systemctl restart bind9 dns-clean DNS Resolver (previously used by Ubuntu) /etc/init.d/dns-clean restart Perform DNS lookups manually \u00b6 At times it can be helpful to perform DNS queries manually. Tools like dig allow us to query a nameserver and ask it to provide records about a particular host or domain. These tools provide us with an enormous amount of flexibility in interacting with DNS. Installing Dig \u00b6 The dig command balances flexibility with ease of use, making it a popular tool for troubleshooting issues with DNS or performing security-related research on a domain. The utility is installed by default on macOS and some Linux distributions. Instructions are provided below if dig isn't available on your system. Linux For Debian/Ubuntu based Linux including Arch, Mint, and Raspberry Pi OS, dig is part of the dnsutils package and is installed with sudo apt install dnsutils . For Fedora/RedHat based Linux including CentOS, dig is part of the bind-utils package and can be installed with sudo dnf install bind-utils -- use sudo yum install bind-utils if dnf is not available. Windows Windows users may install dig by downloading ISC BIND 9 and installing with the Tools Only option 2 . Similar functionality is also provided by the PowerShell Resolve-DnsName command. Common Usage \u00b6 dig <domain name> : Request records for the given domain name. By default dig will send a query for A records (contain IPv4 addresses) to the default name server for the system. dig <type> <domain name> : Override the type in order to obtain cname (DNS aliases for the given name), mx (mail servers), or ns name servers for the given host or domain rather than the default A record. dig @<name server IP> <domain name> : Override the system's name server (often helpful to determine if other resolvers are returning different records). Example pi@titan.local:~ $ dig @1.1.1.1 cname uw.edu ; <<>> DiG 9.10.6 <<>> @1.1.1.1 cname uw.edu ; (1 server found) ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 50713 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1452 ;; QUESTION SECTION: ;uw.edu. IN CNAME ;; AUTHORITY SECTION: uw.edu. 600 IN SOA hanna.cac.washington.edu. domainmaster.cac.washington.edu. 2020012403 10800 1800 3600000 600 ;; Query time: 40 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Sun Jan 26 23:32:59 PST 2020 ;; MSG SIZE rcvd: 105 Resolving DNS with PowerShell \u00b6 PowerShell for Windows provides a powerful, scriptable DNS client that can be called via Resolve-DnsName . This tool replicates many of the features provided by dig, such as overriding the query type with the -type <type> option or the target server with -server <name server IP> . Run man Resolve-DnsName from PowerShell or view the online documentation to learn more about this command. Note that we are using sudo in order to perform this operation with root privileges. \u21a9 Detailed instructions provided at https://help.dyn.com/how-to-use-binds-dig-tool/ . \u21a9","title":"Managing DNS Clients"},{"location":"resources/dns-clients/#managing-dns-clients","text":"","title":"Managing DNS clients"},{"location":"resources/dns-clients/#view-or-clear-your-local-dns-cache","text":"As applications make DNS queries to obtain the IP addresses of remote resources, your operating system will start to maintain a cache of previous responses. These cached responses are used on subsequent lookups in order to reduce network overhead and speed up the process of loading the applicable resources. Clearing your DNS cache is an operating system dependent operation:","title":"View or clear your local DNS cache"},{"location":"resources/dns-clients/#windows-10","text":"Open PowerShell as an administrator and run clear-dnsclientcache .","title":"Windows 10"},{"location":"resources/dns-clients/#macos-1011","text":"Run sudo killall -HUP mDNSResponder from Terminal 1 .","title":"macOS 10.11+:"},{"location":"resources/dns-clients/#linux","text":"As an open source operating system with that comes in a variety of flavors, Linux users may find that some research is necessary to determine how DNS is managed in their distribution of choice and whether the system maintains a cache that can be cleared. Linux DNS caches may be incorporated into a resolver (systemd-resolved), provided by a standalone service (nscd), or built into a name server (bind9) running on localhost. A few of the most common options are listed below, along with the relevant command to restart the service and/or clear the cache directly. Service Description Command systemd-resolved DNS Resolver (distributed with systemd) sudo systemd-resolve --flush-caches nscd DNS Cache sudo systemctl restart nscd dnsmasq Name Server sudo systemctl restart dnsmasq bind9 Name Server sudo systemctl restart bind9 dns-clean DNS Resolver (previously used by Ubuntu) /etc/init.d/dns-clean restart","title":"Linux"},{"location":"resources/dns-clients/#perform-dns-lookups-manually","text":"At times it can be helpful to perform DNS queries manually. Tools like dig allow us to query a nameserver and ask it to provide records about a particular host or domain. These tools provide us with an enormous amount of flexibility in interacting with DNS.","title":"Perform DNS lookups manually"},{"location":"resources/dns-clients/#installing-dig","text":"The dig command balances flexibility with ease of use, making it a popular tool for troubleshooting issues with DNS or performing security-related research on a domain. The utility is installed by default on macOS and some Linux distributions. Instructions are provided below if dig isn't available on your system. Linux For Debian/Ubuntu based Linux including Arch, Mint, and Raspberry Pi OS, dig is part of the dnsutils package and is installed with sudo apt install dnsutils . For Fedora/RedHat based Linux including CentOS, dig is part of the bind-utils package and can be installed with sudo dnf install bind-utils -- use sudo yum install bind-utils if dnf is not available. Windows Windows users may install dig by downloading ISC BIND 9 and installing with the Tools Only option 2 . Similar functionality is also provided by the PowerShell Resolve-DnsName command.","title":"Installing Dig"},{"location":"resources/dns-clients/#common-usage","text":"dig <domain name> : Request records for the given domain name. By default dig will send a query for A records (contain IPv4 addresses) to the default name server for the system. dig <type> <domain name> : Override the type in order to obtain cname (DNS aliases for the given name), mx (mail servers), or ns name servers for the given host or domain rather than the default A record. dig @<name server IP> <domain name> : Override the system's name server (often helpful to determine if other resolvers are returning different records). Example pi@titan.local:~ $ dig @1.1.1.1 cname uw.edu ; <<>> DiG 9.10.6 <<>> @1.1.1.1 cname uw.edu ; (1 server found) ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 50713 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1452 ;; QUESTION SECTION: ;uw.edu. IN CNAME ;; AUTHORITY SECTION: uw.edu. 600 IN SOA hanna.cac.washington.edu. domainmaster.cac.washington.edu. 2020012403 10800 1800 3600000 600 ;; Query time: 40 msec ;; SERVER: 1.1.1.1#53(1.1.1.1) ;; WHEN: Sun Jan 26 23:32:59 PST 2020 ;; MSG SIZE rcvd: 105","title":"Common Usage"},{"location":"resources/dns-clients/#resolving-dns-with-powershell","text":"PowerShell for Windows provides a powerful, scriptable DNS client that can be called via Resolve-DnsName . This tool replicates many of the features provided by dig, such as overriding the query type with the -type <type> option or the target server with -server <name server IP> . Run man Resolve-DnsName from PowerShell or view the online documentation to learn more about this command. Note that we are using sudo in order to perform this operation with root privileges. \u21a9 Detailed instructions provided at https://help.dyn.com/how-to-use-binds-dig-tool/ . \u21a9","title":"Resolving DNS with PowerShell"},{"location":"resources/dummy-interfaces/","text":"Configuring Dummy Interfaces in systemd-networkd \u00b6 Dummys are functionally identical to loopbacks (read more) , though we're allowed to create more than one. Like a loopback, a dummy interface does not require a physical connection, and the addresses associated with the interface won't go up and down based on link status. A dummy interface can also be configured with one or more IP addresses (just like a physical interface) and it can be bound to a client or server socket, responding to network requests received at the configured addresses. We will use dummy interfaces to extend our network virtually for the purpose of labs and to provide logical separation between multiple services hosted on a single physical node. Creating the Interface \u00b6 networkd supports various software-defined interface types, including dummy interfaces. Just like physical interfaces, you can view or modify the state of a dummy interface using standard commands like ip link and ip address . The following example demonstrates how to create and configure a dummy interface with these commands: Manually creating a dummy interface ip link add dev dmz0 type dummy ip addr add dev dmz0 10.10.10.10/32 While ip link and ip address can make non-persistent changes to network devices, these changes will not be restored after shutting down or rebooting the operating system. In order to create a persistent dummy interface on a system running networkd, the ip link settings should be translated into a .netdev file that is loaded from the networkd configuration directory (typically /etc/systemd/network). In addition to providing a name for the interface, the parameter Kind=dummy instructs networkd to add a dummy interface. As shown below, Layer-3 configuration for this interface is defined separately in a .network configuration file. Creating and configuring a dummy interface persistently /etc/systemd/network/10-dmz0.netdev [NetDev] Name=dmz0 Kind=dummy /etc/systemd/network/10-dmz0.network [Match] Name=dmz0 [Network] Address=10.10.10.10/32 # Include an Address statement for each IP required","title":"Dummy Interfaces"},{"location":"resources/dummy-interfaces/#configuring-dummy-interfaces-in-systemd-networkd","text":"Dummys are functionally identical to loopbacks (read more) , though we're allowed to create more than one. Like a loopback, a dummy interface does not require a physical connection, and the addresses associated with the interface won't go up and down based on link status. A dummy interface can also be configured with one or more IP addresses (just like a physical interface) and it can be bound to a client or server socket, responding to network requests received at the configured addresses. We will use dummy interfaces to extend our network virtually for the purpose of labs and to provide logical separation between multiple services hosted on a single physical node.","title":"Configuring Dummy Interfaces in systemd-networkd"},{"location":"resources/dummy-interfaces/#creating-the-interface","text":"networkd supports various software-defined interface types, including dummy interfaces. Just like physical interfaces, you can view or modify the state of a dummy interface using standard commands like ip link and ip address . The following example demonstrates how to create and configure a dummy interface with these commands: Manually creating a dummy interface ip link add dev dmz0 type dummy ip addr add dev dmz0 10.10.10.10/32 While ip link and ip address can make non-persistent changes to network devices, these changes will not be restored after shutting down or rebooting the operating system. In order to create a persistent dummy interface on a system running networkd, the ip link settings should be translated into a .netdev file that is loaded from the networkd configuration directory (typically /etc/systemd/network). In addition to providing a name for the interface, the parameter Kind=dummy instructs networkd to add a dummy interface. As shown below, Layer-3 configuration for this interface is defined separately in a .network configuration file. Creating and configuring a dummy interface persistently /etc/systemd/network/10-dmz0.netdev [NetDev] Name=dmz0 Kind=dummy /etc/systemd/network/10-dmz0.network [Match] Name=dmz0 [Network] Address=10.10.10.10/32 # Include an Address statement for each IP required","title":"Creating the Interface"},{"location":"resources/dynamic-dns/","text":"Registering Dynamic Hosts in DNS \u00b6 ddns-confgen -q key \"ddns-key\" { algorithm hmac-sha256; secret \"zxHaXudonbUFek9EFGPCbTwgIT/BCZJEOTWEDtaMDEY=\"; }; Copy the key declaration and paste into a new file named /etc/bind/ddns-update.key. Take note of key's label, which will be referenced in named and dhcpd configuration. Ensure that the key is readable by root/bind, but not by any other users on the server chown root:bind ddns-update.key chmod 660 ddns-update.key Configure Dynamic Zones in BIND \u00b6 Enable updates by adding a per-zone update-policy in /etc/bind/named.conf.local . Since the policy statement refers to the key by name, you will also need to include contents of the newly generated key before include \"/etc/bind/ddns-update.key\"; // (1)! zone \"example.pi\" { type master; file \"db.example.pi\"; update-policy { grant ddns-key zonesub ANY; }; // (2)! zone \"168.192.in-addr.arpa\" { type master; file \"db.192.168\"; update-policy { grant ddns-key zonesub ANY; }; // (3)! }; Include the newly generated key before the zone declaration. Add an update-policy to each dynamic zone, referencing the key by its label and listing permitted record types. Configure ISC DHCP to perform updates \u00b6 sudo ln -s /etc/bind/ddns-update.key /etc/dhcp/ ``` ddns-update-style standard; (1)! deny client-updates; do-forward-updates on; update-optimization off; # (2)! update-conflict-detection off; include \"/etc/dhcp/ddns-update.key\"; # (3)! zone example.pi. { (4)! primary 127.0.0.1; key ddns-key; } zone 168.192.in-addr.arpa. { primary 127.0.0.1; key ddns-key; } ... subnet 192.168.0.0 netmask 255.255.255.0 { # range and options ddns-domainname \"example.pi\"; # (1)! } Change the default value of ddns-update-style from none to standard 2. 3. Include the key definition before referencing the key in the below zone statements. 5","title":"Registering Dynamic Hosts in DNS"},{"location":"resources/dynamic-dns/#registering-dynamic-hosts-in-dns","text":"ddns-confgen -q key \"ddns-key\" { algorithm hmac-sha256; secret \"zxHaXudonbUFek9EFGPCbTwgIT/BCZJEOTWEDtaMDEY=\"; }; Copy the key declaration and paste into a new file named /etc/bind/ddns-update.key. Take note of key's label, which will be referenced in named and dhcpd configuration. Ensure that the key is readable by root/bind, but not by any other users on the server chown root:bind ddns-update.key chmod 660 ddns-update.key","title":"Registering Dynamic Hosts in DNS"},{"location":"resources/dynamic-dns/#configure-dynamic-zones-in-bind","text":"Enable updates by adding a per-zone update-policy in /etc/bind/named.conf.local . Since the policy statement refers to the key by name, you will also need to include contents of the newly generated key before include \"/etc/bind/ddns-update.key\"; // (1)! zone \"example.pi\" { type master; file \"db.example.pi\"; update-policy { grant ddns-key zonesub ANY; }; // (2)! zone \"168.192.in-addr.arpa\" { type master; file \"db.192.168\"; update-policy { grant ddns-key zonesub ANY; }; // (3)! }; Include the newly generated key before the zone declaration. Add an update-policy to each dynamic zone, referencing the key by its label and listing permitted record types.","title":"Configure Dynamic Zones in BIND"},{"location":"resources/dynamic-dns/#configure-isc-dhcp-to-perform-updates","text":"sudo ln -s /etc/bind/ddns-update.key /etc/dhcp/ ``` ddns-update-style standard; (1)! deny client-updates; do-forward-updates on; update-optimization off; # (2)! update-conflict-detection off; include \"/etc/dhcp/ddns-update.key\"; # (3)! zone example.pi. { (4)! primary 127.0.0.1; key ddns-key; } zone 168.192.in-addr.arpa. { primary 127.0.0.1; key ddns-key; } ... subnet 192.168.0.0 netmask 255.255.255.0 { # range and options ddns-domainname \"example.pi\"; # (1)! } Change the default value of ddns-update-style from none to standard 2. 3. Include the key definition before referencing the key in the below zone statements. 5","title":"Configure ISC DHCP to perform updates"},{"location":"resources/host-config/","text":"Mac/Windows/Linux Networking \u00b6 Renewing DHCP Leases \u00b6 dhcp renewal is when a dhcp client (your laptop, phone, tablet...) renews or updates its IP address configuration with the dhcp server. Often times in our homes the dhcp server is already packaged in our router source . macOS \u00b6 Important The Renew DHCP Lease button for macOS will not result in a complete DHCP Exchange. Be sure to follow the instructions below. Go to Network Preferences >> Select interface >> Advanced -> TCP/IP, Turn off IPv4 Addressing (hit OK + Apply) Return to advanced settings and enable DHCP (hit OK + Apply). Windows \u00b6 Open a command prompt Run ipconfig /release Wi-Fi to release your IP address Wait for the release command to complete and run ipconfig /renew to request a new one Linux \u00b6 Important Linux instructions will vary depending on your target distribution. You may need to search online for alternative instructions. sudo dhclient -r eth0 sudo dhclient eth0 Managing ARP Cache \u00b6 Every computer maintains a cache of associations of ARP responses that have recently appeared on the network. In order to examine ARP functionality or troubleshoot the behavior of a particular network device, you may need to flush the existing contents. Windows \u00b6 Open an Administrator Command Prompt or PowerShell Session and run arp -d Unix (MacOS) \u00b6 sudo arp -ad Linux \u00b6 For the following command, substitute the name of your own network interface for : sudo ip neigh flush dev <wlan0>","title":"Mac/Win/Linux Networking"},{"location":"resources/host-config/#macwindowslinux-networking","text":"","title":"Mac/Windows/Linux Networking"},{"location":"resources/host-config/#renewing-dhcp-leases","text":"dhcp renewal is when a dhcp client (your laptop, phone, tablet...) renews or updates its IP address configuration with the dhcp server. Often times in our homes the dhcp server is already packaged in our router source .","title":"Renewing DHCP Leases"},{"location":"resources/host-config/#macos","text":"Important The Renew DHCP Lease button for macOS will not result in a complete DHCP Exchange. Be sure to follow the instructions below. Go to Network Preferences >> Select interface >> Advanced -> TCP/IP, Turn off IPv4 Addressing (hit OK + Apply) Return to advanced settings and enable DHCP (hit OK + Apply).","title":"macOS"},{"location":"resources/host-config/#windows","text":"Open a command prompt Run ipconfig /release Wi-Fi to release your IP address Wait for the release command to complete and run ipconfig /renew to request a new one","title":"Windows"},{"location":"resources/host-config/#linux","text":"Important Linux instructions will vary depending on your target distribution. You may need to search online for alternative instructions. sudo dhclient -r eth0 sudo dhclient eth0","title":"Linux"},{"location":"resources/host-config/#managing-arp-cache","text":"Every computer maintains a cache of associations of ARP responses that have recently appeared on the network. In order to examine ARP functionality or troubleshoot the behavior of a particular network device, you may need to flush the existing contents.","title":"Managing ARP Cache"},{"location":"resources/host-config/#windows_1","text":"Open an Administrator Command Prompt or PowerShell Session and run arp -d","title":"Windows"},{"location":"resources/host-config/#unix-macos","text":"sudo arp -ad","title":"Unix (MacOS)"},{"location":"resources/host-config/#linux_1","text":"For the following command, substitute the name of your own network interface for : sudo ip neigh flush dev <wlan0>","title":"Linux"},{"location":"resources/iptables/","text":"Introduction to Iptables (2022-04-02) \u00b6 This guide serves the dual purpose of introducing iptables and using it to build a basic ruleset that routes packets between an internal and external network while also applying NAT to private, internal addresses. You should read the entire guide carefully before attempting to install the template or any of the other tools referenced here. Tables, Chains, and Rule Syntax \u00b6 Iptables is a tool that has been used for more than 20 years to allow administrators to manage packet filter rules that shape the behavior of the Linux kernel's network stack. Tables \u00b6 Iptables uses a basic structure called a table to group rules according to their main function. Common tables include nat , filter , mangle , and raw . For this exercise, we'll focus on the nat table to implement address translation between private and public addresses along with the filter table to protect our network from outside traffic. Chains \u00b6 Within each table, rules are assigned to a structure called a chain. A chain is nothing more than an ordered list of rules. Rule conditions are tested in order from the beginning of the chain. Each rule ends with an action. If the conditions of a rule match, iptables will apply the specified action or jump to another chain without processing the other rules. If conditions do not match, the next rule in the chain will be evaluated. The default chains correspond to different points in the packet lifecycle. Within the filter table, we will often work with the INPUT , OUTPUT , and FORWARD chains. These chains correspond to packets sent to the host ( INPUT ), packets being sent by the host ( OUTPUT ), and packets being routed through the host ( FORWARD ). Within the nat table, our focus will be on the POSTROUTING chain. This chain represents the last set of rules that will be evaluated before forwarding a filtered packet. This is where we want to apply address mappings related to SNAT and masquerading. In contrast, the PREROUTING chain is applied before any other process and is used to specify DNAT rules. For a more detailed exploration of the chains we have discussed, see Understanding Netfilter/Iptables Hooks . Managing Rules from the Command Line \u00b6 We can load a set of iptables rules from a file or manage them directly from the command line with the iptables command ( sudo is required). As we explain the structure of rules, we will provide examples using the command line variant of iptables rule syntax. The first component of a rule specified from the command line is the table name. Specify the table using the -t option to the iptables command . If you don't specify a table explicitly, the filter table will be used by default. When working with rules via the command line, we have to work with rules one at a time and specify the order of operations as we go. Recall from the last section that the order of rules in a chain is significant. We can append new rules to the end of a chain using the -A option or insert rules at the beginning of a chain using -I . Likewise, we can delete a rule from a chain by specifying -D and providing a numeric index to the rule. Copy/Paste Warning These are examples only. Keep reading to learn how to build complete rules. Example: Appending Rules Append a rule to the end of the POSTROUTING chain of the nat table ... iptables -t nat -A POSTROUTING <conditions> <actions> Example: Deleting Rules Delete the first rule from the FORWARD chain of filter iptables -D FORWARD 1 Customize Rules with Filter Conditions \u00b6 In addition to specifying table and chain, our rules need to describe the criteria associated with packets we want to filter or manipulate. In this exercise, our primary consideration is the direction of traffic for a given packet, which we describe by specifying the ingress and/or egress interface for a given packet. Attention Throughout the instructions, we'll refer to the internal interface as our <LAN> (because it serves our local network) and the external interface as the <WAN> (because it connects us to the Internet). Your configuration files will reflect the system assigned interface names, such as: eth0 and wlan0 . It's up to you to determine, based on your learning so far, which interface corresponds to which placeholder. For example, we want to apply address translation to outbound packets, i.e., packets being forwarded in the <LAN> interface and out the <WAN> interface. We can specify this restriction in our nat rule by providing the -o option with the name of the outbound interface. Likewise, we can instruct iptables to look at packets coming from the <LAN> and to the <WAN> by combining the -i option with -o in our filter rules. Copy/Paste Warning These are examples only. Keep reading to learn how to build complete rules. Example: Adding filter conditions to rules This NAT rule will be applied on outbound traffic that's being routed to the WAN network. iptables -t NAT -A POSTROUTING -o <WAN> <actions> Example: Combining multiple filters The following filter rule will be applied to outbound traffic that's being forwarded from the LAN to the WAN. iptables -A FORWARD -i <LAN> -o <WAN> <actions> Using Connection State in Rules \u00b6 Iptables is stateful , meaning that it is even possible to specify rules based on the relationship of a packet to other packets that were processed by iptables. This feature shapes our rules in two ways. First, you'll notice that we only have to specify the masquerade rule in the outward direction. The same rule also handles the de-masquerading process for incoming packets. Second, you'll see that we can base filtering decisions on connection state itself. While it's appropriate for NAT routers to allow outgoing traffic, we typically want to place greater restrictions on incoming traffic. When configuring a gateway connection for a home or office, we often block incoming traffic unless it relates to existing connections from the LAN. Unsolicited traffic does not make sense in this context and poses a security risk. To accomplish this feat, we will make use of netfilter's connection tracking extensions which are specified with the -m conntrack and --ctstate RELATED,ESTABLISHED options. Copy/Paste Warning These are examples only. Keep reading to learn how to build complete rules. Example: Using the connection tracking extension Check the connection state of ingress traffic. iptables -A FORWARD -i <WAN> -m conntrack --ctstate RELATED,ESTABLISHED <action> Specify an Action \u00b6 The last component of an iptables rule is specified using the -j option. In a simple configuration, this option provides the action to be carried out against the packet after the match. While we will encounter the MASQUERADE option in our NAT rules, we will more frequently with basic ACCEPT and DROP rules within the filter context. In more complex configurations, -j can point to user-defined chains containing additional rules that relate to the pattern you just matched. As you gain experience, you'll see that this provides a greater degree of organization and control flow. Bringing this option together with the earlier examples, we can express complete rules using the following syntax: iptables -t nat -A POSTROUTING -o <WAN> -j MASQUERADE iptables -A FORWARD -i <WAN> -o <LAN> -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT Default Actions \u00b6 We haven't yet said what will happen if your iptables chains complete without any matching rules. Each iptables chain defines a policy that specifies the default actions that will be taken if no other rule matches in a chain. Default policies are commonly used with the filter chains to implement a posture of failing securely, blocking traffic that wasn't explicitly allowed. # Don't forward packets unless there was an explicit rule match iptables -P FORWARD DROP Be careful, however, that you don't lock yourself out by a bad combination of rules and policies. For example, setting -P INPUT DROP and -P OUTPUT DROP will block all inbound and outbound traffic to your Pi unless you previously added rules to explicitly allow SSH or other tools that are needed for management purposes. Even when you correctly add these rules, it's relatively easy to lock yourself out of a device by flushing your current ruleset -- deleting the rules from all chains while leaving your policies intact. Final NAT Template \u00b6 The following template draws together all of the components we have discussed so far to define a basic NAT configuration for a Linux router. The syntax for this template differs somewhat from the commands we explored above. Rather than invoking each rule or policy in this file through the iptables command, this template would be applied via iptables-restore or iptables-apply . To prepare to use this template, save a copy of this template to the home directory (file name does not matter) of your Linux router. Pay close attention to the comments within the file, since they explain some of the differences in syntax. # Fill in the parameters in <> in order to complete the ruleset # Rules are given on a table-by-table basis, beginning with the *<table> and # ending with COMMIT. # Rules are appended to a chain using the -A <chain> syntax. Parameters vary # somewhat by chain and type of effect desired. # The -j switch instructs the rules engine to jump to another chain or perform # the action on the matched packet. The engine will not evaluate any more rules # in the given chain. # The default policy for a chain is given by the lines beginning with # :<chain>. The [0:0] resets the packet/byte counters that tell us how many # times the default policy has been applied. Note that default policy is # evaluated after all rules, so it only applies if there were not any matches. *nat -A POSTROUTING -o <interface> -j MASQUERADE COMMIT *filter :FORWARD <action> [0:0] -A FORWARD -i <interface> -o <interface> -j ACCEPT -A FORWARD -i <interface> -o <interface> -m conntrack --ctstate RELATED,ESTABLISHED -j <action> COMMIT Loading rules from the file system with iptables-persistent \u00b6 For simplicity, we\u2019ll rely on on a collection of tools called iptables-persistent to test our rules and then load them automatically at boot. Here be Dragons Do not write rules directly to /etc/iptables/rules.v4 . If you do this, you risk creating a rule that locks you out of your device from the network. Without an external monitor and keyboard, you will not be able to bypass these changes since they are loaded at boot. We are presenting iptables-persistent to provide you with a tool that allows us you to apply new rules safely by testing changes before making them fully persistent. Like many other tools, iptables-persistent is available as a package in Debian's package repository. This package contains tools to help you test new rules and install them into the /etc/iptables/rules.v4 path so that they can be loaded automatically in the future. Use apt to install the iptables-persistent package before attempting the instructions below. Make a copy of your rules within your home directory (file name does not matter) and use the iptables-apply command as shown below to test that they work before writing them to /etc/iptables/rules.v4 . While it is possible to edit /etc/iptables/rules.v4 directly, we recomend against it. The following command will flush iptables and load the rules given in ~/untested_rules . After loading the rules, iptables-apply waits for 60 seconds while you confirm that you can still SSH into the device from a second terminal tab or window. If your rules work as intended, you need respond affirmatively at this final prompt within the time limit so that iptables-apply can write them to a permanent location. If you skip this step, iptables-apply will assume that your test failed and restore the old version of the rules. sudo iptables-apply -t 60 -w /etc/iptables/rules.v4 ~/untested_rules After running the command, you\u2019ll have one minute to check that everything is working and confirm that you\u2019re ready to apply the rules. If everything checks out, the rules will be written to /etc/iptables/rules.v4 (where iptables-persistent can load them at boot). If your connection is interrupted or you decide not to keep the rules, the rules will be reset when the timer expires so that you con continue to access your Pi. As a final test that your rules are loaded, reboot the Pi, connect with SSH, and list the rules with sudo iptables-save . If you don\u2019t see your rules, something went wrong. Resources \u00b6 Understanding Netfilter/Iptables Hooks Digital Ocean Tutorial - Iptables and Netfilter Deep Dive Linux Network Administrators Guide - Masquerading DigitalOcean Tutorial - Manipulate Iptables Rules","title":"Introduction to iptables"},{"location":"resources/iptables/#introduction-to-iptables-2022-04-02","text":"This guide serves the dual purpose of introducing iptables and using it to build a basic ruleset that routes packets between an internal and external network while also applying NAT to private, internal addresses. You should read the entire guide carefully before attempting to install the template or any of the other tools referenced here.","title":"Introduction to Iptables (2022-04-02)"},{"location":"resources/iptables/#tables-chains-and-rule-syntax","text":"Iptables is a tool that has been used for more than 20 years to allow administrators to manage packet filter rules that shape the behavior of the Linux kernel's network stack.","title":"Tables, Chains, and Rule Syntax"},{"location":"resources/iptables/#tables","text":"Iptables uses a basic structure called a table to group rules according to their main function. Common tables include nat , filter , mangle , and raw . For this exercise, we'll focus on the nat table to implement address translation between private and public addresses along with the filter table to protect our network from outside traffic.","title":"Tables"},{"location":"resources/iptables/#chains","text":"Within each table, rules are assigned to a structure called a chain. A chain is nothing more than an ordered list of rules. Rule conditions are tested in order from the beginning of the chain. Each rule ends with an action. If the conditions of a rule match, iptables will apply the specified action or jump to another chain without processing the other rules. If conditions do not match, the next rule in the chain will be evaluated. The default chains correspond to different points in the packet lifecycle. Within the filter table, we will often work with the INPUT , OUTPUT , and FORWARD chains. These chains correspond to packets sent to the host ( INPUT ), packets being sent by the host ( OUTPUT ), and packets being routed through the host ( FORWARD ). Within the nat table, our focus will be on the POSTROUTING chain. This chain represents the last set of rules that will be evaluated before forwarding a filtered packet. This is where we want to apply address mappings related to SNAT and masquerading. In contrast, the PREROUTING chain is applied before any other process and is used to specify DNAT rules. For a more detailed exploration of the chains we have discussed, see Understanding Netfilter/Iptables Hooks .","title":"Chains"},{"location":"resources/iptables/#managing-rules-from-the-command-line","text":"We can load a set of iptables rules from a file or manage them directly from the command line with the iptables command ( sudo is required). As we explain the structure of rules, we will provide examples using the command line variant of iptables rule syntax. The first component of a rule specified from the command line is the table name. Specify the table using the -t option to the iptables command . If you don't specify a table explicitly, the filter table will be used by default. When working with rules via the command line, we have to work with rules one at a time and specify the order of operations as we go. Recall from the last section that the order of rules in a chain is significant. We can append new rules to the end of a chain using the -A option or insert rules at the beginning of a chain using -I . Likewise, we can delete a rule from a chain by specifying -D and providing a numeric index to the rule. Copy/Paste Warning These are examples only. Keep reading to learn how to build complete rules. Example: Appending Rules Append a rule to the end of the POSTROUTING chain of the nat table ... iptables -t nat -A POSTROUTING <conditions> <actions> Example: Deleting Rules Delete the first rule from the FORWARD chain of filter iptables -D FORWARD 1","title":"Managing Rules from the Command Line"},{"location":"resources/iptables/#customize-rules-with-filter-conditions","text":"In addition to specifying table and chain, our rules need to describe the criteria associated with packets we want to filter or manipulate. In this exercise, our primary consideration is the direction of traffic for a given packet, which we describe by specifying the ingress and/or egress interface for a given packet. Attention Throughout the instructions, we'll refer to the internal interface as our <LAN> (because it serves our local network) and the external interface as the <WAN> (because it connects us to the Internet). Your configuration files will reflect the system assigned interface names, such as: eth0 and wlan0 . It's up to you to determine, based on your learning so far, which interface corresponds to which placeholder. For example, we want to apply address translation to outbound packets, i.e., packets being forwarded in the <LAN> interface and out the <WAN> interface. We can specify this restriction in our nat rule by providing the -o option with the name of the outbound interface. Likewise, we can instruct iptables to look at packets coming from the <LAN> and to the <WAN> by combining the -i option with -o in our filter rules. Copy/Paste Warning These are examples only. Keep reading to learn how to build complete rules. Example: Adding filter conditions to rules This NAT rule will be applied on outbound traffic that's being routed to the WAN network. iptables -t NAT -A POSTROUTING -o <WAN> <actions> Example: Combining multiple filters The following filter rule will be applied to outbound traffic that's being forwarded from the LAN to the WAN. iptables -A FORWARD -i <LAN> -o <WAN> <actions>","title":"Customize Rules with Filter Conditions"},{"location":"resources/iptables/#using-connection-state-in-rules","text":"Iptables is stateful , meaning that it is even possible to specify rules based on the relationship of a packet to other packets that were processed by iptables. This feature shapes our rules in two ways. First, you'll notice that we only have to specify the masquerade rule in the outward direction. The same rule also handles the de-masquerading process for incoming packets. Second, you'll see that we can base filtering decisions on connection state itself. While it's appropriate for NAT routers to allow outgoing traffic, we typically want to place greater restrictions on incoming traffic. When configuring a gateway connection for a home or office, we often block incoming traffic unless it relates to existing connections from the LAN. Unsolicited traffic does not make sense in this context and poses a security risk. To accomplish this feat, we will make use of netfilter's connection tracking extensions which are specified with the -m conntrack and --ctstate RELATED,ESTABLISHED options. Copy/Paste Warning These are examples only. Keep reading to learn how to build complete rules. Example: Using the connection tracking extension Check the connection state of ingress traffic. iptables -A FORWARD -i <WAN> -m conntrack --ctstate RELATED,ESTABLISHED <action>","title":"Using Connection State in Rules"},{"location":"resources/iptables/#specify-an-action","text":"The last component of an iptables rule is specified using the -j option. In a simple configuration, this option provides the action to be carried out against the packet after the match. While we will encounter the MASQUERADE option in our NAT rules, we will more frequently with basic ACCEPT and DROP rules within the filter context. In more complex configurations, -j can point to user-defined chains containing additional rules that relate to the pattern you just matched. As you gain experience, you'll see that this provides a greater degree of organization and control flow. Bringing this option together with the earlier examples, we can express complete rules using the following syntax: iptables -t nat -A POSTROUTING -o <WAN> -j MASQUERADE iptables -A FORWARD -i <WAN> -o <LAN> -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT","title":"Specify an Action"},{"location":"resources/iptables/#default-actions","text":"We haven't yet said what will happen if your iptables chains complete without any matching rules. Each iptables chain defines a policy that specifies the default actions that will be taken if no other rule matches in a chain. Default policies are commonly used with the filter chains to implement a posture of failing securely, blocking traffic that wasn't explicitly allowed. # Don't forward packets unless there was an explicit rule match iptables -P FORWARD DROP Be careful, however, that you don't lock yourself out by a bad combination of rules and policies. For example, setting -P INPUT DROP and -P OUTPUT DROP will block all inbound and outbound traffic to your Pi unless you previously added rules to explicitly allow SSH or other tools that are needed for management purposes. Even when you correctly add these rules, it's relatively easy to lock yourself out of a device by flushing your current ruleset -- deleting the rules from all chains while leaving your policies intact.","title":"Default Actions"},{"location":"resources/iptables/#final-nat-template","text":"The following template draws together all of the components we have discussed so far to define a basic NAT configuration for a Linux router. The syntax for this template differs somewhat from the commands we explored above. Rather than invoking each rule or policy in this file through the iptables command, this template would be applied via iptables-restore or iptables-apply . To prepare to use this template, save a copy of this template to the home directory (file name does not matter) of your Linux router. Pay close attention to the comments within the file, since they explain some of the differences in syntax. # Fill in the parameters in <> in order to complete the ruleset # Rules are given on a table-by-table basis, beginning with the *<table> and # ending with COMMIT. # Rules are appended to a chain using the -A <chain> syntax. Parameters vary # somewhat by chain and type of effect desired. # The -j switch instructs the rules engine to jump to another chain or perform # the action on the matched packet. The engine will not evaluate any more rules # in the given chain. # The default policy for a chain is given by the lines beginning with # :<chain>. The [0:0] resets the packet/byte counters that tell us how many # times the default policy has been applied. Note that default policy is # evaluated after all rules, so it only applies if there were not any matches. *nat -A POSTROUTING -o <interface> -j MASQUERADE COMMIT *filter :FORWARD <action> [0:0] -A FORWARD -i <interface> -o <interface> -j ACCEPT -A FORWARD -i <interface> -o <interface> -m conntrack --ctstate RELATED,ESTABLISHED -j <action> COMMIT","title":"Final NAT Template"},{"location":"resources/iptables/#loading-rules-from-the-file-system-with-iptables-persistent","text":"For simplicity, we\u2019ll rely on on a collection of tools called iptables-persistent to test our rules and then load them automatically at boot. Here be Dragons Do not write rules directly to /etc/iptables/rules.v4 . If you do this, you risk creating a rule that locks you out of your device from the network. Without an external monitor and keyboard, you will not be able to bypass these changes since they are loaded at boot. We are presenting iptables-persistent to provide you with a tool that allows us you to apply new rules safely by testing changes before making them fully persistent. Like many other tools, iptables-persistent is available as a package in Debian's package repository. This package contains tools to help you test new rules and install them into the /etc/iptables/rules.v4 path so that they can be loaded automatically in the future. Use apt to install the iptables-persistent package before attempting the instructions below. Make a copy of your rules within your home directory (file name does not matter) and use the iptables-apply command as shown below to test that they work before writing them to /etc/iptables/rules.v4 . While it is possible to edit /etc/iptables/rules.v4 directly, we recomend against it. The following command will flush iptables and load the rules given in ~/untested_rules . After loading the rules, iptables-apply waits for 60 seconds while you confirm that you can still SSH into the device from a second terminal tab or window. If your rules work as intended, you need respond affirmatively at this final prompt within the time limit so that iptables-apply can write them to a permanent location. If you skip this step, iptables-apply will assume that your test failed and restore the old version of the rules. sudo iptables-apply -t 60 -w /etc/iptables/rules.v4 ~/untested_rules After running the command, you\u2019ll have one minute to check that everything is working and confirm that you\u2019re ready to apply the rules. If everything checks out, the rules will be written to /etc/iptables/rules.v4 (where iptables-persistent can load them at boot). If your connection is interrupted or you decide not to keep the rules, the rules will be reset when the timer expires so that you con continue to access your Pi. As a final test that your rules are loaded, reboot the Pi, connect with SSH, and list the rules with sudo iptables-save . If you don\u2019t see your rules, something went wrong.","title":"Loading rules from the file system with iptables-persistent"},{"location":"resources/iptables/#resources","text":"Understanding Netfilter/Iptables Hooks Digital Ocean Tutorial - Iptables and Netfilter Deep Dive Linux Network Administrators Guide - Masquerading DigitalOcean Tutorial - Manipulate Iptables Rules","title":"Resources"},{"location":"resources/loopback-interfaces/","text":"Working with Loopbacks in systemd-networkd \u00b6 When we have worked with IP addresses, we have mostly though about them as being configured in association with a particular network interface on a device. One challenge with this configuration is that addresses attached to a physical network interface will not be brought up if the link is unavailable. In certain use cases, we will want an address that operates independently of the physical links. A common application of this configuration, for example, is dynamic routing. Two of the mechanisms that Linux provides in service of this goal are loopbacks and dummy interfaces (read more) . The focus of this guide is on configuration of the loopback interface. Configuring additional loopback addresses \u00b6 Linux allows exactly one loopback interface called lo to be allocated on a given system. You should already be familiar with this interface as the home of the locally scoped 127.0.0.1 localhost address. While we can't create a new interface, we are permitted to add new addresses to the existing loopback. Unlike the localhost address, these addresses will be globally scoped and remotely accessible. Addresses can be configued using the ip address command for a manual, non-persistent configuration or via systemd-networkd .network files. Manually configuring secondary loopback addresses ip addr add dev lo 10.10.10.10/32 Configuring a persistent loopback address /etc/systemd/network/10-lo.network [Match] Name=lo # Each address is placed in a [Address] section [Address] Address=10.10.10.10/32 Resources \u00b6 https://manpages.debian.org/buster/systemd/systemd.network.5.en.html https://wiki.archlinux.org/index.php/systemd-networkd","title":"Loopback Interfaces"},{"location":"resources/loopback-interfaces/#working-with-loopbacks-in-systemd-networkd","text":"When we have worked with IP addresses, we have mostly though about them as being configured in association with a particular network interface on a device. One challenge with this configuration is that addresses attached to a physical network interface will not be brought up if the link is unavailable. In certain use cases, we will want an address that operates independently of the physical links. A common application of this configuration, for example, is dynamic routing. Two of the mechanisms that Linux provides in service of this goal are loopbacks and dummy interfaces (read more) . The focus of this guide is on configuration of the loopback interface.","title":"Working with Loopbacks in systemd-networkd"},{"location":"resources/loopback-interfaces/#configuring-additional-loopback-addresses","text":"Linux allows exactly one loopback interface called lo to be allocated on a given system. You should already be familiar with this interface as the home of the locally scoped 127.0.0.1 localhost address. While we can't create a new interface, we are permitted to add new addresses to the existing loopback. Unlike the localhost address, these addresses will be globally scoped and remotely accessible. Addresses can be configued using the ip address command for a manual, non-persistent configuration or via systemd-networkd .network files. Manually configuring secondary loopback addresses ip addr add dev lo 10.10.10.10/32 Configuring a persistent loopback address /etc/systemd/network/10-lo.network [Match] Name=lo # Each address is placed in a [Address] section [Address] Address=10.10.10.10/32","title":"Configuring additional loopback addresses"},{"location":"resources/loopback-interfaces/#resources","text":"https://manpages.debian.org/buster/systemd/systemd.network.5.en.html https://wiki.archlinux.org/index.php/systemd-networkd","title":"Resources"},{"location":"resources/manage-dhcp/","text":"DHCP \u00b6 DHCP advice will be updated and rolled out to this page. Renew dhcp lease \u00b6 Quote dhcp renewal is when a dhcp client (your laptop, phone, tablet...) renews or updates its IP address cofniguration with the dhcp server. Often times in our homes the dhcp server is already packaged in our router source . Unix (Mac OS) : This steps below are necessary since the renew button for mac os only does a shortened DHCP exchange. Go to Network Preferences >> Select interface >> Advanced -> TCP/IP, Turn off IPv4 Addressing (hit OK + Apply) Return to advanced settings and enable DHCP. Windows : Open a command prompt run ipconfig /release Wi-Fi to release your IP address then run ipconfig /renew to request a new one Linux : sudo dhclient -r eth0 sudo dhclient eth0","title":"Troubleshooting DHCP"},{"location":"resources/manage-dhcp/#dhcp","text":"DHCP advice will be updated and rolled out to this page.","title":"DHCP"},{"location":"resources/manage-dhcp/#renew-dhcp-lease","text":"Quote dhcp renewal is when a dhcp client (your laptop, phone, tablet...) renews or updates its IP address cofniguration with the dhcp server. Often times in our homes the dhcp server is already packaged in our router source . Unix (Mac OS) : This steps below are necessary since the renew button for mac os only does a shortened DHCP exchange. Go to Network Preferences >> Select interface >> Advanced -> TCP/IP, Turn off IPv4 Addressing (hit OK + Apply) Return to advanced settings and enable DHCP. Windows : Open a command prompt run ipconfig /release Wi-Fi to release your IP address then run ipconfig /renew to request a new one Linux : sudo dhclient -r eth0 sudo dhclient eth0","title":"Renew dhcp lease"},{"location":"resources/markdown/","text":"Intro to Markdown \u00b6 What is Markdown? \u00b6 \"Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML)\" source . You will be expected to use this syntax for most of your reports. Every lab you do in this course will require a lab report, and a markdown template will be provided to make your life easier. You will also find a file called README.md in the root of all of your GitHub repo folders that you will need to edit to describe your projects. How do I get started? \u00b6 Don't worry if you are unfamiliar with Markdown, it's really easy to pick up. First, let's learn the syntax required to write a document in Markdown. Github has great documentation on all of the things you can do with it here: mastering-markdown guide. Once you've taken a look at it, you can follow this interactive tutorial: markdowntutorial.com . Editors \u00b6 Now that you've got the syntax down, it's time to download and set up an editor. Most text-editing applications will work with markdown files ( .md ), but they won't allow you to preview what your document will look like with all the formatting, it will just look like plain ##text## #with# -markdown formatting . Instead, you should use an editor developed with markdown in mind. There are two options presented in this course. Option One - Standalone Editor Typora \u00b6 A simple option for an editor is Typora. Typora is a simple Markdown viewer for Windows, Mac OS X, and Linux that allows you to preview and edit your Markdown document in both a source code and presentation format. You can switch between these formats with Ctrl + / on Windows or Cmd + / on Mac. You can download Typora here (download links are at the bottom of the page). Markdown -> PDF when using Typora \u00b6 Often you will need to attach images to a lab report. Unless you want to upload multiple files (the markdown document, plus the images with exact names for markdown to find them) it is recommended that you compile your lab report into a PDF after completion and submit that. In Typora, you can do this by clicking File > Export > PDF . Option Two - Using VS Code \u00b6 A slightly more complex option is to use Visual Studio Code. This might be the best option for you if you already use VS Code to program in other languages. To use VS Code to edit markdown documents, I recommend installing a couple extensions on VS code in order to make your life easier: Markdown Preview Github and Markdown All in One . Each has instructions at the time of installation on how to use them. Markdown -> PDF when using VS Code \u00b6 Often you will need to attach images to a lab report. Unless you want to upload multiple files (the markdown document, plus the images with exact names for markdown to find them) it is recommended that you compile your lab report into a PDF after completion and submit that. If you use VS Code as a Markdown editor, you should use a command line tool such as grip to export Markdown documents to pdf. grip is a command line tool that will easily convert your markdown file to a pdf or html file. Installation instruction github.com/joeyespo/grip Usage: grip <file name>.md --export","title":"Intro to Markdown"},{"location":"resources/markdown/#intro-to-markdown","text":"","title":"Intro to Markdown"},{"location":"resources/markdown/#what-is-markdown","text":"\"Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML)\" source . You will be expected to use this syntax for most of your reports. Every lab you do in this course will require a lab report, and a markdown template will be provided to make your life easier. You will also find a file called README.md in the root of all of your GitHub repo folders that you will need to edit to describe your projects.","title":"What is Markdown?"},{"location":"resources/markdown/#how-do-i-get-started","text":"Don't worry if you are unfamiliar with Markdown, it's really easy to pick up. First, let's learn the syntax required to write a document in Markdown. Github has great documentation on all of the things you can do with it here: mastering-markdown guide. Once you've taken a look at it, you can follow this interactive tutorial: markdowntutorial.com .","title":"How do I get started?"},{"location":"resources/markdown/#editors","text":"Now that you've got the syntax down, it's time to download and set up an editor. Most text-editing applications will work with markdown files ( .md ), but they won't allow you to preview what your document will look like with all the formatting, it will just look like plain ##text## #with# -markdown formatting . Instead, you should use an editor developed with markdown in mind. There are two options presented in this course.","title":"Editors"},{"location":"resources/markdown/#option-one-standalone-editor-typora","text":"A simple option for an editor is Typora. Typora is a simple Markdown viewer for Windows, Mac OS X, and Linux that allows you to preview and edit your Markdown document in both a source code and presentation format. You can switch between these formats with Ctrl + / on Windows or Cmd + / on Mac. You can download Typora here (download links are at the bottom of the page).","title":"Option One - Standalone Editor Typora"},{"location":"resources/markdown/#markdown-pdf-when-using-typora","text":"Often you will need to attach images to a lab report. Unless you want to upload multiple files (the markdown document, plus the images with exact names for markdown to find them) it is recommended that you compile your lab report into a PDF after completion and submit that. In Typora, you can do this by clicking File > Export > PDF .","title":"Markdown -&gt; PDF when using Typora"},{"location":"resources/markdown/#option-two-using-vs-code","text":"A slightly more complex option is to use Visual Studio Code. This might be the best option for you if you already use VS Code to program in other languages. To use VS Code to edit markdown documents, I recommend installing a couple extensions on VS code in order to make your life easier: Markdown Preview Github and Markdown All in One . Each has instructions at the time of installation on how to use them.","title":"Option Two - Using VS Code"},{"location":"resources/markdown/#markdown-pdf-when-using-vs-code","text":"Often you will need to attach images to a lab report. Unless you want to upload multiple files (the markdown document, plus the images with exact names for markdown to find them) it is recommended that you compile your lab report into a PDF after completion and submit that. If you use VS Code as a Markdown editor, you should use a command line tool such as grip to export Markdown documents to pdf. grip is a command line tool that will easily convert your markdown file to a pdf or html file. Installation instruction github.com/joeyespo/grip Usage: grip <file name>.md --export","title":"Markdown -&gt; PDF when using VS Code"},{"location":"resources/netfilter-hooks/","text":"Understanding Netfilter Hooks (2022-04-02) \u00b6 The netfilter component of Linux defines a set of hooks within the TCP/IP stack that are used to run code based on different packet events at different moments in the packet lifecycle. Utilities like iptables and nftables provide a frontend and language for managing rules and actions that we want to perform based on the characteristics of network traffic. These tools are commonly used to implement services like NAT or to provide host or network-based packet filtering firewalls. Working with Local Traffic \u00b6 To better understand how all of this works, let\u2019s start with a simplified example on a standard Linux host. For now, ignore the possibility of routing and focus on the host\u2019s ability to send or receive packets. In this scenario, we can use netfilter for tasks like dropping unwanted traffic or rewriting addresses and layer-3 ports on the fly. Since this is a simplified scenario, we can limit our examination to two hooks, input and output , that are triggered for packets flowing to and from the local device in a non-routing scenario. By non-routing, we mean that the input hook is only invoked when the host is the intended recipient of the message based on the packet\u2019s destination IP address. Likewise, the output hook won\u2019t fire unless the message originated from the local host. Given the input / output hooks, we can use a frontend like iptables to register specific rules and actions that are evaluated for each packet passing through the network stack. Host-based Packet Filters \u00b6 One of the most common applications of the input / output hooks is to perform packet filtering in order to provide a host-based firewall for the Linux device. For example, from a security perspective, we typically want to limit how much of an \u201cattack surface\u201d we expose over the network. We can leverage the input hook to drop packets that aren\u2019t part of a TCP connection that we had previously initiated. In other words, we allow client-based software to open outbound connections but we block any attempts to connect to us as a server. If we need more flexibility, we can create rules to allow connections in to specific services, such as an HTTP or SSH daemon. Working with Routed Traffic \u00b6 Netfilter operations become slightly more complex when routing is introduced. Like an ordinary host, routers still process packets coming to/from the local device, but they also need to forward packets received on one network interface through other interfaces. In fact, this latter operation is their main responsibility. In order to support these communication paths, netfilter defines three additional hooks: forward , prerouting , and postrouting that we can use to perform network-based packet filtering, network address translation (NAT), and other packet-level operations. Network-based Packet Filters \u00b6 For network-based filtering, the forward hook is a direct analogue to the input / output hooks. As we\u2019ve mentioned, input / output are not applied to routed packets. Instead, code registered on the forward hook will be evaluated after the initial routing decision is made. The forward hook provides the basis for network-based firewall functionality. Network-based firewalls enable us to drop or reject unwanted traffic before it has the opportunity to reach our hosts (or even enter into the network). Likewise, we can also leverage packet filtering to prevent certain types of local traffic from inadvertently leaking outside our own network perimeters. Network Address Translation \u00b6 Sometimes it makes more sense to perform an action for an incoming packet before any routing decision has been made or just before actually sending an outgoing packet. This is the case for port and network address translation and is facilitated by attaching rules to the prerouting and postrouting hooks. Specifically, we set up rules on the prerouting hook when we want to modify incoming packets based on their destination IP address. This configuration is called destination NAT (DNAT) and is useful for delivering traffic to a server on a private subnet. Likewise, we use the postrouting hook when our goal is to change outgoing packets based on the original source address. This configuration is called source NAT (SNAT) and is useful when we need to map a public IP on to packets coming from private addresses. Additional Caveats for Local Traffic \u00b6 Unlike the forward hook, prerouting and postrouting may be used for local traffic as well as routed traffic. In particular, an incoming packet will be processed by the prerouting hook before the network stack makes a routing decision and reaches the input hook. For outgoing packets, the output hook is invoked prior to the outbound routing/forwarding decision or the postrouting hook. For local traffic, we often have a choice about which hook provides the best entry point for our rules. Summary \u00b6 When you're first learning about Linux networking internals, it can be difficult to remember the relationship between netfilter hooks and related events in the packet lifecycle. The following list summarizes what we've learned so far in terms of specific traffic flows. Incoming local traffic: (receive packet via network interface) -> prerouting -> (local routing decision) -> input -> (continue processing packet and deliver via sockets) Outgoing local traffic: (receive packet via sockets) -> output -> (outbound routing) -> postrouting -> (continue processing and send via network interface) Routed traffic: (receive packet via network interface) -> prerouting -> (inbound routing) -> forward -> (outbound routing) -> postrouting -> (continue processing and send via network interface) As you work to digest each of these traffic flows, you can refer to the following list for a reminder of which operations can be performed by using a particular hook. Once again, we are distinguishing routed traffic from incoming and outgoing routed traffic. Filtering incoming traffic to local: input Filtering outgoing traffic from local: output Filtering routed traffic (in any direction): forward SNAT for routed traffic: postrouting SNAT for outgoing local traffic: postrouting or output DNAT for routed traffic: prerouting DNAT for incoming local traffic: prerouting or input","title":"Understanding netfilter Hooks"},{"location":"resources/netfilter-hooks/#understanding-netfilter-hooks-2022-04-02","text":"The netfilter component of Linux defines a set of hooks within the TCP/IP stack that are used to run code based on different packet events at different moments in the packet lifecycle. Utilities like iptables and nftables provide a frontend and language for managing rules and actions that we want to perform based on the characteristics of network traffic. These tools are commonly used to implement services like NAT or to provide host or network-based packet filtering firewalls.","title":"Understanding Netfilter Hooks (2022-04-02)"},{"location":"resources/netfilter-hooks/#working-with-local-traffic","text":"To better understand how all of this works, let\u2019s start with a simplified example on a standard Linux host. For now, ignore the possibility of routing and focus on the host\u2019s ability to send or receive packets. In this scenario, we can use netfilter for tasks like dropping unwanted traffic or rewriting addresses and layer-3 ports on the fly. Since this is a simplified scenario, we can limit our examination to two hooks, input and output , that are triggered for packets flowing to and from the local device in a non-routing scenario. By non-routing, we mean that the input hook is only invoked when the host is the intended recipient of the message based on the packet\u2019s destination IP address. Likewise, the output hook won\u2019t fire unless the message originated from the local host. Given the input / output hooks, we can use a frontend like iptables to register specific rules and actions that are evaluated for each packet passing through the network stack.","title":"Working with Local Traffic"},{"location":"resources/netfilter-hooks/#host-based-packet-filters","text":"One of the most common applications of the input / output hooks is to perform packet filtering in order to provide a host-based firewall for the Linux device. For example, from a security perspective, we typically want to limit how much of an \u201cattack surface\u201d we expose over the network. We can leverage the input hook to drop packets that aren\u2019t part of a TCP connection that we had previously initiated. In other words, we allow client-based software to open outbound connections but we block any attempts to connect to us as a server. If we need more flexibility, we can create rules to allow connections in to specific services, such as an HTTP or SSH daemon.","title":"Host-based Packet Filters"},{"location":"resources/netfilter-hooks/#working-with-routed-traffic","text":"Netfilter operations become slightly more complex when routing is introduced. Like an ordinary host, routers still process packets coming to/from the local device, but they also need to forward packets received on one network interface through other interfaces. In fact, this latter operation is their main responsibility. In order to support these communication paths, netfilter defines three additional hooks: forward , prerouting , and postrouting that we can use to perform network-based packet filtering, network address translation (NAT), and other packet-level operations.","title":"Working with Routed Traffic"},{"location":"resources/netfilter-hooks/#network-based-packet-filters","text":"For network-based filtering, the forward hook is a direct analogue to the input / output hooks. As we\u2019ve mentioned, input / output are not applied to routed packets. Instead, code registered on the forward hook will be evaluated after the initial routing decision is made. The forward hook provides the basis for network-based firewall functionality. Network-based firewalls enable us to drop or reject unwanted traffic before it has the opportunity to reach our hosts (or even enter into the network). Likewise, we can also leverage packet filtering to prevent certain types of local traffic from inadvertently leaking outside our own network perimeters.","title":"Network-based Packet Filters"},{"location":"resources/netfilter-hooks/#network-address-translation","text":"Sometimes it makes more sense to perform an action for an incoming packet before any routing decision has been made or just before actually sending an outgoing packet. This is the case for port and network address translation and is facilitated by attaching rules to the prerouting and postrouting hooks. Specifically, we set up rules on the prerouting hook when we want to modify incoming packets based on their destination IP address. This configuration is called destination NAT (DNAT) and is useful for delivering traffic to a server on a private subnet. Likewise, we use the postrouting hook when our goal is to change outgoing packets based on the original source address. This configuration is called source NAT (SNAT) and is useful when we need to map a public IP on to packets coming from private addresses.","title":"Network Address Translation"},{"location":"resources/netfilter-hooks/#additional-caveats-for-local-traffic","text":"Unlike the forward hook, prerouting and postrouting may be used for local traffic as well as routed traffic. In particular, an incoming packet will be processed by the prerouting hook before the network stack makes a routing decision and reaches the input hook. For outgoing packets, the output hook is invoked prior to the outbound routing/forwarding decision or the postrouting hook. For local traffic, we often have a choice about which hook provides the best entry point for our rules.","title":"Additional Caveats for Local Traffic"},{"location":"resources/netfilter-hooks/#summary","text":"When you're first learning about Linux networking internals, it can be difficult to remember the relationship between netfilter hooks and related events in the packet lifecycle. The following list summarizes what we've learned so far in terms of specific traffic flows. Incoming local traffic: (receive packet via network interface) -> prerouting -> (local routing decision) -> input -> (continue processing packet and deliver via sockets) Outgoing local traffic: (receive packet via sockets) -> output -> (outbound routing) -> postrouting -> (continue processing and send via network interface) Routed traffic: (receive packet via network interface) -> prerouting -> (inbound routing) -> forward -> (outbound routing) -> postrouting -> (continue processing and send via network interface) As you work to digest each of these traffic flows, you can refer to the following list for a reminder of which operations can be performed by using a particular hook. Once again, we are distinguishing routed traffic from incoming and outgoing routed traffic. Filtering incoming traffic to local: input Filtering outgoing traffic from local: output Filtering routed traffic (in any direction): forward SNAT for routed traffic: postrouting SNAT for outgoing local traffic: postrouting or output DNAT for routed traffic: prerouting DNAT for incoming local traffic: prerouting or input","title":"Summary"},{"location":"resources/nftables/","text":"Introduction to netfilter and nftables (2022-04-02) \u00b6 This guide introduces nftables by building a basic ruleset that allows us to safely forward packets between internal and external networks while also masquerading traffic with the IP address of the external network interface. Read the entire guide carefully before attempting to install the template or any of the other tools referenced here . What is nftables \u00b6 nftables is the default tool used to manage netfilter's packet filter rules in Raspberry Pi OS. Though nftables was originally released in 2014, it did not make its way into Raspberry Pi OS until the Bullseye release in November 2021. nftables is the successor to iptables , which has been in use within the Linux community for more than 20 years. nftables is a packet filtering framework included in a variety of modern Linux implementations. Packet filtering is a powerful technique that enables administrators to analyze and control the flow of inbound and outbound network traffic from any endpoint or intermediate network node. This level of control is essential for host- and network-based firewalls, network address translation (NAT), and other applications. Packet filters define rules to match traffic based primarily on Layer 2 - 4 properties, such as: the inbound or outbound interface, type and length of messages, addresses, ports, and connection state. Each filter also describes actions taken when a match is found, e.g., log, deliver, or drop the packet. netfilter-based packet filters can also be used to apply NAT, make decisions about Quality of Service, or to reroute packets mid-flight. nftables builds on netfilter , an open-source project adding hooks, connection tracking, and other capabilities to the Linux network stack. These components enable dynamic filters, like nftables rules, to be applied to every packet traversing the network stack. They are the secret sauce to many of the applications described above. Tables, Chains, and Rule Syntax \u00b6 In nftables , rules are composed of expressions that are used to select packets and statements that determine what actions netfilter will perform when a match occurs. While rules are the meat of our filter configurations, nftables doesn't allow them to stand alone. And so, before we explore the rule syntax, we need to looks tables and chains . Tables \u00b6 nftables uses a basic structure known as a table to organize rules. Each table is associated with a single address family and includes rules to apply to packets of that family. This guide is focused on layer-3 traffic and considers tables for the following three address families: ip : for IPv4 rules (default) ip6 : for IPv6 rules inet : for rules that apply to both IPv4 and IPv6 packets While its predecessor, iptables , included a default set of tables for common packet filter functionality, nftables administrators are left to define their own tables. For this exercise, we'll create an IPv4 nat table to implement address translation between private and public addresses and an IPv4/IPv6 filter table to protect the Pi and the rest of our LAN from malicious traffic. 1 Example: Empty filter and nat tables table inet filter { # Define chains (and rules) for IPv4 or IPv6 packets } table ip nat { # Define chains (and rules) for IPv4 packets } Chains \u00b6 Within each table, rules are grouped in chains . A chain is an ordered list of rules describing the packets to match and the action to take when a match is found. When a chain is processed, the rules in it are tested in order from the beginning until a match is found. If nftables finds a match while evaluating a rule, the remaining rules in that chain may be skipped depending on what action is taken. Base Chains \u00b6 nftables won't evaluate the rules in a chain automatically. Rather, a chain will only be processed if it is explicitly called from a rule in another chain or if the chain has been associated with a netfilter hook .A chain that is associated with a hook is called a base chain . Within the filter table, we are going to work with three base chains named input , output , and forward . These chains will be associated with filter hooks of the same names 2 , causing them to be processed when packets are being sent to software running on the Pi ( input hook), when packets are being sent out by software on the Pi ( output ) hook, or when packets are being routed by the Pi from one network to another ( forward hook). Example: Filter table and empty base chains table inet filter { chain input { type filter hook input priority 0; # Rules are evaluated when a packet is intended for this host } chain forward { type filter hook forward priority 0; # Rules are evaluated when an incoming packet will be forwarded by this host } chain output { type filter hook output priority 0; # Rules are evaluated when a packet is being sent from this host } } The nat table will have one base chain that is named for its respective hook , i.e., postrouting . Within netfilter, the postrouting hooks are the last ones to be processed when sending or forwarding a packet. As such, rules processed here can perform masquerading on the source IP addresses. 3 Example: NAT with postrouting base chain table ip nat { chain postrouting { type nat hook postrouting priority 100; # Rules are evaluated after forwarding decisions in order to support source NAT or masquerading } } Rules Syntax \u00b6 The basic nftables rule syntax includes an expression and a statement. Expressions define conditions that need to be satisfied before an action is applied to a packet. Statements define the actions that will be taken. Since actions are the simpler component of a rule, we'll begin our exploration there. Statements (actions) \u00b6 nftables statements are used to control packet flow, apply NAT transformations, compute metrics, record logs, and modify the order of rule evaluation. While the list below is not exhaustive, it is sufficient for this guide and the beginning firewall developer. accept : Stop processing chain and deliver packet drop : Stop processing chain and drop packet counter : Increment byte and packet counters and continue processing chain log : Write information about packet to logs and continue processing chain masquerade : Replace source IP address with the address of the output interface and stop processing chain You may observe that actions like drop and accept cause nftables to stop processing the current chain. These actions are known as terminal actions. Actions like log and counter are non-terminal because they allow nftables to continue processing even if a match had been found. nftables supports multiple actions in a single statement, but a terminal may only appear as the final component of a rule. For example, we can produce a rule that increments a counter and delivers a packet by ending our rule with counter accept . We can also write a rule that increments a counter and logs a packet without specifying a policy decision by ending the rule with counter log or log counter . However, we cannot combine terminals or include a terminal before a non-terminal as with accept counter or drop accept . Expressions (conditions) \u00b6 Our rules need to describe the packets we want to filter or manipulate. In this exercise, our primary consideration will be the direction in which a given packet is moving through the Pi. This is particularly of importance for routing decisions and NAT. We can describe our criteria by examining the ingress network for incoming packets and/or the egress network interface for outgoing packets. Attention Throughout the instructions, we'll refer to the internal interface as our <LAN> (because it serves our local network) and the external interface as the <WAN> (because it connects us to the Internet). Your configuration files will reflect the system assigned interface names, such as: eth0 and wlan0 . It's up to you to determine, based on your learning so far, which interface corresponds to which placeholder. Let's look at a rule that we can use to apply address translation to outbound packets. Since outbound packets will leave on the WAN, we can specify this restriction using the outbound interface name (oifname) condition, i.e., oifname <WAN> . The following example masquerades outbound traffic on the <WAN> interface. Example: Applying NAT transformation to outbound traffic table ip nat { chain postrouting { type nat hook postrouting priority srcnat; oifname <WAN> masquerade } } We can be even more specific with our rules by writing an expression with multiple conditionals. To identify outbound traffic forwarded from the LAN to the WAN, we can check both the inbound and outbound interface names by writing iifname <LAN> oifname <WAN> . The following example demonstrates a rule that explicitly accepts traffic flowing from <LAN> to <WAN> . Example: Combining multiple expressions table inet filter { chain forward { type filter hook forward priority 0; iifname <LAN> oifname <WAN> accept } } Using Connection State in Rules \u00b6 Netfilter is a stateful filtering framework, meaning that it is even possible to specify nftables rules based on the state of a network connection for a given packet. This feature shapes our rules in two ways. First, you'll notice that we only had to specify the masquerade rule in the egress direction. The same rule also handles the de-masquerading process for ingress packets. Second, you'll see that we can base filtering decisions on connection state itself. While it's appropriate for NAT routers to allow outgoing traffic, we typically want to place restrict incoming traffic. When configuring a gateway connection for a home or office, we often block incoming traffic unless it relates to existing connections from the LAN. Unsolicited traffic does not make sense in this context and poses a security risk. To accomplish this feat, we will make use of netfilter's connection tracking extensions and restrict incoming traffic to packets that are part of an established connection or related to a recent egress packet. The connection tracking portion of this expression is ct state established,related . Example: Using the connection tracking extension table inet filter { chain forward { type filter hook forward priority 0; iifname <WAN> ct state established,related accept } } Default Policy (for Base Chains) \u00b6 We are missing one piece to complete our configuration. By default, nftables accepts a packet unless a match occurs on a terminal rule. Base chains can override this behavior by defining a default policy. We'll use this feature to create a firewall that fail securely, i.e., blocking traffic that we don't explicitly allow. The following example adds a base chain policy in order to drop forwarded packets that we didn't allow from another rule. Example: Default drop policy table inet filter { chain forward { type filter hook forward priority 0; policy drop; # Explicitly allow \"safe\" connections iifname <LAN> oifname <WAN> accept iifname <WAN> ct state established,related accept } } The default deny posture is a best practice for your networks and devices, but it's important to approach the strategy with care. Without additional rules, attaching policy drop to the input and output chains will block inbound and outbound SSH and other protocols that might be needed for remote management. We will come back to this in a later guide, but we recommend for now that you leave the default accept policy on these chains. Final NAT Template \u00b6 The following template draws together all of the components we have discussed so far to define a basic NAT configuration for a Linux router, leaving placeholder 4 , 5 elements for the reader to complete. Please review the previous examples and specifications that have been given in order to create a valid configuration. The following section will help you test and install your new ruleset. !!! info Routing / NAT template # Always flush the active ruleset before defining your new rules flush ruleset table inet filter { chain forward { type filter hook <HOOK> priority 0; policy <ACTION>; # Explicitly allow \"safe\" connections iifname <LAN> oifname <WAN> <ACTION> iifname <WAN> ct state established,related <ACTION> } chain input { type filter hook input priority 0; # You may leave this chain empty for now } chain output { type filter hook output priority 0; # You may leave this chain empty for now } } table ip nat { chain postrouting { type nat hook postrouting priority srcnat; oifname <WAN> masquerade } } Configuring nftables \u00b6 Throughout this guide, nftables configuration has been presented in a declarative, table-based format that closely reflects the table/chain/rule hierarchy. nftables also supports a command-based syntax that is passed to the nft utility on the command line or from within scripts in order to create, read, update, and delete individual elements of a ruleset dynamically. We generally want firewall and routing rules to be configured as soon as possible during the boot process. When the nftables service is started, Raspberry Pi OS will initialize it with the contents of /etc/nftables.conf . While experimentation is usually encouraged, you may encounter negative consequences if you make haphazard modifications to this file. A simple script is provided below to support the learning process by testing your ruleset before making changes permanent. Enable the nftables Service \u00b6 The nftables service may not be running by default on your device. You can check on the current status of the daemon with systemctl status nftables . To launch the service immediately, run systemctl start nftables . To ensure that nftables also starts automatically at boot, run systemctl enable nftables . Editing nftable Rules Safely \u00b6 Here be Dragons Do not write rules directly to /etc/nftables.conf . Without proper testing, you risk creating a rule that locks you out of your device from the network. Create a working copy of /etc/nftables.conf into your home directory (it is okay to rename the file) . Open the new copy and ensure that flush ruleset near the top (before your table definitions). 6 Proceed with any modifications to the working copy. To test your ruleset, we recommend a scripted approach that can automatically revert a change that locks you out of the Pi. INFO314 students can find a copy of nftables-apply.sh in the project repository or create the script from the following listing. nftables-apply.sh #!/bin/bash # Adapted from https://sanjuroe.dev/nft-safe-reload (retrieved on 2022-04-03) # Modified to avoid editing system rules in-place SYSTEM_RULES=\"/etc/nftables.conf\" TIMEOUT=45 saved_rules=$(mktemp) cleanup() { rm -f \"$saved_rules\" } trap \"cleanup\" EXIT; # Waits $TIMEOUT seconds for a yes/no response read_approval() { read -t $TIMEOUT response 2> /dev/null case \"$response\" in y|Y) return 0 ;; *) return 1 ;; esac } # Make a copy of the active ruleset backup() { printf \"flush ruleset\\n\" > $saved_rules nft list ruleset >> $saved_rules } # Apply a named ruleset apply() { nft -f \"$1\" } # Update system ruleset save() { local source_rules=\"$1\" cp --no-preserve=mode,ownership \"$source_rules\" \"$SYSTEM_RULES\" } # Make a backup of the active ruleset in case of rollback backup new_rules=\"$1\" if apply \"$new_rules\"; then printf \"Are you still able to connect to your device (auto-rollback in $TIMEOUT seconds)? [y/n] \" if read_approval; then save \"$new_rules\" printf \"\\nUpdated system ruleset at ${SYSTEM_RULES}\\n\" exit 0 else apply \"$saved_rules\" printf \"\\nRolling back to original configuration\\n\" exit 2 fi fi To test your rules, pass the name of your new rules file to the nftables-apply.sh script, e.g., ./nftables-apply.sh nftables-test.conf . If your rules load without any errors, you will be prompted to answer whether you can still connect. Open an additional terminal window and launch SSH to connect to your Pi. If you are able to complete this step successfully, you can apply your changes to /etc/nftables.conf by answering y at the nftables-apply prompt in your original session. If the test fails, answer n or wait 45 seconds for the rules to revert automatically. Once you are satisified that your rules are working correctly, it's a good idea to verify that your rules are loaded and that everything works correctly after a reboot. Use the nft list ruleset command to view active rules. Resources \u00b6 Understanding Netfilter Hooks Securing Your Server with nftables Safe Reload with nftables Linux Network Administrators Guide - Masquerading These names were chosen to mirror the built-in tables of iptables . \u21a9 This naming convention is influenced by iptables and its built-in chains. \u21a9 netfilter also defines a prerouting nat hook that executes before routing decisions and can be used to implement port-forwarding and other destination NAT configurations. \u21a9 Text surrounded by <> symbols is indicative of a placeholder that should be filled in before loading the ruleset. \u21a9 Do not quote text substituted for placeholders unless quotes are shown in the template. \u21a9 nft -f <FILENAME> is additive by default. Including flush ruleset before your table/chain definitions ensures that the new ruleset is properly loaded. \u21a9","title":"Introduction to nftables"},{"location":"resources/nftables/#introduction-to-netfilter-and-nftables-2022-04-02","text":"This guide introduces nftables by building a basic ruleset that allows us to safely forward packets between internal and external networks while also masquerading traffic with the IP address of the external network interface. Read the entire guide carefully before attempting to install the template or any of the other tools referenced here .","title":"Introduction to netfilter and nftables (2022-04-02)"},{"location":"resources/nftables/#what-is-nftables","text":"nftables is the default tool used to manage netfilter's packet filter rules in Raspberry Pi OS. Though nftables was originally released in 2014, it did not make its way into Raspberry Pi OS until the Bullseye release in November 2021. nftables is the successor to iptables , which has been in use within the Linux community for more than 20 years. nftables is a packet filtering framework included in a variety of modern Linux implementations. Packet filtering is a powerful technique that enables administrators to analyze and control the flow of inbound and outbound network traffic from any endpoint or intermediate network node. This level of control is essential for host- and network-based firewalls, network address translation (NAT), and other applications. Packet filters define rules to match traffic based primarily on Layer 2 - 4 properties, such as: the inbound or outbound interface, type and length of messages, addresses, ports, and connection state. Each filter also describes actions taken when a match is found, e.g., log, deliver, or drop the packet. netfilter-based packet filters can also be used to apply NAT, make decisions about Quality of Service, or to reroute packets mid-flight. nftables builds on netfilter , an open-source project adding hooks, connection tracking, and other capabilities to the Linux network stack. These components enable dynamic filters, like nftables rules, to be applied to every packet traversing the network stack. They are the secret sauce to many of the applications described above.","title":"What is nftables"},{"location":"resources/nftables/#tables-chains-and-rule-syntax","text":"In nftables , rules are composed of expressions that are used to select packets and statements that determine what actions netfilter will perform when a match occurs. While rules are the meat of our filter configurations, nftables doesn't allow them to stand alone. And so, before we explore the rule syntax, we need to looks tables and chains .","title":"Tables, Chains, and Rule Syntax"},{"location":"resources/nftables/#tables","text":"nftables uses a basic structure known as a table to organize rules. Each table is associated with a single address family and includes rules to apply to packets of that family. This guide is focused on layer-3 traffic and considers tables for the following three address families: ip : for IPv4 rules (default) ip6 : for IPv6 rules inet : for rules that apply to both IPv4 and IPv6 packets While its predecessor, iptables , included a default set of tables for common packet filter functionality, nftables administrators are left to define their own tables. For this exercise, we'll create an IPv4 nat table to implement address translation between private and public addresses and an IPv4/IPv6 filter table to protect the Pi and the rest of our LAN from malicious traffic. 1 Example: Empty filter and nat tables table inet filter { # Define chains (and rules) for IPv4 or IPv6 packets } table ip nat { # Define chains (and rules) for IPv4 packets }","title":"Tables"},{"location":"resources/nftables/#chains","text":"Within each table, rules are grouped in chains . A chain is an ordered list of rules describing the packets to match and the action to take when a match is found. When a chain is processed, the rules in it are tested in order from the beginning until a match is found. If nftables finds a match while evaluating a rule, the remaining rules in that chain may be skipped depending on what action is taken.","title":"Chains"},{"location":"resources/nftables/#base-chains","text":"nftables won't evaluate the rules in a chain automatically. Rather, a chain will only be processed if it is explicitly called from a rule in another chain or if the chain has been associated with a netfilter hook .A chain that is associated with a hook is called a base chain . Within the filter table, we are going to work with three base chains named input , output , and forward . These chains will be associated with filter hooks of the same names 2 , causing them to be processed when packets are being sent to software running on the Pi ( input hook), when packets are being sent out by software on the Pi ( output ) hook, or when packets are being routed by the Pi from one network to another ( forward hook). Example: Filter table and empty base chains table inet filter { chain input { type filter hook input priority 0; # Rules are evaluated when a packet is intended for this host } chain forward { type filter hook forward priority 0; # Rules are evaluated when an incoming packet will be forwarded by this host } chain output { type filter hook output priority 0; # Rules are evaluated when a packet is being sent from this host } } The nat table will have one base chain that is named for its respective hook , i.e., postrouting . Within netfilter, the postrouting hooks are the last ones to be processed when sending or forwarding a packet. As such, rules processed here can perform masquerading on the source IP addresses. 3 Example: NAT with postrouting base chain table ip nat { chain postrouting { type nat hook postrouting priority 100; # Rules are evaluated after forwarding decisions in order to support source NAT or masquerading } }","title":"Base Chains"},{"location":"resources/nftables/#rules-syntax","text":"The basic nftables rule syntax includes an expression and a statement. Expressions define conditions that need to be satisfied before an action is applied to a packet. Statements define the actions that will be taken. Since actions are the simpler component of a rule, we'll begin our exploration there.","title":"Rules Syntax"},{"location":"resources/nftables/#statements-actions","text":"nftables statements are used to control packet flow, apply NAT transformations, compute metrics, record logs, and modify the order of rule evaluation. While the list below is not exhaustive, it is sufficient for this guide and the beginning firewall developer. accept : Stop processing chain and deliver packet drop : Stop processing chain and drop packet counter : Increment byte and packet counters and continue processing chain log : Write information about packet to logs and continue processing chain masquerade : Replace source IP address with the address of the output interface and stop processing chain You may observe that actions like drop and accept cause nftables to stop processing the current chain. These actions are known as terminal actions. Actions like log and counter are non-terminal because they allow nftables to continue processing even if a match had been found. nftables supports multiple actions in a single statement, but a terminal may only appear as the final component of a rule. For example, we can produce a rule that increments a counter and delivers a packet by ending our rule with counter accept . We can also write a rule that increments a counter and logs a packet without specifying a policy decision by ending the rule with counter log or log counter . However, we cannot combine terminals or include a terminal before a non-terminal as with accept counter or drop accept .","title":"Statements (actions)"},{"location":"resources/nftables/#expressions-conditions","text":"Our rules need to describe the packets we want to filter or manipulate. In this exercise, our primary consideration will be the direction in which a given packet is moving through the Pi. This is particularly of importance for routing decisions and NAT. We can describe our criteria by examining the ingress network for incoming packets and/or the egress network interface for outgoing packets. Attention Throughout the instructions, we'll refer to the internal interface as our <LAN> (because it serves our local network) and the external interface as the <WAN> (because it connects us to the Internet). Your configuration files will reflect the system assigned interface names, such as: eth0 and wlan0 . It's up to you to determine, based on your learning so far, which interface corresponds to which placeholder. Let's look at a rule that we can use to apply address translation to outbound packets. Since outbound packets will leave on the WAN, we can specify this restriction using the outbound interface name (oifname) condition, i.e., oifname <WAN> . The following example masquerades outbound traffic on the <WAN> interface. Example: Applying NAT transformation to outbound traffic table ip nat { chain postrouting { type nat hook postrouting priority srcnat; oifname <WAN> masquerade } } We can be even more specific with our rules by writing an expression with multiple conditionals. To identify outbound traffic forwarded from the LAN to the WAN, we can check both the inbound and outbound interface names by writing iifname <LAN> oifname <WAN> . The following example demonstrates a rule that explicitly accepts traffic flowing from <LAN> to <WAN> . Example: Combining multiple expressions table inet filter { chain forward { type filter hook forward priority 0; iifname <LAN> oifname <WAN> accept } }","title":"Expressions (conditions)"},{"location":"resources/nftables/#using-connection-state-in-rules","text":"Netfilter is a stateful filtering framework, meaning that it is even possible to specify nftables rules based on the state of a network connection for a given packet. This feature shapes our rules in two ways. First, you'll notice that we only had to specify the masquerade rule in the egress direction. The same rule also handles the de-masquerading process for ingress packets. Second, you'll see that we can base filtering decisions on connection state itself. While it's appropriate for NAT routers to allow outgoing traffic, we typically want to place restrict incoming traffic. When configuring a gateway connection for a home or office, we often block incoming traffic unless it relates to existing connections from the LAN. Unsolicited traffic does not make sense in this context and poses a security risk. To accomplish this feat, we will make use of netfilter's connection tracking extensions and restrict incoming traffic to packets that are part of an established connection or related to a recent egress packet. The connection tracking portion of this expression is ct state established,related . Example: Using the connection tracking extension table inet filter { chain forward { type filter hook forward priority 0; iifname <WAN> ct state established,related accept } }","title":"Using Connection State in Rules"},{"location":"resources/nftables/#default-policy-for-base-chains","text":"We are missing one piece to complete our configuration. By default, nftables accepts a packet unless a match occurs on a terminal rule. Base chains can override this behavior by defining a default policy. We'll use this feature to create a firewall that fail securely, i.e., blocking traffic that we don't explicitly allow. The following example adds a base chain policy in order to drop forwarded packets that we didn't allow from another rule. Example: Default drop policy table inet filter { chain forward { type filter hook forward priority 0; policy drop; # Explicitly allow \"safe\" connections iifname <LAN> oifname <WAN> accept iifname <WAN> ct state established,related accept } } The default deny posture is a best practice for your networks and devices, but it's important to approach the strategy with care. Without additional rules, attaching policy drop to the input and output chains will block inbound and outbound SSH and other protocols that might be needed for remote management. We will come back to this in a later guide, but we recommend for now that you leave the default accept policy on these chains.","title":"Default Policy (for Base Chains)"},{"location":"resources/nftables/#final-nat-template","text":"The following template draws together all of the components we have discussed so far to define a basic NAT configuration for a Linux router, leaving placeholder 4 , 5 elements for the reader to complete. Please review the previous examples and specifications that have been given in order to create a valid configuration. The following section will help you test and install your new ruleset. !!! info Routing / NAT template # Always flush the active ruleset before defining your new rules flush ruleset table inet filter { chain forward { type filter hook <HOOK> priority 0; policy <ACTION>; # Explicitly allow \"safe\" connections iifname <LAN> oifname <WAN> <ACTION> iifname <WAN> ct state established,related <ACTION> } chain input { type filter hook input priority 0; # You may leave this chain empty for now } chain output { type filter hook output priority 0; # You may leave this chain empty for now } } table ip nat { chain postrouting { type nat hook postrouting priority srcnat; oifname <WAN> masquerade } }","title":"Final NAT Template"},{"location":"resources/nftables/#configuring-nftables","text":"Throughout this guide, nftables configuration has been presented in a declarative, table-based format that closely reflects the table/chain/rule hierarchy. nftables also supports a command-based syntax that is passed to the nft utility on the command line or from within scripts in order to create, read, update, and delete individual elements of a ruleset dynamically. We generally want firewall and routing rules to be configured as soon as possible during the boot process. When the nftables service is started, Raspberry Pi OS will initialize it with the contents of /etc/nftables.conf . While experimentation is usually encouraged, you may encounter negative consequences if you make haphazard modifications to this file. A simple script is provided below to support the learning process by testing your ruleset before making changes permanent.","title":"Configuring nftables"},{"location":"resources/nftables/#enable-the-nftables-service","text":"The nftables service may not be running by default on your device. You can check on the current status of the daemon with systemctl status nftables . To launch the service immediately, run systemctl start nftables . To ensure that nftables also starts automatically at boot, run systemctl enable nftables .","title":"Enable the nftables Service"},{"location":"resources/nftables/#editing-nftable-rules-safely","text":"Here be Dragons Do not write rules directly to /etc/nftables.conf . Without proper testing, you risk creating a rule that locks you out of your device from the network. Create a working copy of /etc/nftables.conf into your home directory (it is okay to rename the file) . Open the new copy and ensure that flush ruleset near the top (before your table definitions). 6 Proceed with any modifications to the working copy. To test your ruleset, we recommend a scripted approach that can automatically revert a change that locks you out of the Pi. INFO314 students can find a copy of nftables-apply.sh in the project repository or create the script from the following listing. nftables-apply.sh #!/bin/bash # Adapted from https://sanjuroe.dev/nft-safe-reload (retrieved on 2022-04-03) # Modified to avoid editing system rules in-place SYSTEM_RULES=\"/etc/nftables.conf\" TIMEOUT=45 saved_rules=$(mktemp) cleanup() { rm -f \"$saved_rules\" } trap \"cleanup\" EXIT; # Waits $TIMEOUT seconds for a yes/no response read_approval() { read -t $TIMEOUT response 2> /dev/null case \"$response\" in y|Y) return 0 ;; *) return 1 ;; esac } # Make a copy of the active ruleset backup() { printf \"flush ruleset\\n\" > $saved_rules nft list ruleset >> $saved_rules } # Apply a named ruleset apply() { nft -f \"$1\" } # Update system ruleset save() { local source_rules=\"$1\" cp --no-preserve=mode,ownership \"$source_rules\" \"$SYSTEM_RULES\" } # Make a backup of the active ruleset in case of rollback backup new_rules=\"$1\" if apply \"$new_rules\"; then printf \"Are you still able to connect to your device (auto-rollback in $TIMEOUT seconds)? [y/n] \" if read_approval; then save \"$new_rules\" printf \"\\nUpdated system ruleset at ${SYSTEM_RULES}\\n\" exit 0 else apply \"$saved_rules\" printf \"\\nRolling back to original configuration\\n\" exit 2 fi fi To test your rules, pass the name of your new rules file to the nftables-apply.sh script, e.g., ./nftables-apply.sh nftables-test.conf . If your rules load without any errors, you will be prompted to answer whether you can still connect. Open an additional terminal window and launch SSH to connect to your Pi. If you are able to complete this step successfully, you can apply your changes to /etc/nftables.conf by answering y at the nftables-apply prompt in your original session. If the test fails, answer n or wait 45 seconds for the rules to revert automatically. Once you are satisified that your rules are working correctly, it's a good idea to verify that your rules are loaded and that everything works correctly after a reboot. Use the nft list ruleset command to view active rules.","title":"Editing nftable Rules Safely"},{"location":"resources/nftables/#resources","text":"Understanding Netfilter Hooks Securing Your Server with nftables Safe Reload with nftables Linux Network Administrators Guide - Masquerading These names were chosen to mirror the built-in tables of iptables . \u21a9 This naming convention is influenced by iptables and its built-in chains. \u21a9 netfilter also defines a prerouting nat hook that executes before routing decisions and can be used to implement port-forwarding and other destination NAT configurations. \u21a9 Text surrounded by <> symbols is indicative of a placeholder that should be filled in before loading the ruleset. \u21a9 Do not quote text substituted for placeholders unless quotes are shown in the template. \u21a9 nft -f <FILENAME> is additive by default. Including flush ruleset before your table/chain definitions ensures that the new ruleset is properly loaded. \u21a9","title":"Resources"},{"location":"resources/pi-materials/","text":"Required Class Materials \u00b6 In this course, you will need to purchase a Raspberry Pi 4 B. Many of the labs and exercises in this course are built around the Raspberry Pi's hardware. The Pi is a compact, single-board computer that can be used to create a Linux-based router and other common network components. Warning Please let us know ASAP if a lockdown is preventing packages or if sellers are indicating major delays. Also please keep a close eye on fulfillment times. All of the links provided here have reasonable times when we looked at them, but things can change quickly. Feel free to email with any questions. Please pay close attention to delivery time frames when ordering . We are hoping for students to be mostly equipped by approximately 4/8 For this reason, I don't recommend Amazon for the Raspberry Pi. Instead, check the following sources: PiShop.US US Shipping in 2 - 4 business days BestBuy Curbside Pickup in Seattle US shipping in about 8 days Canakit US shipping in 5 to 8 business days TL;DR \u00b6 Within the US: Order the Raspberry Pi hardware. At minimum, you will need: Board : Raspberry Pi 4 Model B (2GB version, Board Only, for $35 USD) Recommended US Seller: PiShop US Please keep the cardboard box the Pi came in as a safe place to store it when not in use. Power : Raspberry Pi 4 Power Supply (USB-C) Recommended US Seller: PiShop US Storage : A fast, microSD card, at least 8GB Recommended US Seller Ethernet Adapter : If your computer does not have an ethernet port , then you need a USB based Ethernet adapter. If your computer only has USB-A ports, you need a USB-A to Ethernet adapter Recommended US Seller If your computer only has USB-C ports, then you need a USB-C to Ethernet adapter Recommended US Seller Ethernet Cable : An ethernet cable long enough to connect your computer's ethernet port to your Raspberry Pi. Many people can find one of these at home, but you may need to purchase if you don't have one available Recommended US Seller A way to write to a microSD card. If you don't have access to a computer with a built-in SD reader/writer , a USB microSD card reader/writer will be essential. If your computer only has USB-A ports, you need a USB-A microSD card reader/writer Recommended US Seller If your computer only has USB-C ports, then you need a USB-CmicroSD card reader/writer Recommended US Seller In addition, we recommend getting these optional supplies . An inexpensive case for your Pi , though it should be pretty safe while using at home without a case. Recommended US Seller We typically recommend a USB-C battery pack rather than relying on AC (wall outlet) power, but this won't be a major issue with us meeting remotely. The battery bank must have 5 volt output at 3 amps, no less. Recommended US Seller Outside the US : Order the Raspberry Pi hardware. To do this: Please research your purchasing options and order right away if possible. To research, we recommend starting here: https://www.raspberrypi.org/products/raspberry-pi-4-model-b/ . Select 'Buy Now', then select '2GB RAM' and your country. Then select one of the options on the right. After doing some research, refer to the US guide above. You need to order the same 6 minimum parts as in the US guide above, and the optional ones are recommended too. You likely will need to use other websites for ordering parts 3 through 6. If you need help finding parts on the US list, please reach out to us. Materials: A Closer Look \u00b6 Compute \u00b6 The main hardware you need for this course is a Raspberry Pi 4 Model B. The Pi is a compact, single-board computer that can be used to create a Linux-based router and other common network components. We recommend the 2GB version of the Raspberry Pi 4 Model B, but if you ever plan to do other projects with the device after this course, feel free to upgrade to the 4GB model. We don't recommend the kits because they don't align well with our needs, and you can often save a lot of money by only buying the parts you need. That being said, feel free to buy a kit if you want it for the convenience. Make sure that you get all of the 6 required minimal parts in the list above, though. If you are shipping within the US, you may be able to get reasonable delivery times from these suppliers (Amazon is quoting one month for Seattle, so don't order it there unless you the shipping time is faster where you live): PiShop.US (Recomended) Canakit Chicago Electronics Distributors Power \u00b6 You will need something to power the Raspberry Pi. Typically in this course, we use external USB battery banks, but since this course is now remote, you can rely on AC (wall outlet) power instead. If going the AC power route, you need a USB-C power supply. We recommend the official power supply found here , but it may be easier to order it with your Pi as an add-on item. You can use another power supply if you have one, provided it meets the required specifications. The power supply needs to provide 3 amps of current at 5 volts, and needs to have a USB-C at the charging end. You can see if your power supply provides 3 amps of current by looking on the back of the power supply, where it will say something like 5V3A; 5V, 3A; 3A; or 3000mA. Note: we are talking about amps (A) and milliamps (mA), NOT milliamp-hours (mAh). If it says something smaller, like 2.4A or 1A, that won't cut it , and you need something else, like the recommended model. Also, you will need to power your Pi while your computer is on, so please don't assume you can use your only laptop charger to power your Pi! If going the battery bank power route, you will need a strong USB battery bank. We recommended this power bank that we have tested to work great with the Pi. If you want to use your own, the battery bank must have 5 volt output at 3 amps, no less, and needs to have a USB-C at the charging end. You can check if your battery bank provides 3 amps of current by looking on the back of the battery bank, where it will say something like 5V3A; 5V, 3A; 3A; or 3000mA. Note: we are talking about amps (A) and milliamps (mA), NOT milliamp-hours (mAh). If it says something smaller, like 2.4A or 1A, that won't cut it , and you need something else, like the recommended model. Storage \u00b6 In addition to the Raspberry Pi (and power), you will need a fast microSD card (> 8GB) on which to install the Linux operating system. I typically order these from Amazon to save money, but it may be easier to order with your Pi as an add-on item. Sandisk 16GB on Amazon Prime PNY 32GB on Amazon Prime Ethernet Adapter \u00b6 In addition to the Pi, please check on whether your computer has a built-in ethernet port available (most modern laptops do not). Since you will need to connect to ethernet in order to manage your Pi, you may need to purchase a USB-based Ethernet adapter . Determine whether your computer is USB-A or USB-C and then pick accordingly. If your computer only has USB-A ports, you need a USB-A to Ethernet adapter Recommended US Seller If your computer only has USB-C ports, then you need a USB-C to Ethernet adapter Recommended US Seller Ethernet Cable \u00b6 You will need an ethernet cable long enough to connect your computer's ethernet port to your Raspberry Pi. Many people can find one of these at home, but you may need to purchase if you don't have one available Recommended US Seller MicroSD Card Reader \u00b6 Finally, you will need a way to write to a microSD card. This is essential for setting up your Pi, but you shouldn't need it after the initial set-up. If you don't have access to a computer with a built-in SD reader/writer , a USB microSD card reader/writer will be essential. If your computer only has USB-A ports, you need a USB-A microSD card reader/writer Recommended US Seller If your computer only has USB-C ports, then you need a USB-CmicroSD card reader/writer Recommended US Seller Case \u00b6 An inexpensive case for your Pi is very nice to have, but is optional . The Pi by itself is a bare PCB, like a motherboard, so it is prone to damage if mishandled or placed in a bag without any other protection. Because we are remote, the Pi should be safe without a case at your house, but please keep the cardboard box the Pi came in as a safe place to store it when not in use. Most cases protect the Pi within a plastic shell. Some cases come with extra supplies, like heatsinks (metal fins that stick on the chips on the Pi to provide passive cooling), or even fans to cool the Pi. These aren't necessary for this class, but do help your Pi push itself to its limits in terms of CPU power, so they are nice especially if you are planning to use your Pi for other projects after this course. Right now on Amazon, I only found one case that does not have one-month shipping times. Recommended Case . This case comes with a nice heatsink for passive cooling. This case does not, however, come with a fan, so you may want to get a different case by doing your own research, or waiting a month for something with a fan like this case . Just make sure that the case supports a Raspberry Pi 4 Model B. \u200b","title":"Required Class Materials"},{"location":"resources/pi-materials/#required-class-materials","text":"In this course, you will need to purchase a Raspberry Pi 4 B. Many of the labs and exercises in this course are built around the Raspberry Pi's hardware. The Pi is a compact, single-board computer that can be used to create a Linux-based router and other common network components. Warning Please let us know ASAP if a lockdown is preventing packages or if sellers are indicating major delays. Also please keep a close eye on fulfillment times. All of the links provided here have reasonable times when we looked at them, but things can change quickly. Feel free to email with any questions. Please pay close attention to delivery time frames when ordering . We are hoping for students to be mostly equipped by approximately 4/8 For this reason, I don't recommend Amazon for the Raspberry Pi. Instead, check the following sources: PiShop.US US Shipping in 2 - 4 business days BestBuy Curbside Pickup in Seattle US shipping in about 8 days Canakit US shipping in 5 to 8 business days","title":"Required Class Materials"},{"location":"resources/pi-materials/#tldr","text":"Within the US: Order the Raspberry Pi hardware. At minimum, you will need: Board : Raspberry Pi 4 Model B (2GB version, Board Only, for $35 USD) Recommended US Seller: PiShop US Please keep the cardboard box the Pi came in as a safe place to store it when not in use. Power : Raspberry Pi 4 Power Supply (USB-C) Recommended US Seller: PiShop US Storage : A fast, microSD card, at least 8GB Recommended US Seller Ethernet Adapter : If your computer does not have an ethernet port , then you need a USB based Ethernet adapter. If your computer only has USB-A ports, you need a USB-A to Ethernet adapter Recommended US Seller If your computer only has USB-C ports, then you need a USB-C to Ethernet adapter Recommended US Seller Ethernet Cable : An ethernet cable long enough to connect your computer's ethernet port to your Raspberry Pi. Many people can find one of these at home, but you may need to purchase if you don't have one available Recommended US Seller A way to write to a microSD card. If you don't have access to a computer with a built-in SD reader/writer , a USB microSD card reader/writer will be essential. If your computer only has USB-A ports, you need a USB-A microSD card reader/writer Recommended US Seller If your computer only has USB-C ports, then you need a USB-CmicroSD card reader/writer Recommended US Seller In addition, we recommend getting these optional supplies . An inexpensive case for your Pi , though it should be pretty safe while using at home without a case. Recommended US Seller We typically recommend a USB-C battery pack rather than relying on AC (wall outlet) power, but this won't be a major issue with us meeting remotely. The battery bank must have 5 volt output at 3 amps, no less. Recommended US Seller Outside the US : Order the Raspberry Pi hardware. To do this: Please research your purchasing options and order right away if possible. To research, we recommend starting here: https://www.raspberrypi.org/products/raspberry-pi-4-model-b/ . Select 'Buy Now', then select '2GB RAM' and your country. Then select one of the options on the right. After doing some research, refer to the US guide above. You need to order the same 6 minimum parts as in the US guide above, and the optional ones are recommended too. You likely will need to use other websites for ordering parts 3 through 6. If you need help finding parts on the US list, please reach out to us.","title":"TL;DR"},{"location":"resources/pi-materials/#materials-a-closer-look","text":"","title":"Materials: A Closer Look"},{"location":"resources/pi-materials/#compute","text":"The main hardware you need for this course is a Raspberry Pi 4 Model B. The Pi is a compact, single-board computer that can be used to create a Linux-based router and other common network components. We recommend the 2GB version of the Raspberry Pi 4 Model B, but if you ever plan to do other projects with the device after this course, feel free to upgrade to the 4GB model. We don't recommend the kits because they don't align well with our needs, and you can often save a lot of money by only buying the parts you need. That being said, feel free to buy a kit if you want it for the convenience. Make sure that you get all of the 6 required minimal parts in the list above, though. If you are shipping within the US, you may be able to get reasonable delivery times from these suppliers (Amazon is quoting one month for Seattle, so don't order it there unless you the shipping time is faster where you live): PiShop.US (Recomended) Canakit Chicago Electronics Distributors","title":"Compute"},{"location":"resources/pi-materials/#power","text":"You will need something to power the Raspberry Pi. Typically in this course, we use external USB battery banks, but since this course is now remote, you can rely on AC (wall outlet) power instead. If going the AC power route, you need a USB-C power supply. We recommend the official power supply found here , but it may be easier to order it with your Pi as an add-on item. You can use another power supply if you have one, provided it meets the required specifications. The power supply needs to provide 3 amps of current at 5 volts, and needs to have a USB-C at the charging end. You can see if your power supply provides 3 amps of current by looking on the back of the power supply, where it will say something like 5V3A; 5V, 3A; 3A; or 3000mA. Note: we are talking about amps (A) and milliamps (mA), NOT milliamp-hours (mAh). If it says something smaller, like 2.4A or 1A, that won't cut it , and you need something else, like the recommended model. Also, you will need to power your Pi while your computer is on, so please don't assume you can use your only laptop charger to power your Pi! If going the battery bank power route, you will need a strong USB battery bank. We recommended this power bank that we have tested to work great with the Pi. If you want to use your own, the battery bank must have 5 volt output at 3 amps, no less, and needs to have a USB-C at the charging end. You can check if your battery bank provides 3 amps of current by looking on the back of the battery bank, where it will say something like 5V3A; 5V, 3A; 3A; or 3000mA. Note: we are talking about amps (A) and milliamps (mA), NOT milliamp-hours (mAh). If it says something smaller, like 2.4A or 1A, that won't cut it , and you need something else, like the recommended model.","title":"Power"},{"location":"resources/pi-materials/#storage","text":"In addition to the Raspberry Pi (and power), you will need a fast microSD card (> 8GB) on which to install the Linux operating system. I typically order these from Amazon to save money, but it may be easier to order with your Pi as an add-on item. Sandisk 16GB on Amazon Prime PNY 32GB on Amazon Prime","title":"Storage"},{"location":"resources/pi-materials/#ethernet-adapter","text":"In addition to the Pi, please check on whether your computer has a built-in ethernet port available (most modern laptops do not). Since you will need to connect to ethernet in order to manage your Pi, you may need to purchase a USB-based Ethernet adapter . Determine whether your computer is USB-A or USB-C and then pick accordingly. If your computer only has USB-A ports, you need a USB-A to Ethernet adapter Recommended US Seller If your computer only has USB-C ports, then you need a USB-C to Ethernet adapter Recommended US Seller","title":"Ethernet Adapter"},{"location":"resources/pi-materials/#ethernet-cable","text":"You will need an ethernet cable long enough to connect your computer's ethernet port to your Raspberry Pi. Many people can find one of these at home, but you may need to purchase if you don't have one available Recommended US Seller","title":"Ethernet Cable"},{"location":"resources/pi-materials/#microsd-card-reader","text":"Finally, you will need a way to write to a microSD card. This is essential for setting up your Pi, but you shouldn't need it after the initial set-up. If you don't have access to a computer with a built-in SD reader/writer , a USB microSD card reader/writer will be essential. If your computer only has USB-A ports, you need a USB-A microSD card reader/writer Recommended US Seller If your computer only has USB-C ports, then you need a USB-CmicroSD card reader/writer Recommended US Seller","title":"MicroSD Card Reader"},{"location":"resources/pi-materials/#case","text":"An inexpensive case for your Pi is very nice to have, but is optional . The Pi by itself is a bare PCB, like a motherboard, so it is prone to damage if mishandled or placed in a bag without any other protection. Because we are remote, the Pi should be safe without a case at your house, but please keep the cardboard box the Pi came in as a safe place to store it when not in use. Most cases protect the Pi within a plastic shell. Some cases come with extra supplies, like heatsinks (metal fins that stick on the chips on the Pi to provide passive cooling), or even fans to cool the Pi. These aren't necessary for this class, but do help your Pi push itself to its limits in terms of CPU power, so they are nice especially if you are planning to use your Pi for other projects after this course. Right now on Amazon, I only found one case that does not have one-month shipping times. Recommended Case . This case comes with a nice heatsink for passive cooling. This case does not, however, come with a fan, so you may want to get a different case by doing your own research, or waiting a month for something with a fan like this case . Just make sure that the case supports a Raspberry Pi 4 Model B. \u200b","title":"Case"},{"location":"resources/setup-frr/","text":"Getting Started with Free Range Routing (FRR) on Raspberry Pi OS (last edited 2022-05-20) \u00b6 Installation \u00b6 Since we are introducing a new software package, it is a good idea to review the project homepage and learn what resources are provided to you. The FRRouting home page at https://frrouting.org provides links to official documentation as well as to download the current software release. As we have with other installs, we would like to rely on package-based installation with apt . FRRouting does provide installation packages, but these are not included in the default repositories for Raspberry Pi OS or other Debian-based Linux flavors. To resolve this issue, navigate to the Releases section of the home page and follow the link for Debian packages. Follow the instructions at this link in order to add a new package repository to apt and install the FRRouting software on your Pi. Getting Started \u00b6 The official FRRouting documentation linked from the home page also contains a Basic Setup section. While this document is helpful, it is unfortunately missing some details that would be helpful to new users. You can follow the instructions below to finish installing FRR and connect to its management shell for the first time. Give the Pi user permission to run the FRR managment client a. Run sudo usermod -aG frrvty pi to add the pi user to the frrvty management group b. Logout (exit SSH) and return in order for Linux to recognize your new privileges Fix file system permissions a. Run sudo chmod o+x /etc/frr to enable directory level access needed to read/write configuration files. b. Run sudo install -o frr -g frrvty -m 660 /dev/null /etc/frr/vtysh.conf to create an empty configuration file called vtysh.conf with the necessary ownership and permissions. This handy one-liner creates the file and then sets user/group ownership and permissions without needing to make separate calls to chmod and chown . Enable the BGP routing daemon a. Edit /etc/frr/daemons and set bgpd=yes . b. If applicable, repeat this process for other routing daemons. Restart FRRouting: sudo systemctl restart frr Learn the basics of navigating VTY Shell Basics \u00b6 Launch VTY shell \u00b6 To manage FRR, we will use a dedicated UI called the VTY shell. Launch the shell with the vtysh command. VTYSH modes \u00b6 While using the VTY shell, you'll need to switch between modes . While most of our work will be conducted in Configuration Mode , the shell will launch initially in Enable mode . To enter Configuration Mode, type configure terminal at the VTY shell prompt. To exit Configuration Mode and return to Enable Mode, type exit . Save Configuration (from enable mode) \u00b6 Configuration changes you make from VTY shell will take effect right away, but they do not persist between reboots due to a distinction FRR makes between the Running Config and the Startup Config . To save your changes to disk( /etc/frr/frr.conf ), run write memory or copy running-config startup-config from Enable Mode. This command will fail if run from Configuration Mode. Return to Enable Mode and try again if you receive an Unknown command error. Show the Running Config (from enable mode) \u00b6 To view the active Running Config, return to Enable Mode and enter show running-config or write terminal at the prompt. Shortcuts \u00b6 Command abbreviations are accepted in VTY shell as long as the abbreviation is unambiguous. The shell will do its best to determine your intent and complete the command. configure terminal can be abbreviated conf quit can be abbreviated q write memory can be abbreviated w m","title":"Install Free Range Routing (FRR)"},{"location":"resources/setup-frr/#getting-started-with-free-range-routing-frr-on-raspberry-pi-os-last-edited-2022-05-20","text":"","title":"Getting Started with Free Range Routing (FRR) on Raspberry Pi OS (last edited 2022-05-20)"},{"location":"resources/setup-frr/#installation","text":"Since we are introducing a new software package, it is a good idea to review the project homepage and learn what resources are provided to you. The FRRouting home page at https://frrouting.org provides links to official documentation as well as to download the current software release. As we have with other installs, we would like to rely on package-based installation with apt . FRRouting does provide installation packages, but these are not included in the default repositories for Raspberry Pi OS or other Debian-based Linux flavors. To resolve this issue, navigate to the Releases section of the home page and follow the link for Debian packages. Follow the instructions at this link in order to add a new package repository to apt and install the FRRouting software on your Pi.","title":"Installation"},{"location":"resources/setup-frr/#getting-started","text":"The official FRRouting documentation linked from the home page also contains a Basic Setup section. While this document is helpful, it is unfortunately missing some details that would be helpful to new users. You can follow the instructions below to finish installing FRR and connect to its management shell for the first time. Give the Pi user permission to run the FRR managment client a. Run sudo usermod -aG frrvty pi to add the pi user to the frrvty management group b. Logout (exit SSH) and return in order for Linux to recognize your new privileges Fix file system permissions a. Run sudo chmod o+x /etc/frr to enable directory level access needed to read/write configuration files. b. Run sudo install -o frr -g frrvty -m 660 /dev/null /etc/frr/vtysh.conf to create an empty configuration file called vtysh.conf with the necessary ownership and permissions. This handy one-liner creates the file and then sets user/group ownership and permissions without needing to make separate calls to chmod and chown . Enable the BGP routing daemon a. Edit /etc/frr/daemons and set bgpd=yes . b. If applicable, repeat this process for other routing daemons. Restart FRRouting: sudo systemctl restart frr","title":"Getting Started"},{"location":"resources/setup-frr/#learn-the-basics-of-navigating-vty-shell-basics","text":"","title":"Learn the basics of navigating VTY Shell Basics"},{"location":"resources/setup-frr/#launch-vty-shell","text":"To manage FRR, we will use a dedicated UI called the VTY shell. Launch the shell with the vtysh command.","title":"Launch VTY shell"},{"location":"resources/setup-frr/#vtysh-modes","text":"While using the VTY shell, you'll need to switch between modes . While most of our work will be conducted in Configuration Mode , the shell will launch initially in Enable mode . To enter Configuration Mode, type configure terminal at the VTY shell prompt. To exit Configuration Mode and return to Enable Mode, type exit .","title":"VTYSH modes"},{"location":"resources/setup-frr/#save-configuration-from-enable-mode","text":"Configuration changes you make from VTY shell will take effect right away, but they do not persist between reboots due to a distinction FRR makes between the Running Config and the Startup Config . To save your changes to disk( /etc/frr/frr.conf ), run write memory or copy running-config startup-config from Enable Mode. This command will fail if run from Configuration Mode. Return to Enable Mode and try again if you receive an Unknown command error.","title":"Save Configuration (from enable mode)"},{"location":"resources/setup-frr/#show-the-running-config-from-enable-mode","text":"To view the active Running Config, return to Enable Mode and enter show running-config or write terminal at the prompt.","title":"Show the Running Config (from enable mode)"},{"location":"resources/setup-frr/#shortcuts","text":"Command abbreviations are accepted in VTY shell as long as the abbreviation is unambiguous. The shell will do its best to determine your intent and complete the command. configure terminal can be abbreviated conf quit can be abbreviated q write memory can be abbreviated w m","title":"Shortcuts"},{"location":"resources/setup-wireguard/","text":"Installing and Configuring WireGuard on Raspbian and Debian-based Linux \u00b6 Before you Begin \u00b6 These instructions will aide you with installation of WireGuard on Raspbian/Debian Buster. They have been tested on the February 2020 release of Raspbian Buster and on a Debian 10.3 droplet on DigitalOcean. Instructions may differ for other distributions or releases. Installing WireGuard \u00b6 Locating an Installation Package \u00b6 While WireGuard support has been added to recent versions of the Linux Kernel, this milestone was not reached until after the Debian and Raspbian teams had frozen features for Buster. At the time this guide was written, the WireGuard application and kernel module were not yet available in the mainline Debian and Raspbian package repositories. However, we can obtain these components from Debian's backport repository for Buster, a collection of new and updated software compiled for Buster. Depending on your installation, buster-backports may already be listed as a valid software source. We found this to be the case for Debian 10.3 on DigitalOcean, though on Raspbian, we needed to manually add buster-backports as a new source and import the signing keys used to verify the integrity of software installed from the repositories. Check Existing Package Sources \u00b6 Before you proceed, determine whether manual configuration of backports is necessary: # Search existing apt package source locations apt-cache policy | grep buster-backports Manually Configure Backports \u00b6 After completing the following steps, apt operations will consider packages from the backports repository while still preferring stable software versions from the mainline repository when available. # Import the PGP/GPG signing keys for buster-backports from a key server sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 04EE7237B7D453EC 648ACFD622F3D138 # Add the backports repositories to the apt configuration echo \"deb http://deb.debian.org/debian/ buster-backports main contrib non-free\" | sudo tee -a /etc/apt/sources.list.d/debian-backports.list # Update the local software catalog via apt sudo apt update Install Linux Kernel Headers \u00b6 The WireGuard package in backports repository attempts to compile a kernel module in order to add WireGuard networking capabilities. To complete this task, the compiler must have access to kernel headers, a set of files that define the interface of kernel functions and data structures. The kernel headers are available as a package and accessible via apt . Installation depends on your chosen distribution: Installing Kernel Headers for Raspbian \u00b6 sudo apt install raspberrypi-kernel-headers Installing Kernel Headers for Debian \u00b6 # `uname -r` is used to specify the proper kernel version sudo apt install linux-headers- $( uname -r ) Install WireGuard and the DKMS-based module \u00b6 Finally, with the pre-requisites in place, we can use apt to install WireGuard and all of its supporting components. Once installed, you can use modprobe as shown below to verify that it the WireGuard kernel module is recognized by the kernel. # Install sudo apt install wireguard wireguard-dkms # Verify (should return without any output/error) sudo modprobe wireguard Getting Started with WireGuard \u00b6 The aim of the WireGuard project is to provide a fast and simple VPN that relies on rock-solid, modern cryptography. Generate a WireGuard Key Pair for each Server \u00b6 Every node participating in a WireGuard VPN is required to have a private key for its own use and a public key that will be distributed to each of its peers. Before setting up our own VPN, we need to generate these keys on each server. The following commands open a root-privileged shell in order to generate the keys. This extra step allows us to ensure proper file ownership and permissions via umask (which doesn't work smoothly with sudo) # Open a root shell sudo bash # Override default file creation permissions umask 077 # Create the public and private keys in /etc/wireguard wg genkey | tee -a /etc/wireguard/privatekey | wg pubkey > /etc/wireguard/publickey # Close the root shell exit After generating the keys for your servers, be sure to document the publickey for each endpoint. You\u2019ll need it again in order to configure each of your VPN peers. Identify Additional Parameters for your VPN \u00b6 Endpoint IP and Ports \u00b6 The endpoint addresses of a WireGuard VPN are the external addresses that peers will use in order to initiate connections with one another and to forward the encrypted payloads (via UDP datagrams that fully encapsulate the traffic sent/received on a virtual network interface). Each endpoint of a WireGuard VPN can function as both client and server (hence the name peer), however, taking full advanatage of this capability requires that all endpoints have routeable addresses. Due to NAT and/or firewall configurations, we may have endpoints that aren't directly reachable. WireGuard provides utilities to cope with this scenario, as long as at least one endpoint is able to receive incoming sessions from its peer(s). As with all servers, a routeable peer must define a port on which it will listen for incoming messages. WireGuard does not provide a standard port configuration, so it is up to administrators to determine an appropriate UDP port for WireGuard server to listen. Since we will be configuring multiple instances of WireGuard on our servers, we should pay close attention to which ports are in use so that we don't cause a collision between independent tunnel interfaces. In the following examples, we will assume that we have one publicly routeable peer and one located behind a NAT. We'll use port 51820 to listen for connections on the routeable peer. Tunnel IP addresses \u00b6 WireGuard VPN connections are presented at the OS level as layer-3 network interfaces and will be configured with their own IP subnet/address settings. The main constraint is that these addresses are not part of any other subnet connected to the same device. For example, if my LAN is using 172.27.2.0/26 and my home network is 10.0.1.0/24, I cannot use anything from 172.27.2.0 - 63 or 10.0.1.0 - 255. I could, however, use addresses above 172.27.2.64. The constraint above isn\u2019t anything unique to WireGuard, we\u2019re simply following the principle that you can\u2019t route between networks with overlapping IP ranges (in the same way that we can\u2019t give the same address to two nodes on the same network). The following examples will define tunnel addresses of 10.99.0.2 and 10.99.0.3 for traffic sent inside the VPN. Create WireGuard Interfaces \u00b6 In order to send and receive network traffic through a VPN, each peer is configured with a virtual network interface. Any traffic sent to this interface will be transported over the VPN tunnel. Incoming traffic will egress on this interface after being processed and decrypted by WireGuard. The following examples demonstrate the use of the ip command to manually set up the virtual interface for WireGuard. You should be aware that any configuration you set up with this utility is not persistent. It will be reset after a reboot. Persistent WireGuard configuration will be covered separately. # Create the virtual interface sudo ip link add dev wg0 type wireguard # Assign a tunnel address to the interface (your second peer will reverse the order of these arguments) sudo ip addr add dev wg0 10.99.0.2 peer 10.99.0.3 # Bring the interface online sudo ip link set up dev wg0 Create your Peers \u00b6 Configure wireguard to use the new virtual interface to maintain a tunnel with its peer. As in the previous step, we\u2019ll use the CLI interface to do this manually and come back later to add a persistent configuration. # Gather the public addresses for your peers (as applicable). You should have a public address for your DO peer, and you will need it to set up the Pi. Since the Pi is behind a NAT on your home network, we can't reach it directly with a public IPv4 address. As such, we'll always rely on the Pi to initiate the connection to Digital Ocean. I'll discuss implications of this later and how to deal with any limitations. # The core command looks like `wg set <INTERFACE> listen-port <PORT> private-key <PRIVATE KEY PATH> peer <PUBLIC KEY OF PEER> allowed-ips <List of CIDR IP ranges> endpoint <PUBLIC IP OF PEER>:<PORT>`. # Raspberry Pi / no public IP to listen on (replace public key and address of DO endpoint) sudo wg set wg0 private-key /etc/wireguard/privatekey peer ABCDEFG allowed-ips 0.0.0.0/0 endpoint A.B.C.D:51280 # DigitalOcean / has its own public IP to listen on but can't reach RPi directly wg set wg0 listen-port 51280 private-key /etc/wireguard/privatekey peer ABCDEFG allowed-ips 0.0.0.0/0 Observe how we adjusted the command when one of the peers doesn\u2019t have a routable public IP. The downside of this scenario is that the tunnel can only be initiated from one side of the link, and we won\u2019t be able to receive inbound traffic until it\u2019s open. We\u2019ll come back to discuss how to set up a keep-alive so that the tunnel is always open. When we have the luxury of public IP addresses for both peers, we should aim to set up both ends to listen and to connect to the peer endpoint. Test your Tunnel \u00b6 If everything has gone well to this point, make sure that you can ping each peer using its tunnel IP address. This may not seem like the most impressive feat , but we\u2019ll quickly expand the functionality by adding the ability to forward traffic between other attached networks. In order to do this, we need to set up routes for each subnet and add iptables rules that allow traffic to be forwarded on our new interfaces. If you\u2019d like to experiment with this on your own, check out the ip route command in order to program static routes. Our upcoming tasks will focus on using dynamic routing to automate the route configuration for the entire class network (which will have more than 30 routers and subnets).","title":"Install and Configure WireGuard"},{"location":"resources/setup-wireguard/#installing-and-configuring-wireguard-on-raspbian-and-debian-based-linux","text":"","title":"Installing and Configuring WireGuard on Raspbian and Debian-based Linux"},{"location":"resources/setup-wireguard/#before-you-begin","text":"These instructions will aide you with installation of WireGuard on Raspbian/Debian Buster. They have been tested on the February 2020 release of Raspbian Buster and on a Debian 10.3 droplet on DigitalOcean. Instructions may differ for other distributions or releases.","title":"Before you Begin"},{"location":"resources/setup-wireguard/#installing-wireguard","text":"","title":"Installing WireGuard"},{"location":"resources/setup-wireguard/#locating-an-installation-package","text":"While WireGuard support has been added to recent versions of the Linux Kernel, this milestone was not reached until after the Debian and Raspbian teams had frozen features for Buster. At the time this guide was written, the WireGuard application and kernel module were not yet available in the mainline Debian and Raspbian package repositories. However, we can obtain these components from Debian's backport repository for Buster, a collection of new and updated software compiled for Buster. Depending on your installation, buster-backports may already be listed as a valid software source. We found this to be the case for Debian 10.3 on DigitalOcean, though on Raspbian, we needed to manually add buster-backports as a new source and import the signing keys used to verify the integrity of software installed from the repositories.","title":"Locating an Installation Package"},{"location":"resources/setup-wireguard/#check-existing-package-sources","text":"Before you proceed, determine whether manual configuration of backports is necessary: # Search existing apt package source locations apt-cache policy | grep buster-backports","title":"Check Existing Package Sources"},{"location":"resources/setup-wireguard/#manually-configure-backports","text":"After completing the following steps, apt operations will consider packages from the backports repository while still preferring stable software versions from the mainline repository when available. # Import the PGP/GPG signing keys for buster-backports from a key server sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 04EE7237B7D453EC 648ACFD622F3D138 # Add the backports repositories to the apt configuration echo \"deb http://deb.debian.org/debian/ buster-backports main contrib non-free\" | sudo tee -a /etc/apt/sources.list.d/debian-backports.list # Update the local software catalog via apt sudo apt update","title":"Manually Configure Backports"},{"location":"resources/setup-wireguard/#install-linux-kernel-headers","text":"The WireGuard package in backports repository attempts to compile a kernel module in order to add WireGuard networking capabilities. To complete this task, the compiler must have access to kernel headers, a set of files that define the interface of kernel functions and data structures. The kernel headers are available as a package and accessible via apt . Installation depends on your chosen distribution:","title":"Install Linux Kernel Headers"},{"location":"resources/setup-wireguard/#installing-kernel-headers-for-raspbian","text":"sudo apt install raspberrypi-kernel-headers","title":"Installing Kernel Headers for Raspbian"},{"location":"resources/setup-wireguard/#installing-kernel-headers-for-debian","text":"# `uname -r` is used to specify the proper kernel version sudo apt install linux-headers- $( uname -r )","title":"Installing Kernel Headers for Debian"},{"location":"resources/setup-wireguard/#install-wireguard-and-the-dkms-based-module","text":"Finally, with the pre-requisites in place, we can use apt to install WireGuard and all of its supporting components. Once installed, you can use modprobe as shown below to verify that it the WireGuard kernel module is recognized by the kernel. # Install sudo apt install wireguard wireguard-dkms # Verify (should return without any output/error) sudo modprobe wireguard","title":"Install WireGuard and the DKMS-based module"},{"location":"resources/setup-wireguard/#getting-started-with-wireguard","text":"The aim of the WireGuard project is to provide a fast and simple VPN that relies on rock-solid, modern cryptography.","title":"Getting Started with WireGuard"},{"location":"resources/setup-wireguard/#generate-a-wireguard-key-pair-for-each-server","text":"Every node participating in a WireGuard VPN is required to have a private key for its own use and a public key that will be distributed to each of its peers. Before setting up our own VPN, we need to generate these keys on each server. The following commands open a root-privileged shell in order to generate the keys. This extra step allows us to ensure proper file ownership and permissions via umask (which doesn't work smoothly with sudo) # Open a root shell sudo bash # Override default file creation permissions umask 077 # Create the public and private keys in /etc/wireguard wg genkey | tee -a /etc/wireguard/privatekey | wg pubkey > /etc/wireguard/publickey # Close the root shell exit After generating the keys for your servers, be sure to document the publickey for each endpoint. You\u2019ll need it again in order to configure each of your VPN peers.","title":"Generate a WireGuard Key Pair for each Server"},{"location":"resources/setup-wireguard/#identify-additional-parameters-for-your-vpn","text":"","title":"Identify Additional Parameters for your VPN"},{"location":"resources/setup-wireguard/#endpoint-ip-and-ports","text":"The endpoint addresses of a WireGuard VPN are the external addresses that peers will use in order to initiate connections with one another and to forward the encrypted payloads (via UDP datagrams that fully encapsulate the traffic sent/received on a virtual network interface). Each endpoint of a WireGuard VPN can function as both client and server (hence the name peer), however, taking full advanatage of this capability requires that all endpoints have routeable addresses. Due to NAT and/or firewall configurations, we may have endpoints that aren't directly reachable. WireGuard provides utilities to cope with this scenario, as long as at least one endpoint is able to receive incoming sessions from its peer(s). As with all servers, a routeable peer must define a port on which it will listen for incoming messages. WireGuard does not provide a standard port configuration, so it is up to administrators to determine an appropriate UDP port for WireGuard server to listen. Since we will be configuring multiple instances of WireGuard on our servers, we should pay close attention to which ports are in use so that we don't cause a collision between independent tunnel interfaces. In the following examples, we will assume that we have one publicly routeable peer and one located behind a NAT. We'll use port 51820 to listen for connections on the routeable peer.","title":"Endpoint IP and Ports"},{"location":"resources/setup-wireguard/#tunnel-ip-addresses","text":"WireGuard VPN connections are presented at the OS level as layer-3 network interfaces and will be configured with their own IP subnet/address settings. The main constraint is that these addresses are not part of any other subnet connected to the same device. For example, if my LAN is using 172.27.2.0/26 and my home network is 10.0.1.0/24, I cannot use anything from 172.27.2.0 - 63 or 10.0.1.0 - 255. I could, however, use addresses above 172.27.2.64. The constraint above isn\u2019t anything unique to WireGuard, we\u2019re simply following the principle that you can\u2019t route between networks with overlapping IP ranges (in the same way that we can\u2019t give the same address to two nodes on the same network). The following examples will define tunnel addresses of 10.99.0.2 and 10.99.0.3 for traffic sent inside the VPN.","title":"Tunnel IP addresses"},{"location":"resources/setup-wireguard/#create-wireguard-interfaces","text":"In order to send and receive network traffic through a VPN, each peer is configured with a virtual network interface. Any traffic sent to this interface will be transported over the VPN tunnel. Incoming traffic will egress on this interface after being processed and decrypted by WireGuard. The following examples demonstrate the use of the ip command to manually set up the virtual interface for WireGuard. You should be aware that any configuration you set up with this utility is not persistent. It will be reset after a reboot. Persistent WireGuard configuration will be covered separately. # Create the virtual interface sudo ip link add dev wg0 type wireguard # Assign a tunnel address to the interface (your second peer will reverse the order of these arguments) sudo ip addr add dev wg0 10.99.0.2 peer 10.99.0.3 # Bring the interface online sudo ip link set up dev wg0","title":"Create WireGuard Interfaces"},{"location":"resources/setup-wireguard/#create-your-peers","text":"Configure wireguard to use the new virtual interface to maintain a tunnel with its peer. As in the previous step, we\u2019ll use the CLI interface to do this manually and come back later to add a persistent configuration. # Gather the public addresses for your peers (as applicable). You should have a public address for your DO peer, and you will need it to set up the Pi. Since the Pi is behind a NAT on your home network, we can't reach it directly with a public IPv4 address. As such, we'll always rely on the Pi to initiate the connection to Digital Ocean. I'll discuss implications of this later and how to deal with any limitations. # The core command looks like `wg set <INTERFACE> listen-port <PORT> private-key <PRIVATE KEY PATH> peer <PUBLIC KEY OF PEER> allowed-ips <List of CIDR IP ranges> endpoint <PUBLIC IP OF PEER>:<PORT>`. # Raspberry Pi / no public IP to listen on (replace public key and address of DO endpoint) sudo wg set wg0 private-key /etc/wireguard/privatekey peer ABCDEFG allowed-ips 0.0.0.0/0 endpoint A.B.C.D:51280 # DigitalOcean / has its own public IP to listen on but can't reach RPi directly wg set wg0 listen-port 51280 private-key /etc/wireguard/privatekey peer ABCDEFG allowed-ips 0.0.0.0/0 Observe how we adjusted the command when one of the peers doesn\u2019t have a routable public IP. The downside of this scenario is that the tunnel can only be initiated from one side of the link, and we won\u2019t be able to receive inbound traffic until it\u2019s open. We\u2019ll come back to discuss how to set up a keep-alive so that the tunnel is always open. When we have the luxury of public IP addresses for both peers, we should aim to set up both ends to listen and to connect to the peer endpoint.","title":"Create your Peers"},{"location":"resources/setup-wireguard/#test-your-tunnel","text":"If everything has gone well to this point, make sure that you can ping each peer using its tunnel IP address. This may not seem like the most impressive feat , but we\u2019ll quickly expand the functionality by adding the ability to forward traffic between other attached networks. In order to do this, we need to set up routes for each subnet and add iptables rules that allow traffic to be forwarded on our new interfaces. If you\u2019d like to experiment with this on your own, check out the ip route command in order to program static routes. Our upcoming tasks will focus on using dynamic routing to automate the route configuration for the entire class network (which will have more than 30 routers and subnets).","title":"Test your Tunnel"},{"location":"resources/ssh-agent/","text":"Using the SSH Agent to Manage Login Keys \u00b6 SSH keys can provide a notable improvement over password-based security (with respect to certain threats), but they are not without inconvenience or risk. Most notably, if we don't use encryption with strong passphrases to keys on disk, an intruder or piece of malware can more easily retrieve our keys and use them to access any resources we are permitted to access. Moreover, when we encrypt our private keys, we face the potential inconvenience of supplying the passphrase each time we run ssh . To ease the burden of using keys in the proper manner, OpenSSH provides a helper service, i.e., ssh-agent , to help you manage your private keys. Once an identity has been added to the ssh-agent , the agent can use the private key to log into servers without requiring you to enter a password for the the server or supply the key's passphrase. The ssh-agent helper is available for both macOS and Windows 10 (as well as Linux), but the configuration process varies for each system. By following the instructions provided in this guide when you first set up your private keys, you'll be able to take advantage of the security improvements offered by key-based SSH authentication with OpenSSH on your macOS or Windows 10 device. Configuring ssh-agent for macOS \u00b6 Configure OpenSSH to work with ssh-agent and macOS KeyChain Launch the ssh-agent as a background service. Use ssh-add to load your keys into the agent. Step 1 \u00b6 Edit or create ~/.ssh/config so that ssh-agent and macOS KeyChain are used automatically to manage private keys and passphrases. This configuration is required by the version of ssh distributed by Apple since macOS Sierra 10.12.2. Host * AddKeysToAgent yes UseKeyChain yes Step 2 \u00b6 Launch the ssh-agent as a background service. # The eval $() syntax is used to update the current environment based on the output of the ssh-agent command $ eval \" $( ssh-agent -s ) \" Add your key to the ssh-agent using the ssh-add utility. Step 3 \u00b6 # The -K option is required for some versions of macOS. Omit if it returns an error. ssh-add -K ~/.ssh/id_ed25519 # Check that your key is loaded by listing current keys in the agent ssh-add -l Configuring ssh-agent for Windows 10 \u00b6 Enable the ssh-agent Windows Service (disabled by default). Configure Powershell to launch ssh-agent when you open a console. Use ssh-add to load your keys into the agent. Step 1 \u00b6 Launch Powershell with administrator privileges and set the startup mode for the ssh-agent service to Manual since it is configured by default as Disabled . Set-Service -Name ssh-agent -StartupType Manual Step 2 \u00b6 Open a normal (non-administrator) Powershell console and edit/create a profile script to automatically launch the ssh-agent service. In order to do this, we need to enable the ability to run basic scripts on the system and then find the location of the script (automatically assigned by Windows to the $PROFILE variable). # Modify Powershell policy to allow basic powershell scripts to run Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser # Test whether the profile script exists Test-Path $PROFILE # If the previous command returns False, create the file New-Item -path $PROFILE -type file -force # Launch Notepad.exe to create a script notepad . exe $PROFILE Use Notepad to add the following code to your profile script. This will be run each time you launch a new console. # Launch the service if it's not already running $agentService = Get-Service -Name ssh-agent if ( $agentService . Status -ne \"Running\" ) { Start-Service -Name ssh-agent } Step 3 \u00b6 Open a fresh Powershell console and add your keys to the agent. # Add the private key to the ssh-agent ssh-add $HOME \\. ssh \\ id_ed25519 # Check that your key is loaded by listing current keys in the agent ssh-add -l","title":"Using the SSH Agent"},{"location":"resources/ssh-agent/#using-the-ssh-agent-to-manage-login-keys","text":"SSH keys can provide a notable improvement over password-based security (with respect to certain threats), but they are not without inconvenience or risk. Most notably, if we don't use encryption with strong passphrases to keys on disk, an intruder or piece of malware can more easily retrieve our keys and use them to access any resources we are permitted to access. Moreover, when we encrypt our private keys, we face the potential inconvenience of supplying the passphrase each time we run ssh . To ease the burden of using keys in the proper manner, OpenSSH provides a helper service, i.e., ssh-agent , to help you manage your private keys. Once an identity has been added to the ssh-agent , the agent can use the private key to log into servers without requiring you to enter a password for the the server or supply the key's passphrase. The ssh-agent helper is available for both macOS and Windows 10 (as well as Linux), but the configuration process varies for each system. By following the instructions provided in this guide when you first set up your private keys, you'll be able to take advantage of the security improvements offered by key-based SSH authentication with OpenSSH on your macOS or Windows 10 device.","title":"Using the SSH Agent to Manage Login Keys"},{"location":"resources/ssh-agent/#configuring-ssh-agent-for-macos","text":"Configure OpenSSH to work with ssh-agent and macOS KeyChain Launch the ssh-agent as a background service. Use ssh-add to load your keys into the agent.","title":"Configuring ssh-agent for macOS"},{"location":"resources/ssh-agent/#step-1","text":"Edit or create ~/.ssh/config so that ssh-agent and macOS KeyChain are used automatically to manage private keys and passphrases. This configuration is required by the version of ssh distributed by Apple since macOS Sierra 10.12.2. Host * AddKeysToAgent yes UseKeyChain yes","title":"Step 1"},{"location":"resources/ssh-agent/#step-2","text":"Launch the ssh-agent as a background service. # The eval $() syntax is used to update the current environment based on the output of the ssh-agent command $ eval \" $( ssh-agent -s ) \" Add your key to the ssh-agent using the ssh-add utility.","title":"Step 2"},{"location":"resources/ssh-agent/#step-3","text":"# The -K option is required for some versions of macOS. Omit if it returns an error. ssh-add -K ~/.ssh/id_ed25519 # Check that your key is loaded by listing current keys in the agent ssh-add -l","title":"Step 3"},{"location":"resources/ssh-agent/#configuring-ssh-agent-for-windows-10","text":"Enable the ssh-agent Windows Service (disabled by default). Configure Powershell to launch ssh-agent when you open a console. Use ssh-add to load your keys into the agent.","title":"Configuring ssh-agent for Windows 10"},{"location":"resources/ssh-agent/#step-1_1","text":"Launch Powershell with administrator privileges and set the startup mode for the ssh-agent service to Manual since it is configured by default as Disabled . Set-Service -Name ssh-agent -StartupType Manual","title":"Step 1"},{"location":"resources/ssh-agent/#step-2_1","text":"Open a normal (non-administrator) Powershell console and edit/create a profile script to automatically launch the ssh-agent service. In order to do this, we need to enable the ability to run basic scripts on the system and then find the location of the script (automatically assigned by Windows to the $PROFILE variable). # Modify Powershell policy to allow basic powershell scripts to run Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser # Test whether the profile script exists Test-Path $PROFILE # If the previous command returns False, create the file New-Item -path $PROFILE -type file -force # Launch Notepad.exe to create a script notepad . exe $PROFILE Use Notepad to add the following code to your profile script. This will be run each time you launch a new console. # Launch the service if it's not already running $agentService = Get-Service -Name ssh-agent if ( $agentService . Status -ne \"Running\" ) { Start-Service -Name ssh-agent }","title":"Step 2"},{"location":"resources/ssh-agent/#step-3_1","text":"Open a fresh Powershell console and add your keys to the agent. # Add the private key to the ssh-agent ssh-add $HOME \\. ssh \\ id_ed25519 # Check that your key is loaded by listing current keys in the agent ssh-add -l","title":"Step 3"},{"location":"resources/ssh-primer/","text":"Getting Started with SSH \u00b6 SSH stands for 'Secure Shell'. A 'shell' is a command line interface, such as the one's you've seen in Terminal, PowerShell, or Git Bash. Throughout this course, you'll be using the shell, remotely, to configure Linux. Connecting to a Server \u00b6 The basic syntax for ssh is: ssh <USERNAME>@<HOST> For example, in order to connect to a new install of Raspberry Pi OS, enter ssh pi@raspberrypi.local . If successful, you should receive a message and prompt that you must respond to in order to continue: Unknown Host Prompt The authenticity of host 'raspberrypi.local (fe80::0f0e:0d0c:0b0a:0908%en9)' can't be established. ED25519 key fingerprint is SHA256:gy7+oAsjNc5gvP7aaR9k9Wl/oMdCLjAy2MJL8ZaQ9N0. This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? This message indicates that your local SSH client is attempting to authenticate the remote server. While SSH clients have the option to authenticate with a password, SSH servers are only able to authenticate themselves using keys. Since we've never connected to this server, the client is asking whether to trust the public key information that has been presented. If you accept, SSH will store a fingerprint locally and pull it up whenever you reach out to the same hostname or IP address. This mechanism is known as Trust on First Use (TOFU) . Type yes and press Enter to continue. If the server authenticates you successfully, it should return a login message and a prompt. If authentication fails, you should be prompted for a password or disconnected (if the user doesn't exist or password authentication is disabled). Successful connection with client certificates Warning: Permanently added 'raspberrypi.local' (ED25519) to the list of known hosts. Linux raspberrypi 5.10.103-v8+ #1530 SMP PREEMPT Tue Mar 8 13:06:35 GMT 2022 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Thu Mar 31 00:32:28 2022 from fe80::0102:0304:0506:0708%eth0 pi@raspberrypi:~ $ Create SSH client keys \u00b6 When you are connecting to a remote server, you'll need a way to authenticate yourself and login to your server. While you can use a standard password, it is not a smart security practice. Rather, it's important to learn to generate and use a public keypair for SSH. A keypair is composed of a private key and a public key. Your public key can be given out, to say, GitHub or DigitalOcean, while your private key should never leave your device. OpenSSH is shipped with a utility called ssh-keygen that will generate a keypair for you. To create your SSH keypair, use ssh-keygen as follows: With either Terminal (for Mac) or PowerShell/Git Bash (for Windows) run the following command with your own email address: ssh-keygen -t ed25519 -C <DESCRIPTION> When prompted for a file name for the private SSH key. Accept the default by pressing ++Enter++. 1 You will be prompted for a passphrase. This is important as it is used to protect your private SSH key. Make it something strong, like you would a password, and commit it to memory or write it down somewhere. Assuming that you accepted the default location above, your keys will be saved to ~/.ssh/id_ed25519 (private) and ~/.ssh/id_ed25519.pub (public). (OPTIONAL STEP) To avoid having to enter the passphrase every time you use your private key, continue to set up the ssh-agent as described in this tutorial . Register Client Keys with a Server \u00b6 In order to connect to a server using an SSH keypair, the server will need a copy of the public key to associate with a user account on the system. By default, each user will have a .ssh folder in their home directory. When a user attempts to log in via an SSH connection, the server will look for a file named ~/.ssh/authorized_keys containing a list of public keys. The client proceeds to authenticate itself by proving to the server that it is in possession of a matching private key. To use this feature on a Linux server, create the .ssh directory in your home directory (on the server). If you're already logged in, you can create the directory using mkdir -p ~/.ssh . After that is done, type exit to terminate the connection and return to your local command prompt. You are here!!! The following commands are run from your local shell. Running them inside of an existing SSH session will not have the effect you are looking for. With the directory in place, copy your public key (most likely ~/.ssh/id_ed25519.pub ) to the server using the scp command 2 scp $HOME /.ssh/id_ed25519.pub pi@raspberrypi.local:.ssh/authorized_keys By default, your SSH keys will be saved to ~/.ssh . If you are prompted to overwrite an existing key, you can cancel the process by typing n and pressing ++Enter++. \u21a9 The first parameter to scp specifies the name of the local file. The example is copying the public key named id_ed25519.pub from the current user's home directory. The second parameter to scp names the user ( pi ), the host ( raspberrypi.local ), and the remote destination for the file ( .ssh/authorized_keys ). Like ssh , scp is a user-based tool and will be executed relative to the home directory of the authenticated user ( /home/pi ). We can override the default by specifying an absolute path beginning with a / , e.g., /home/pi/.ssh/authorized_keys . \u21a9","title":"Getting Started with SSH"},{"location":"resources/ssh-primer/#getting-started-with-ssh","text":"SSH stands for 'Secure Shell'. A 'shell' is a command line interface, such as the one's you've seen in Terminal, PowerShell, or Git Bash. Throughout this course, you'll be using the shell, remotely, to configure Linux.","title":"Getting Started with SSH"},{"location":"resources/ssh-primer/#connecting-to-a-server","text":"The basic syntax for ssh is: ssh <USERNAME>@<HOST> For example, in order to connect to a new install of Raspberry Pi OS, enter ssh pi@raspberrypi.local . If successful, you should receive a message and prompt that you must respond to in order to continue: Unknown Host Prompt The authenticity of host 'raspberrypi.local (fe80::0f0e:0d0c:0b0a:0908%en9)' can't be established. ED25519 key fingerprint is SHA256:gy7+oAsjNc5gvP7aaR9k9Wl/oMdCLjAy2MJL8ZaQ9N0. This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? This message indicates that your local SSH client is attempting to authenticate the remote server. While SSH clients have the option to authenticate with a password, SSH servers are only able to authenticate themselves using keys. Since we've never connected to this server, the client is asking whether to trust the public key information that has been presented. If you accept, SSH will store a fingerprint locally and pull it up whenever you reach out to the same hostname or IP address. This mechanism is known as Trust on First Use (TOFU) . Type yes and press Enter to continue. If the server authenticates you successfully, it should return a login message and a prompt. If authentication fails, you should be prompted for a password or disconnected (if the user doesn't exist or password authentication is disabled). Successful connection with client certificates Warning: Permanently added 'raspberrypi.local' (ED25519) to the list of known hosts. Linux raspberrypi 5.10.103-v8+ #1530 SMP PREEMPT Tue Mar 8 13:06:35 GMT 2022 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Thu Mar 31 00:32:28 2022 from fe80::0102:0304:0506:0708%eth0 pi@raspberrypi:~ $","title":"Connecting to a Server"},{"location":"resources/ssh-primer/#create-ssh-client-keys","text":"When you are connecting to a remote server, you'll need a way to authenticate yourself and login to your server. While you can use a standard password, it is not a smart security practice. Rather, it's important to learn to generate and use a public keypair for SSH. A keypair is composed of a private key and a public key. Your public key can be given out, to say, GitHub or DigitalOcean, while your private key should never leave your device. OpenSSH is shipped with a utility called ssh-keygen that will generate a keypair for you. To create your SSH keypair, use ssh-keygen as follows: With either Terminal (for Mac) or PowerShell/Git Bash (for Windows) run the following command with your own email address: ssh-keygen -t ed25519 -C <DESCRIPTION> When prompted for a file name for the private SSH key. Accept the default by pressing ++Enter++. 1 You will be prompted for a passphrase. This is important as it is used to protect your private SSH key. Make it something strong, like you would a password, and commit it to memory or write it down somewhere. Assuming that you accepted the default location above, your keys will be saved to ~/.ssh/id_ed25519 (private) and ~/.ssh/id_ed25519.pub (public). (OPTIONAL STEP) To avoid having to enter the passphrase every time you use your private key, continue to set up the ssh-agent as described in this tutorial .","title":"Create SSH client keys"},{"location":"resources/ssh-primer/#register-client-keys-with-a-server","text":"In order to connect to a server using an SSH keypair, the server will need a copy of the public key to associate with a user account on the system. By default, each user will have a .ssh folder in their home directory. When a user attempts to log in via an SSH connection, the server will look for a file named ~/.ssh/authorized_keys containing a list of public keys. The client proceeds to authenticate itself by proving to the server that it is in possession of a matching private key. To use this feature on a Linux server, create the .ssh directory in your home directory (on the server). If you're already logged in, you can create the directory using mkdir -p ~/.ssh . After that is done, type exit to terminate the connection and return to your local command prompt. You are here!!! The following commands are run from your local shell. Running them inside of an existing SSH session will not have the effect you are looking for. With the directory in place, copy your public key (most likely ~/.ssh/id_ed25519.pub ) to the server using the scp command 2 scp $HOME /.ssh/id_ed25519.pub pi@raspberrypi.local:.ssh/authorized_keys By default, your SSH keys will be saved to ~/.ssh . If you are prompted to overwrite an existing key, you can cancel the process by typing n and pressing ++Enter++. \u21a9 The first parameter to scp specifies the name of the local file. The example is copying the public key named id_ed25519.pub from the current user's home directory. The second parameter to scp names the user ( pi ), the host ( raspberrypi.local ), and the remote destination for the file ( .ssh/authorized_keys ). Like ssh , scp is a user-based tool and will be executed relative to the home directory of the authenticated user ( /home/pi ). We can override the default by specifying an absolute path beginning with a / , e.g., /home/pi/.ssh/authorized_keys . \u21a9","title":"Register Client Keys with a Server"},{"location":"resources/tshark-install/","text":"Install TShark \u00b6 To perform captures from your pi you will need to install tshark (command line version of wireshark) using the apt command. When prompted to allow non-root users to run packet captures, say yes . After install, run sudo usermod -aG wireshark pi and reboot . This command is adding the pi user to the wireshark group. This group was created when you installed tshark and it is used to allow non-root users to run packet captures. After rebooting, test tshark by running tshark -i wlan0 and confirming that packets are captured. Type Ctrl + C to quit capturing. Info Use the command man tshark from the pi for more info about tshark and how to use it. Performing a Capture \u00b6 Tshark is a terminal based tool, but that doesn't mean you are limited to conducting all of your analysis on the commandline. Follow along below to explore two different approaches to get your tshark captures into wireshark for analysis. Capturing to a file \u00b6 The first approach we present is the easiest, but requires some manual effort to complete the capture and copy back to your computer with ssh/scp. Once the file is saved to your computer, you can open it in Wireshark and perform analysis just as you would with a native Wireshark capture. tshark allows you to specify the interface on which to capture using the -i argument as well as a filename to record the capture using -w . You may also pass a capture filter as the final argument of the command. # Capture DNS traffic from wlan0 and write the output into a file named cap.pcapng tshark -i wlan0 -w cap.pcapng 'port 53' Live Capture to Wireshark \u00b6 With a little more effort, Wireshark can leverage tshark for a remote capture. In this case, we are launching a capture with tshark and piping the results back through the SSH session into Wireshark (instead of saving to a file on the Pi). There is an ulterior motive for sharing this method. For some students, the live capture does provide a more natural workflow. However, this is a good opportunity to give you a small taste of what SSH can accomplish 1 . Windows users Add the wireshark program directory ( c:\\program files\\wireshark\\ ) to the system path and then use the standard command prompt rather than Powershell to launch the remote capture. The following command will launch a remote capture on your Pi (see additional notes for Windows below): ssh pi@titan.local tshark -s0 -F libpcap -i wlan0 -w - 'port 53' | wireshark -k -i - Live Wireshark captures are cool, but we've hardly scratched the surface of secure shell's super powers. \u21a9","title":"Install TShark"},{"location":"resources/tshark-install/#install-tshark","text":"To perform captures from your pi you will need to install tshark (command line version of wireshark) using the apt command. When prompted to allow non-root users to run packet captures, say yes . After install, run sudo usermod -aG wireshark pi and reboot . This command is adding the pi user to the wireshark group. This group was created when you installed tshark and it is used to allow non-root users to run packet captures. After rebooting, test tshark by running tshark -i wlan0 and confirming that packets are captured. Type Ctrl + C to quit capturing. Info Use the command man tshark from the pi for more info about tshark and how to use it.","title":"Install TShark"},{"location":"resources/tshark-install/#performing-a-capture","text":"Tshark is a terminal based tool, but that doesn't mean you are limited to conducting all of your analysis on the commandline. Follow along below to explore two different approaches to get your tshark captures into wireshark for analysis.","title":"Performing a Capture"},{"location":"resources/tshark-install/#capturing-to-a-file","text":"The first approach we present is the easiest, but requires some manual effort to complete the capture and copy back to your computer with ssh/scp. Once the file is saved to your computer, you can open it in Wireshark and perform analysis just as you would with a native Wireshark capture. tshark allows you to specify the interface on which to capture using the -i argument as well as a filename to record the capture using -w . You may also pass a capture filter as the final argument of the command. # Capture DNS traffic from wlan0 and write the output into a file named cap.pcapng tshark -i wlan0 -w cap.pcapng 'port 53'","title":"Capturing to a file"},{"location":"resources/tshark-install/#live-capture-to-wireshark","text":"With a little more effort, Wireshark can leverage tshark for a remote capture. In this case, we are launching a capture with tshark and piping the results back through the SSH session into Wireshark (instead of saving to a file on the Pi). There is an ulterior motive for sharing this method. For some students, the live capture does provide a more natural workflow. However, this is a good opportunity to give you a small taste of what SSH can accomplish 1 . Windows users Add the wireshark program directory ( c:\\program files\\wireshark\\ ) to the system path and then use the standard command prompt rather than Powershell to launch the remote capture. The following command will launch a remote capture on your Pi (see additional notes for Windows below): ssh pi@titan.local tshark -s0 -F libpcap -i wlan0 -w - 'port 53' | wireshark -k -i - Live Wireshark captures are cool, but we've hardly scratched the surface of secure shell's super powers. \u21a9","title":"Live Capture to Wireshark"},{"location":"resources/unifi-installation/","text":"Installing the UniFi Network Application \u00b6 UniFi-branded switches are managed devices from Ubiquiti that can be configured through a web-based management controller. Ubiquiti provides instructions to self-host the controller on Windows, macOS, and Linux. The current version of the controller will not run (without a lot of effort) on the 64-bit version of Raspberry Pi OS, so we recommend installing it on your laptop. Ubiquiti's installation instructions are fairly easy to follow, but we recommend that you follow the steps below. Download \u00b6 Download the current version of UniFi Network application from https://www.ui.com/download-software/ . To complete this step, you will need to scroll past the advertisement at the top of the page and click on the Download button for the UniFi Network software. Install \u00b6 Locate and launch the installer from your normal Downloads location. If you are on macOS and receive a warning, please read the following tip to proceed. macOS Security Warnings Recent versions of macOS have implemented software signature checks to help users distinguish potential malware from applications distributed from trusted sources. In order to avoid these warnings, software developers need to pay a fee to enroll in Apple's developer program and obtain code signing keys and certificates. Since Ubiquiti isn't signing this application with official signing keys, macOS does produce a stark warning upon launching the installer. Ubiquiti recommends that you change your settings to allow software from unidentified developers, but this isn't a great solution from a security perspective. Instead, you can bypass the warning by locating the installer in Finder and right-clicking to select the Open option. More information about software signatures and these warnings is available at https://support.apple.com/en-us/HT202491 . Proceed through the remaining installation steps with the default settings. Initial Setup \u00b6 Once you've completed the installation, the UniFi application should be visible in the Window's Start Menu or the macOS application folder. If you attempt to launch the application now, it will likely fail with an error. Install Java 8 \u00b6 The UniFi Network application requires Java 8 to launch. While Oracle still maintains Java 8, this is an older version and unlikely to be installed on your system. If you saw an error when launching the UniFi application, download the installer from the Java website and follow the provided instructions to complete this step. Create a Ubiquiti Account \u00b6 The UniFi network application is a web-based application that is intended to be accessed through the browser over the network. Even when running the application locally, a login is required. By default, the application integrates with web-based Ubiquiti accounts. Using the advanced set up process, it is possible to avoid this requirement, though we recommend sticking with the default for simplicity. Create a Ubiquiti account now at https://account.ui.com using a valid email address, and follow the instructions to verify the email address you gave and activate your account. Launching the Application \u00b6 If you haven't already, launch the UniFi application from the Window's start menu or the macOS Applications folder. The software will launch a small window, that is used to inform you of the web server's current status and provide a local link you can use to launch the management interface in a browser. When the server is ready, you should see a green check mark in the status window. Click on the button labeled Launch a Browser to Manage the Network and switch to the new browser window to proceed with setup. Creating the Network \u00b6 You will need to name your network and agree to the UniFi service terms. You can accept the default or enter an alternate name, e.g., info314. Click Next to continue and proceed by logging in with your Ubiquiti web credentials. If you decided to use local credentials instead, click Switch to Advanced Setup . You may accept the default settings on Step 3 and click next to continue. If your computer is currently connected to the switch and both devices are able to receive a DHCP address, you'll be given the option to adopt the device in Step 4. You may do this now or just click the Next button and come back to it later. Since we won't be managing any UniFi wireless access points with this instance of the controller, click Skip on Step 5 to continue to the final step. Click Finish on step 6 to complete the configuration process. Uninstalling the UniFi Network Application \u00b6 After the course, you may wish to remove this software from your computer. To uninstall the Network Application, review the instructions in the following help article . You will likely want to remove Java as well. The official website provides instructions for macOS and Windows .","title":"Getting Started with the UniFi Network Application"},{"location":"resources/unifi-installation/#installing-the-unifi-network-application","text":"UniFi-branded switches are managed devices from Ubiquiti that can be configured through a web-based management controller. Ubiquiti provides instructions to self-host the controller on Windows, macOS, and Linux. The current version of the controller will not run (without a lot of effort) on the 64-bit version of Raspberry Pi OS, so we recommend installing it on your laptop. Ubiquiti's installation instructions are fairly easy to follow, but we recommend that you follow the steps below.","title":"Installing the UniFi Network Application"},{"location":"resources/unifi-installation/#download","text":"Download the current version of UniFi Network application from https://www.ui.com/download-software/ . To complete this step, you will need to scroll past the advertisement at the top of the page and click on the Download button for the UniFi Network software.","title":"Download"},{"location":"resources/unifi-installation/#install","text":"Locate and launch the installer from your normal Downloads location. If you are on macOS and receive a warning, please read the following tip to proceed. macOS Security Warnings Recent versions of macOS have implemented software signature checks to help users distinguish potential malware from applications distributed from trusted sources. In order to avoid these warnings, software developers need to pay a fee to enroll in Apple's developer program and obtain code signing keys and certificates. Since Ubiquiti isn't signing this application with official signing keys, macOS does produce a stark warning upon launching the installer. Ubiquiti recommends that you change your settings to allow software from unidentified developers, but this isn't a great solution from a security perspective. Instead, you can bypass the warning by locating the installer in Finder and right-clicking to select the Open option. More information about software signatures and these warnings is available at https://support.apple.com/en-us/HT202491 . Proceed through the remaining installation steps with the default settings.","title":"Install"},{"location":"resources/unifi-installation/#initial-setup","text":"Once you've completed the installation, the UniFi application should be visible in the Window's Start Menu or the macOS application folder. If you attempt to launch the application now, it will likely fail with an error.","title":"Initial Setup"},{"location":"resources/unifi-installation/#install-java-8","text":"The UniFi Network application requires Java 8 to launch. While Oracle still maintains Java 8, this is an older version and unlikely to be installed on your system. If you saw an error when launching the UniFi application, download the installer from the Java website and follow the provided instructions to complete this step.","title":"Install Java 8"},{"location":"resources/unifi-installation/#create-a-ubiquiti-account","text":"The UniFi network application is a web-based application that is intended to be accessed through the browser over the network. Even when running the application locally, a login is required. By default, the application integrates with web-based Ubiquiti accounts. Using the advanced set up process, it is possible to avoid this requirement, though we recommend sticking with the default for simplicity. Create a Ubiquiti account now at https://account.ui.com using a valid email address, and follow the instructions to verify the email address you gave and activate your account.","title":"Create a Ubiquiti Account"},{"location":"resources/unifi-installation/#launching-the-application","text":"If you haven't already, launch the UniFi application from the Window's start menu or the macOS Applications folder. The software will launch a small window, that is used to inform you of the web server's current status and provide a local link you can use to launch the management interface in a browser. When the server is ready, you should see a green check mark in the status window. Click on the button labeled Launch a Browser to Manage the Network and switch to the new browser window to proceed with setup.","title":"Launching the Application"},{"location":"resources/unifi-installation/#creating-the-network","text":"You will need to name your network and agree to the UniFi service terms. You can accept the default or enter an alternate name, e.g., info314. Click Next to continue and proceed by logging in with your Ubiquiti web credentials. If you decided to use local credentials instead, click Switch to Advanced Setup . You may accept the default settings on Step 3 and click next to continue. If your computer is currently connected to the switch and both devices are able to receive a DHCP address, you'll be given the option to adopt the device in Step 4. You may do this now or just click the Next button and come back to it later. Since we won't be managing any UniFi wireless access points with this instance of the controller, click Skip on Step 5 to continue to the final step. Click Finish on step 6 to complete the configuration process.","title":"Creating the Network"},{"location":"resources/unifi-installation/#uninstalling-the-unifi-network-application","text":"After the course, you may wish to remove this software from your computer. To uninstall the Network Application, review the instructions in the following help article . You will likely want to remove Java as well. The official website provides instructions for macOS and Windows .","title":"Uninstalling the UniFi Network Application"},{"location":"resources/uw-wireless/","text":"University of Washington Wireless Networks Reference (2022-03-29) \u00b6 Overview \u00b6 The University of Washington offers three wireless SSIDs to support the networking needs of students, staff, and faculty. These networks serve slightly different purposes with each one employing a distinct security configuration to ensure that Internet access is restricted to current students, staff, and faculty. The University of Washington SSID is an open network that employs a captive portal . In order to access any site outside of the UW network, you must authenticate your session using your NetID username and password. Since a browser is needed at the time you connect, this is not an ideal solution for a headless network device. The eduroam SSID is an encrypted, WPA2 Enterprise network that requires new device onboarding before making a connection. The UW MPSK network is an encrypted WPA2 Personal network, much like the one you might use at home, except that an online onboarding step (described in the next section) is required for each device you want to connect. Additional information about these networks is available at https://itconnect.uw.edu/connect/uw-networks/campus-wi-fi/ . UW MPSK Network Onboarding \u00b6 The UW MPSK network is a good fit for gaming consoles and IoT devices that operate without a screen and keyboard. To connect to his network, you will need to register through the UW IT website and obtain a passphrase (which is unique to each device). In order to complete these instructions, you will need the following information: Your NetID and Password The MAC address of the device you want to register 1 http://register.wifi.uw.edu/guest/mac_create.php Eduroam Onboarding \u00b6 In prior years, access to eduroam relied on username/password authentication through the University's NetID system. Authentication was performed by the wireless client -- wpa_supplicant in our case -- when connecting to the system. If a user had a valid NetID, no prior registration was needed. As of February 2022, the university quit accepting NetID based connections and began requiring all wireless clients to be registered and set up ahead of time with a client certificate. UW provides a portal and tools that automate most of this process for mainstream desktop systems; however, those tools aren't compatible Raspberry Pi OS. The following instructions will guide you through connecting to the onboarding portal, registering your device, downloading your client identity certificates, and installing these credentials onto your Raspberry Pi. In order to complete these instructions, you will need to gather the following information: Your NetID and Password The MAC address of the device you want to register 1 A passphrase that will be used to encrypt your new certificates. Register and Download Identity Certificates \u00b6 From your workstation, open a browser and navigate to http://onboard.wifi.uw.edu/ . You will be directed to a page that instructs you to Click to configure eduroam and identifies your current device. Do not click on the Sign In button immediately. Before you do so, you will need to select an alternate device type at the bottom of this screen. Select User-Defined from this drop-down list and then proceed to Sign In to be directed to the UW single sign on page. After successfully logging in, you will be presented with a form that can be used to generate a new certificate. Fill out the requested details, entering a description of the device you\u2019re connecting, such as \"Raspberry Pi\" or \"INFO314 Pi\" , and then carefully typing or pasting your MAC address into the field labeled MAC Address . After you press the \u201cCreate\u201d button, you will be prompted to enter a passphrase. The text you enter here will be used to encrypt your new certificate and its private key. You will need to use this passphrase again later. On the following screen, click on the link labeled P12 to download a file containing your certificate and private key. Take note of the P12 filename before proceeding. On the final screen, record a copy of the settings displayed in the section that says Please use the following settings to configure your device . You will need these values to complete the wpa_supplicant network configuration. . Before you leave this page, click on the link for the CA Certificate in order to download a copy of to your computer. 2 Take note of this filename as well. Install certificates to your device \u00b6 Before configuring wpa_supplicant, we will need to convert the files downloaded during onboarding into a format supported by the software, and install them into an appropriate location. The client certificate and private key (credentials that are used to identify you to the network) are stored in a passphrase encrypted PKCS#12 file. This is the first file that you downloaded from the P12 link. Copy the files you downloaded in the previous step into the home directory of your Pi. Extract the client certificate and the private key into separate PEM files using the openssl command-line utility. 3 4 # Extract the client certificate and convert to PEM openssl pkcs12 -in \"<P12_FILENAME>\" -out <NETID>_cert.pem -clcerts -nokeys # Extract the private key and convert to PEM openssl pkcs12 -in \"<P12_FILENAME>\" -out <NETID>_key.pem -nodes You should now have two new pem files in your home directory. Move these files along with certificate authority into /etc/wpa_supplicant/ and make a note of their names. Info No conversion is necessary for the certificate authority. The file that you downloaded is already in the PEM format. Before you wrap up, update the ownership and permissions of the certificate files to further protect them. This is particularly important for <NETID>_key.pem , which now contains an unencrypted copy of your certificate's private key. sudo chown root:root /etc/wpa_supplicant/*.pem sudo chmod 600 /etc/wpa_supplicant/*.pem Cleanup \u00b6 Retain a copy of the certificates and configuration information in case you need to repeat this process later. You will also need the passphrase in order to decrypt the p12 file. Store this value in a safe place. For now, you may leave the downloads in the home directory of your pi so that they are available if you need to troubleshoot this process. Once your connection to the eduroam network is verified, you can safely remove both files. You can look up MAC addresses on your pi using the ip link command. Your device will display a different MAC address (labeled link/ether ) for each network interface. Register the address associated with the wireless interface -- wlan0 by default. \u21a9 \u21a9 The Certificate Authority (CA) certificate is a public credential that your device uses to verify that you are speaking to a legitimate server. \u21a9 All caps text enclosed in angle brackets are placeholders. Fill in these values before running the code. \u21a9 You will be prompted for your passphrase in order to convert the file. \u21a9","title":"UW Wireless Network Reference"},{"location":"resources/uw-wireless/#university-of-washington-wireless-networks-reference-2022-03-29","text":"","title":"University of Washington Wireless Networks Reference (2022-03-29)"},{"location":"resources/uw-wireless/#overview","text":"The University of Washington offers three wireless SSIDs to support the networking needs of students, staff, and faculty. These networks serve slightly different purposes with each one employing a distinct security configuration to ensure that Internet access is restricted to current students, staff, and faculty. The University of Washington SSID is an open network that employs a captive portal . In order to access any site outside of the UW network, you must authenticate your session using your NetID username and password. Since a browser is needed at the time you connect, this is not an ideal solution for a headless network device. The eduroam SSID is an encrypted, WPA2 Enterprise network that requires new device onboarding before making a connection. The UW MPSK network is an encrypted WPA2 Personal network, much like the one you might use at home, except that an online onboarding step (described in the next section) is required for each device you want to connect. Additional information about these networks is available at https://itconnect.uw.edu/connect/uw-networks/campus-wi-fi/ .","title":"Overview"},{"location":"resources/uw-wireless/#uw-mpsk-network-onboarding","text":"The UW MPSK network is a good fit for gaming consoles and IoT devices that operate without a screen and keyboard. To connect to his network, you will need to register through the UW IT website and obtain a passphrase (which is unique to each device). In order to complete these instructions, you will need the following information: Your NetID and Password The MAC address of the device you want to register 1 http://register.wifi.uw.edu/guest/mac_create.php","title":"UW MPSK Network Onboarding"},{"location":"resources/uw-wireless/#eduroam-onboarding","text":"In prior years, access to eduroam relied on username/password authentication through the University's NetID system. Authentication was performed by the wireless client -- wpa_supplicant in our case -- when connecting to the system. If a user had a valid NetID, no prior registration was needed. As of February 2022, the university quit accepting NetID based connections and began requiring all wireless clients to be registered and set up ahead of time with a client certificate. UW provides a portal and tools that automate most of this process for mainstream desktop systems; however, those tools aren't compatible Raspberry Pi OS. The following instructions will guide you through connecting to the onboarding portal, registering your device, downloading your client identity certificates, and installing these credentials onto your Raspberry Pi. In order to complete these instructions, you will need to gather the following information: Your NetID and Password The MAC address of the device you want to register 1 A passphrase that will be used to encrypt your new certificates.","title":"Eduroam Onboarding"},{"location":"resources/uw-wireless/#register-and-download-identity-certificates","text":"From your workstation, open a browser and navigate to http://onboard.wifi.uw.edu/ . You will be directed to a page that instructs you to Click to configure eduroam and identifies your current device. Do not click on the Sign In button immediately. Before you do so, you will need to select an alternate device type at the bottom of this screen. Select User-Defined from this drop-down list and then proceed to Sign In to be directed to the UW single sign on page. After successfully logging in, you will be presented with a form that can be used to generate a new certificate. Fill out the requested details, entering a description of the device you\u2019re connecting, such as \"Raspberry Pi\" or \"INFO314 Pi\" , and then carefully typing or pasting your MAC address into the field labeled MAC Address . After you press the \u201cCreate\u201d button, you will be prompted to enter a passphrase. The text you enter here will be used to encrypt your new certificate and its private key. You will need to use this passphrase again later. On the following screen, click on the link labeled P12 to download a file containing your certificate and private key. Take note of the P12 filename before proceeding. On the final screen, record a copy of the settings displayed in the section that says Please use the following settings to configure your device . You will need these values to complete the wpa_supplicant network configuration. . Before you leave this page, click on the link for the CA Certificate in order to download a copy of to your computer. 2 Take note of this filename as well.","title":"Register and Download Identity Certificates"},{"location":"resources/uw-wireless/#install-certificates-to-your-device","text":"Before configuring wpa_supplicant, we will need to convert the files downloaded during onboarding into a format supported by the software, and install them into an appropriate location. The client certificate and private key (credentials that are used to identify you to the network) are stored in a passphrase encrypted PKCS#12 file. This is the first file that you downloaded from the P12 link. Copy the files you downloaded in the previous step into the home directory of your Pi. Extract the client certificate and the private key into separate PEM files using the openssl command-line utility. 3 4 # Extract the client certificate and convert to PEM openssl pkcs12 -in \"<P12_FILENAME>\" -out <NETID>_cert.pem -clcerts -nokeys # Extract the private key and convert to PEM openssl pkcs12 -in \"<P12_FILENAME>\" -out <NETID>_key.pem -nodes You should now have two new pem files in your home directory. Move these files along with certificate authority into /etc/wpa_supplicant/ and make a note of their names. Info No conversion is necessary for the certificate authority. The file that you downloaded is already in the PEM format. Before you wrap up, update the ownership and permissions of the certificate files to further protect them. This is particularly important for <NETID>_key.pem , which now contains an unencrypted copy of your certificate's private key. sudo chown root:root /etc/wpa_supplicant/*.pem sudo chmod 600 /etc/wpa_supplicant/*.pem","title":"Install certificates to your device"},{"location":"resources/uw-wireless/#cleanup","text":"Retain a copy of the certificates and configuration information in case you need to repeat this process later. You will also need the passphrase in order to decrypt the p12 file. Store this value in a safe place. For now, you may leave the downloads in the home directory of your pi so that they are available if you need to troubleshoot this process. Once your connection to the eduroam network is verified, you can safely remove both files. You can look up MAC addresses on your pi using the ip link command. Your device will display a different MAC address (labeled link/ether ) for each network interface. Register the address associated with the wireless interface -- wlan0 by default. \u21a9 \u21a9 The Certificate Authority (CA) certificate is a public credential that your device uses to verify that you are speaking to a legitimate server. \u21a9 All caps text enclosed in angle brackets are placeholders. Fill in these values before running the code. \u21a9 You will be prompted for your passphrase in order to convert the file. \u21a9","title":"Cleanup"},{"location":"resources/vlan-interfaces/","text":"Configuring VLANs in systemd-networkd (last edited 2022-05-20) \u00b6 The Linux network stack provides full support for 802.1Q VLANs, including the ability to virtualize broadcast domains based on tagged network traffic. Sending and receiving tagged traffic is supported through the use of virtual network devices that can be configured and utilized by software in many of the same ways as physical network devices like eth0 . Creating VLAN Interfaces \u00b6 systemd-networkd provides support for creating and configuring virtual network devices, including VLAN interfaces. These devices are configured in .netdev files added to the standard networkd configuration locations. The .netdev definition for a VLAN interface defines the following properties: Name - User-defined name for the network interface Kind - vlan Id - Integer VLAN ID between 0 and 4094 Creating a VLAN interface /etc/systemd/network/15-vlan25.netdev [NetDev] Name=vlan25 Kind=vlan [VLAN] # Specify the tag Id=25 Add VLANs to a Physical Interface \u00b6 In order to send and receive tagged traffic over a physical network link, virtual network devices are associated with the physical LAN interface. In systemd-networkd , this association can be made by specifying one or more VLAN properties to the physical interface's .network configuration. Associating a VLAN to a physical interface /etc/systemd/network/20-eth0.network [Match] Name = eth0 [Network] Address = 192.168.0.1/24 # (1) VLAN = vlan25 # (2) VLAN = vlan50 Addresses and other configuration are associated with native (untagged) traffic on the device. Each VLAN is associated based on the name of the virtual network device. After associating a VLAN device to a phyical interface, tagged frames will be presented to the operating system as originating from the VLAN interface. Likewise, traffic that is sent through a VLAN interface will be tagged with the specified ID before being sent on the network. Layer-3 Configuration for VLAN Interfaces \u00b6 Attaching the VLANs to a physical interface enables traffic to be sent and received from the virtual interface via tagged frames on the physical link. At the moment, however, our VLAN interfaces do not have any network-level settings attached to them. Depending on the task at hand and the configuration of the Linux host, you may configure the new interfaces by any method(s) available, including networkd: Sample Network Configurations IPv4 DHCP IPv4 Static Link-local IPv6 only /etc/systemd/network/25-vlan25.network [Match] Name = vlan25 [Network] DHCP = ipv4 /etc/systemd/network/25-vlan25.network [Match] Name = vlan25 [Network] Address = 172.16.0.1/24 DNS = 1.1.1.1 /etc/systemd/network/25-vlan25.network [Match] Name = vlan25 [Network] LinkLocalAddressing = ipv6 IPv6AcceptRA = yes IPv6PrivacyExtensions = no","title":"VLAN Interfaces"},{"location":"resources/vlan-interfaces/#configuring-vlans-in-systemd-networkd-last-edited-2022-05-20","text":"The Linux network stack provides full support for 802.1Q VLANs, including the ability to virtualize broadcast domains based on tagged network traffic. Sending and receiving tagged traffic is supported through the use of virtual network devices that can be configured and utilized by software in many of the same ways as physical network devices like eth0 .","title":"Configuring VLANs in systemd-networkd (last edited 2022-05-20)"},{"location":"resources/vlan-interfaces/#creating-vlan-interfaces","text":"systemd-networkd provides support for creating and configuring virtual network devices, including VLAN interfaces. These devices are configured in .netdev files added to the standard networkd configuration locations. The .netdev definition for a VLAN interface defines the following properties: Name - User-defined name for the network interface Kind - vlan Id - Integer VLAN ID between 0 and 4094 Creating a VLAN interface /etc/systemd/network/15-vlan25.netdev [NetDev] Name=vlan25 Kind=vlan [VLAN] # Specify the tag Id=25","title":"Creating VLAN Interfaces"},{"location":"resources/vlan-interfaces/#add-vlans-to-a-physical-interface","text":"In order to send and receive tagged traffic over a physical network link, virtual network devices are associated with the physical LAN interface. In systemd-networkd , this association can be made by specifying one or more VLAN properties to the physical interface's .network configuration. Associating a VLAN to a physical interface /etc/systemd/network/20-eth0.network [Match] Name = eth0 [Network] Address = 192.168.0.1/24 # (1) VLAN = vlan25 # (2) VLAN = vlan50 Addresses and other configuration are associated with native (untagged) traffic on the device. Each VLAN is associated based on the name of the virtual network device. After associating a VLAN device to a phyical interface, tagged frames will be presented to the operating system as originating from the VLAN interface. Likewise, traffic that is sent through a VLAN interface will be tagged with the specified ID before being sent on the network.","title":"Add VLANs to a Physical Interface"},{"location":"resources/vlan-interfaces/#layer-3-configuration-for-vlan-interfaces","text":"Attaching the VLANs to a physical interface enables traffic to be sent and received from the virtual interface via tagged frames on the physical link. At the moment, however, our VLAN interfaces do not have any network-level settings attached to them. Depending on the task at hand and the configuration of the Linux host, you may configure the new interfaces by any method(s) available, including networkd: Sample Network Configurations IPv4 DHCP IPv4 Static Link-local IPv6 only /etc/systemd/network/25-vlan25.network [Match] Name = vlan25 [Network] DHCP = ipv4 /etc/systemd/network/25-vlan25.network [Match] Name = vlan25 [Network] Address = 172.16.0.1/24 DNS = 1.1.1.1 /etc/systemd/network/25-vlan25.network [Match] Name = vlan25 [Network] LinkLocalAddressing = ipv6 IPv6AcceptRA = yes IPv6PrivacyExtensions = no","title":"Layer-3 Configuration for VLAN Interfaces"},{"location":"resources/wifi-reference/","text":"WPA Supplicant Configuration Reference (2022-03-29) \u00b6 Basic Configuration \u00b6 Wireless settings for the Pi are controlled by a service called wpa_supplicant , which stores information about known wireless networks in a text-based configuration file in /etc/wpa_supplicant/ . By default, in Raspberry Pi OS, the name of this file is wpa_supplicant.conf . You may also encounter an interface-specific configuration where the interface name is appended to the file, e.g., wpa_supplicant-wlan0.conf . In both cases, the file is owned by root and requires root privileges to read or edit. To learn more about wpa_supplicant , run the command ` Security Risk wpa_supplicant.conf is protected from casual reading due to the fact that it is a sensitive file that might contain the password to your home network or even the password for your school/work account. Practice caution with this file: Never share the contents of this file directly online. Scrub passwords, keys, and hashes before committing a copy into a repository . Reset passwords if you lose your Pi or suspect that you may have disclosed it inadvertently. You can edit wpa_supplicant configs directly on the Pi using any terminal-based text editor. Alternatively, you can create the file on your local system and copy it into place on the Pi (as described later in this guide). Warning: Windows line-endings and rich text format As students get started with Linux networking, we frequently encounter problems related to the overall file format. As a rule, the configuration files you create in this class must be plain text with standard line endings. You'll want to stick to using a code-oriented text editor, as opposed to options like macOS TextEdit and Windows Notepad that often save files as rich text rather than plain text. For Windows users, a code-oriented editor will also help you avoid issues related to line endings. While most operating systems use a simple New Line (aka Line Feed) control character to signify the end of a line, most Windows tools also include a Carriage Return . This alternate line ending causes parsing errors in many Linux tools. The general structure of the configuration file is show below. The file begins with a standard set of parameters specifying the country (needed to initialize appropriate radio settings), a control interface used by network management tools, and a boolean that instructs wpa_supplicant to accept configuration updates from other network management tools. We won't delve any deeper into the meaning of these initial parameters for now. Rather, our concern will be how to configure Linux to join nearby wireless networks. Example wpa_supplicant.conf country=US ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\"Some public network\" key_mgmt=NONE } network={ ssid=\"My home network\" psk=\"Don't tell anyone the password\" } Each network is represented by a configuration block that surrounded by network={...} . The contents of the network block will depend largely on the security settings of the network, e.g., whether or not the network is encrypted with a passphrase. This document provides instructions for configuring three common types of networks: Unencrypted Networks WPA2 Personal Networks (simple passphrase) WPA2 Enterprise Networks Let's start by examining the configuration for an unencrypted network. Unencrypted Networks \u00b6 All networks are defined by parameter=value pairs enclosed within network={} . Regardless of security configuration, each network block is required to contain an ssid parameter identifying the network. The service set identifier (SSID) is the network name that you see on your device when you connect to a wireless network. Since this name may include whitespace, we encapsulate it in double quotes. In addition to the ssid , wpa_supplicant expects us to provide encryption a passphrase and other encryption settings for the wireless network. Omitting these settings, even for an unencrypted network, will result in errors. Instead, for unencrypted networks, we explicitly disable encryption with key_mgmt=NONE . Configuration for an unencrypted network network={ ssid=\"Coffee Shop\" key_mgmt=NONE } WPA2 Personal Networks \u00b6 For a basic (non-enterprise) encrypted network, the configuration of the network block changes only slightly. Rather than specify the key_mgmt setting, we assign the network passphrase to the psk parameter. There are two ways to accomplish this task. First, we can assign the passphrase directly to the parameter in plaintext as shown here: Danger: Don't do this!!! network={ ssid=\"Home Wifi\" psk=\"super secret squirrels\" } Security professionals generally frown on plaintext passwords and passphrases being written to configuration files or code. As such, we prefer to write the configuration based on the raw network key (computed using a function called PBKDF in conjunction with SHA1 ). Using wpa_passphrase to generate a raw PSK You can generate the raw psk directly on your Pi by running the wpa_passphrase utility. This utility takes your SSID as an argument and then prompts you to enter your passphrase. # Pass your SSID as the first argument wpa_passphrase \"Home Wifi\" You will not see any characters or placeholders echoed as you type the passphrase, but wpa_passphrase will continue to accept input until you hit Enter/Return . The output will be a valid wpa_supplicant configuration that you can paste into your configuration. network={ ssid=\"Home Wifi\" psk=2508539ff867a3578f6ba7d9ee1d4a62aea82c25d30ffb1eb3a05cd08a373c02 } WPA2 Enterprise Networks \u00b6 Unlike home and coffee shop networks, enterprise networks like eduroam , require a bit more setup since they authenticate individual users to the network as part of the process of establishing an encrypted connection. As such, these networks can provide substantially more security than networks that are protected by WPA2 Personal . They're also much more flexible. For example, once you have properly configured eduroam to connect on your campus, you will also be able to get online at other schools offering eduroam hotspots. Certificate-based Authentication \u00b6 Enterprise networks utilizing certificate-based authentication rely on EAP-TLS mode of operation. Public key authentication has many security benefits over password-based mechanisms, though the process of onboarding new users and devices is more complex. Users on these networks are required to register or enroll in order to obtain a client identity certificate. Before you attempt to add an EAP-TLS network to wpa_supplicant, you must complete the onboarding process and install certificates onto your device. For University of Washington students, faculty, and staff, we have documented onboarding and certificate installation in separately (click here) . Eduroam configuration template (EAP-TLS) The majority of the values needed for this template will be provided by your organization during onboarding. For , your organization most likely supports CCMP , which is a mode of AES encryption. If you're unsure, enter CCMP TKIP to allow for legacy encryption support (not recommended). All path names will be dependent on the installation location for your certificates. network={ priority=10 ssid=\"eduroam\" scan_ssid=1 key_mgmt=WPA-EAP proto=RSN pairwise=<ENCRYPTION_MODES> group=<ENCRYPTION_MODES> eap=TLS identity=\"<IDENTITY>\" anonymous_identity=\"<ANONYMOUS_IDENTITY>\" ca_cert=\"</PATH/TO/CA_CERT.PEM>\" client_cert=\"</PATH/TO/CLIENT_CERT.PEM>\" private_key=\"</PATH/TO/PRIVATE_KEY.PEM>\" domain_match=\"<DOMAIN>\" phase2=\"auth=<INNER_EAP_TYPE>\" } Password-based Authentication \u00b6 Password-based authentication can be set up for an enterprise wireless network by leveraging the Protected Extensible Authentication Protocol (PEAP) and the Microsoft Challenge Authentication Protocol version 2 (MSCHAPv2) to authenticate network clients based on a previously registered username and passphrase. The following template configures wpa_supplicant for PEAP/MSCHAPv2 authentication on an Eduroam network. Add it to your wpa_supplicant.conf , substituting your own username and password hash for the supplied values. Avoid Credential Exposure If implemented poorly, PEAP can expose your password to a malicious network operator. To prevent attacks, include the Certificate Authority (CA) certificate 1 in your wpa_supplicant configuration. Without this information, the wireless client may send password information to an evil twin (malicious network posing as one you trust). Likewise, we advise against hard-coding your plaintext school or work password into the wireless configuration file. Instead, compute an MD4 hash from your password and substitute it for the password. MD4 is a weak hash and fairly vulnerable to password cracking, but combined with a strong password, it does provide a layer of protection if your device is lost or stolen. Follow these commands in order to compute the MD4 hash in Linux. The history commands are not needed to compute a hash but are added for security. Without them, your password will be stored in the Bash history file and easily readable to anyone with access to your memory card. set +o history echo -n 'This is your password' | iconv -t utf16le | openssl md4 # You should see output like 6f9bad2c90b80bd549e595fc91e27806 set -o history Eduroam configuration template (EAP-PEAP) This configuration is no longer supported on University of Washington's eduroam network (effective Feb 1, 2022). network={ ssid=\"eduroam\" scan_ssid=1 key_mgmt=WPA-EAP proto=RSN eap=PEAP identity=\"<USERNAME>@<ORGANIZATION_DOMAIN>\" password=hash:6f9bad2c90b80bd549e595fc91e27806 ca_cert=\"</PATH/TO/CA_CERT.PEM>\" phase1=\"peaplabel=0\" phase2=\"auth=MSCHAPV2\" } Applying Configuration Changes \u00b6 Like other services, wpa_supplicant will not load our changes automatically. Rather than reset the daemon completely using systemctl , we can use wpa_cli to update the configuration and perform other basic maintenance. When running wpa_cli we need to specify the interface we are configuring and a command to send to the wpa_supplicant service. Load configuration from wpa_supplicant.conf # Update configuration from disk wpa_cli -i wlan0 reconfigure # Check the status of current connection wpa_cli -i wlan0 status See man wpa_cli for further instructions and examples. Obtain this file from your organization's IT department. \u21a9","title":"wpa_supplicant Reference"},{"location":"resources/wifi-reference/#wpa-supplicant-configuration-reference-2022-03-29","text":"","title":"WPA Supplicant Configuration Reference (2022-03-29)"},{"location":"resources/wifi-reference/#basic-configuration","text":"Wireless settings for the Pi are controlled by a service called wpa_supplicant , which stores information about known wireless networks in a text-based configuration file in /etc/wpa_supplicant/ . By default, in Raspberry Pi OS, the name of this file is wpa_supplicant.conf . You may also encounter an interface-specific configuration where the interface name is appended to the file, e.g., wpa_supplicant-wlan0.conf . In both cases, the file is owned by root and requires root privileges to read or edit. To learn more about wpa_supplicant , run the command ` Security Risk wpa_supplicant.conf is protected from casual reading due to the fact that it is a sensitive file that might contain the password to your home network or even the password for your school/work account. Practice caution with this file: Never share the contents of this file directly online. Scrub passwords, keys, and hashes before committing a copy into a repository . Reset passwords if you lose your Pi or suspect that you may have disclosed it inadvertently. You can edit wpa_supplicant configs directly on the Pi using any terminal-based text editor. Alternatively, you can create the file on your local system and copy it into place on the Pi (as described later in this guide). Warning: Windows line-endings and rich text format As students get started with Linux networking, we frequently encounter problems related to the overall file format. As a rule, the configuration files you create in this class must be plain text with standard line endings. You'll want to stick to using a code-oriented text editor, as opposed to options like macOS TextEdit and Windows Notepad that often save files as rich text rather than plain text. For Windows users, a code-oriented editor will also help you avoid issues related to line endings. While most operating systems use a simple New Line (aka Line Feed) control character to signify the end of a line, most Windows tools also include a Carriage Return . This alternate line ending causes parsing errors in many Linux tools. The general structure of the configuration file is show below. The file begins with a standard set of parameters specifying the country (needed to initialize appropriate radio settings), a control interface used by network management tools, and a boolean that instructs wpa_supplicant to accept configuration updates from other network management tools. We won't delve any deeper into the meaning of these initial parameters for now. Rather, our concern will be how to configure Linux to join nearby wireless networks. Example wpa_supplicant.conf country=US ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\"Some public network\" key_mgmt=NONE } network={ ssid=\"My home network\" psk=\"Don't tell anyone the password\" } Each network is represented by a configuration block that surrounded by network={...} . The contents of the network block will depend largely on the security settings of the network, e.g., whether or not the network is encrypted with a passphrase. This document provides instructions for configuring three common types of networks: Unencrypted Networks WPA2 Personal Networks (simple passphrase) WPA2 Enterprise Networks Let's start by examining the configuration for an unencrypted network.","title":"Basic Configuration"},{"location":"resources/wifi-reference/#unencrypted-networks","text":"All networks are defined by parameter=value pairs enclosed within network={} . Regardless of security configuration, each network block is required to contain an ssid parameter identifying the network. The service set identifier (SSID) is the network name that you see on your device when you connect to a wireless network. Since this name may include whitespace, we encapsulate it in double quotes. In addition to the ssid , wpa_supplicant expects us to provide encryption a passphrase and other encryption settings for the wireless network. Omitting these settings, even for an unencrypted network, will result in errors. Instead, for unencrypted networks, we explicitly disable encryption with key_mgmt=NONE . Configuration for an unencrypted network network={ ssid=\"Coffee Shop\" key_mgmt=NONE }","title":"Unencrypted Networks"},{"location":"resources/wifi-reference/#wpa2-personal-networks","text":"For a basic (non-enterprise) encrypted network, the configuration of the network block changes only slightly. Rather than specify the key_mgmt setting, we assign the network passphrase to the psk parameter. There are two ways to accomplish this task. First, we can assign the passphrase directly to the parameter in plaintext as shown here: Danger: Don't do this!!! network={ ssid=\"Home Wifi\" psk=\"super secret squirrels\" } Security professionals generally frown on plaintext passwords and passphrases being written to configuration files or code. As such, we prefer to write the configuration based on the raw network key (computed using a function called PBKDF in conjunction with SHA1 ). Using wpa_passphrase to generate a raw PSK You can generate the raw psk directly on your Pi by running the wpa_passphrase utility. This utility takes your SSID as an argument and then prompts you to enter your passphrase. # Pass your SSID as the first argument wpa_passphrase \"Home Wifi\" You will not see any characters or placeholders echoed as you type the passphrase, but wpa_passphrase will continue to accept input until you hit Enter/Return . The output will be a valid wpa_supplicant configuration that you can paste into your configuration. network={ ssid=\"Home Wifi\" psk=2508539ff867a3578f6ba7d9ee1d4a62aea82c25d30ffb1eb3a05cd08a373c02 }","title":"WPA2 Personal Networks"},{"location":"resources/wifi-reference/#wpa2-enterprise-networks","text":"Unlike home and coffee shop networks, enterprise networks like eduroam , require a bit more setup since they authenticate individual users to the network as part of the process of establishing an encrypted connection. As such, these networks can provide substantially more security than networks that are protected by WPA2 Personal . They're also much more flexible. For example, once you have properly configured eduroam to connect on your campus, you will also be able to get online at other schools offering eduroam hotspots.","title":"WPA2 Enterprise Networks"},{"location":"resources/wifi-reference/#certificate-based-authentication","text":"Enterprise networks utilizing certificate-based authentication rely on EAP-TLS mode of operation. Public key authentication has many security benefits over password-based mechanisms, though the process of onboarding new users and devices is more complex. Users on these networks are required to register or enroll in order to obtain a client identity certificate. Before you attempt to add an EAP-TLS network to wpa_supplicant, you must complete the onboarding process and install certificates onto your device. For University of Washington students, faculty, and staff, we have documented onboarding and certificate installation in separately (click here) . Eduroam configuration template (EAP-TLS) The majority of the values needed for this template will be provided by your organization during onboarding. For , your organization most likely supports CCMP , which is a mode of AES encryption. If you're unsure, enter CCMP TKIP to allow for legacy encryption support (not recommended). All path names will be dependent on the installation location for your certificates. network={ priority=10 ssid=\"eduroam\" scan_ssid=1 key_mgmt=WPA-EAP proto=RSN pairwise=<ENCRYPTION_MODES> group=<ENCRYPTION_MODES> eap=TLS identity=\"<IDENTITY>\" anonymous_identity=\"<ANONYMOUS_IDENTITY>\" ca_cert=\"</PATH/TO/CA_CERT.PEM>\" client_cert=\"</PATH/TO/CLIENT_CERT.PEM>\" private_key=\"</PATH/TO/PRIVATE_KEY.PEM>\" domain_match=\"<DOMAIN>\" phase2=\"auth=<INNER_EAP_TYPE>\" }","title":"Certificate-based Authentication"},{"location":"resources/wifi-reference/#password-based-authentication","text":"Password-based authentication can be set up for an enterprise wireless network by leveraging the Protected Extensible Authentication Protocol (PEAP) and the Microsoft Challenge Authentication Protocol version 2 (MSCHAPv2) to authenticate network clients based on a previously registered username and passphrase. The following template configures wpa_supplicant for PEAP/MSCHAPv2 authentication on an Eduroam network. Add it to your wpa_supplicant.conf , substituting your own username and password hash for the supplied values. Avoid Credential Exposure If implemented poorly, PEAP can expose your password to a malicious network operator. To prevent attacks, include the Certificate Authority (CA) certificate 1 in your wpa_supplicant configuration. Without this information, the wireless client may send password information to an evil twin (malicious network posing as one you trust). Likewise, we advise against hard-coding your plaintext school or work password into the wireless configuration file. Instead, compute an MD4 hash from your password and substitute it for the password. MD4 is a weak hash and fairly vulnerable to password cracking, but combined with a strong password, it does provide a layer of protection if your device is lost or stolen. Follow these commands in order to compute the MD4 hash in Linux. The history commands are not needed to compute a hash but are added for security. Without them, your password will be stored in the Bash history file and easily readable to anyone with access to your memory card. set +o history echo -n 'This is your password' | iconv -t utf16le | openssl md4 # You should see output like 6f9bad2c90b80bd549e595fc91e27806 set -o history Eduroam configuration template (EAP-PEAP) This configuration is no longer supported on University of Washington's eduroam network (effective Feb 1, 2022). network={ ssid=\"eduroam\" scan_ssid=1 key_mgmt=WPA-EAP proto=RSN eap=PEAP identity=\"<USERNAME>@<ORGANIZATION_DOMAIN>\" password=hash:6f9bad2c90b80bd549e595fc91e27806 ca_cert=\"</PATH/TO/CA_CERT.PEM>\" phase1=\"peaplabel=0\" phase2=\"auth=MSCHAPV2\" }","title":"Password-based Authentication"},{"location":"resources/wifi-reference/#applying-configuration-changes","text":"Like other services, wpa_supplicant will not load our changes automatically. Rather than reset the daemon completely using systemctl , we can use wpa_cli to update the configuration and perform other basic maintenance. When running wpa_cli we need to specify the interface we are configuring and a command to send to the wpa_supplicant service. Load configuration from wpa_supplicant.conf # Update configuration from disk wpa_cli -i wlan0 reconfigure # Check the status of current connection wpa_cli -i wlan0 status See man wpa_cli for further instructions and examples. Obtain this file from your organization's IT department. \u21a9","title":"Applying Configuration Changes"},{"location":"resources/wireguard-configuration/","text":"WireGuard Configuration \u00b6 Linux does not define a canonical approach to network configuration. Traditionally each distribution has made its own choices with which adminstrators will become familiar. In recent years, a number of distributions have standardized systemd-networkd based network configuration. The systemd movement has been a topic of hot debate, though for new students of Linux, it offers the advantage of predictability. Manually configure wireguard with iproute2 ip link add dev wg0 type wireguard ip addr add dev wg0 10.99.0.4 peer 10.99.0.5 wg set wg0 listen-port 51820 private-key /etc/wireguard/private-key \\ peer AglT3WUjY0j9Ic/SvfGGmGQ1r39MoQqlXDq9+hjOKhU= allowed-ips 0.0.0.0/0 \\ endpoint 1.2.3.4:51821 ip link set up dev wg0 /etc/wireguard/privatekey X/n17o9G+4o84NT4l53uV3Jf13WKiA9EVs9l3onsEno= Configuring wireguard persistently with systemd-networkd After creating the files below, make sure that ownership and permissions are set to protect private keys. sudo chown root:systemd-network /etc/systemd/network/99-wg0.netdev sudo chmod 640 /etc/systemd/network/99-wg0.netdev /etc/systemd/network/99-wg0.netdev [NetDev] Name=wg0 Kind=wireguard Description=WireGuard Tunnel Endpoint [WireGuard] ListenPort=51820 PrivateKey=X/n17o9G+4o84NT4l53uV3Jf13WKiA9EVs9l3onsEno= [WireGuardPeer] PublicKey=AglT3WUjY0j9Ic/SvfGGmGQ1r39MoQqlXDq9+hjOKhU= AllowedIPs=0.0.0.0/0 Endpoint=1.2.3.4:51821 # Recommended only on routers that do not provide their own listener PersistentKeepalive=25 /etc/systemd/network/99-wg0.network [Match] Name=wg0 [Address] Address=10.99.0.4/32 Peer=10.99.0.5/32 Configuring wireguard persistently with legacy Debian networking (ifupdown) /etc/network/interfaces auto wg0 iface wg0 inet static address 10.99.0.4 pointopoint 10.99.0.5 pre-up ip link add dev wg0 type wireguard pre-up wg setconf wg0 /etc/wireguard/wg0.conf post-down ip link delete dev wg0 /etc/wireguard/wg0.conf [Interface] ListenPort = 51820 PrivateKey = X/n17o9G+4o84NT4l53uV3Jf13WKiA9EVs9l3onsEno= [Peer] PublicKey = AglT3WUjY0j9Ic/SvfGGmGQ1r39MoQqlXDq9+hjOKhU= AllowedIPs = 0.0.0.0/0 Endpoint = 1.2.3.4:51821","title":"WireGuard Configuration"},{"location":"resources/wireguard-configuration/#wireguard-configuration","text":"Linux does not define a canonical approach to network configuration. Traditionally each distribution has made its own choices with which adminstrators will become familiar. In recent years, a number of distributions have standardized systemd-networkd based network configuration. The systemd movement has been a topic of hot debate, though for new students of Linux, it offers the advantage of predictability. Manually configure wireguard with iproute2 ip link add dev wg0 type wireguard ip addr add dev wg0 10.99.0.4 peer 10.99.0.5 wg set wg0 listen-port 51820 private-key /etc/wireguard/private-key \\ peer AglT3WUjY0j9Ic/SvfGGmGQ1r39MoQqlXDq9+hjOKhU= allowed-ips 0.0.0.0/0 \\ endpoint 1.2.3.4:51821 ip link set up dev wg0 /etc/wireguard/privatekey X/n17o9G+4o84NT4l53uV3Jf13WKiA9EVs9l3onsEno= Configuring wireguard persistently with systemd-networkd After creating the files below, make sure that ownership and permissions are set to protect private keys. sudo chown root:systemd-network /etc/systemd/network/99-wg0.netdev sudo chmod 640 /etc/systemd/network/99-wg0.netdev /etc/systemd/network/99-wg0.netdev [NetDev] Name=wg0 Kind=wireguard Description=WireGuard Tunnel Endpoint [WireGuard] ListenPort=51820 PrivateKey=X/n17o9G+4o84NT4l53uV3Jf13WKiA9EVs9l3onsEno= [WireGuardPeer] PublicKey=AglT3WUjY0j9Ic/SvfGGmGQ1r39MoQqlXDq9+hjOKhU= AllowedIPs=0.0.0.0/0 Endpoint=1.2.3.4:51821 # Recommended only on routers that do not provide their own listener PersistentKeepalive=25 /etc/systemd/network/99-wg0.network [Match] Name=wg0 [Address] Address=10.99.0.4/32 Peer=10.99.0.5/32 Configuring wireguard persistently with legacy Debian networking (ifupdown) /etc/network/interfaces auto wg0 iface wg0 inet static address 10.99.0.4 pointopoint 10.99.0.5 pre-up ip link add dev wg0 type wireguard pre-up wg setconf wg0 /etc/wireguard/wg0.conf post-down ip link delete dev wg0 /etc/wireguard/wg0.conf [Interface] ListenPort = 51820 PrivateKey = X/n17o9G+4o84NT4l53uV3Jf13WKiA9EVs9l3onsEno= [Peer] PublicKey = AglT3WUjY0j9Ic/SvfGGmGQ1r39MoQqlXDq9+hjOKhU= AllowedIPs = 0.0.0.0/0 Endpoint = 1.2.3.4:51821","title":"WireGuard Configuration"},{"location":"resources/wireshark-install/","text":"Installing WireShark \u00b6 Install WiresShark using the instructions linked below and test that you are able to run a packet capture over your current wireless connection. Instructions (macOS) \u00b6 Download the macOS installer from the WireShark download page and proceed with the instructions at: https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallOSXInstall.html Important The latest release of WireShark shipped with a macOS specific bug that appears with a permission denied error every time the user opens a new terminal window. This is a known bug 1 in the latest installer and can be resolved by running sudo chmod 644 /etc/manpaths.d/Wireshark /etc/paths.d/Wireshark from the terminal. Instructions (Windows) \u00b6 Download the Windows installer (64-bit) from the Wireshark download page and proceed with the instructions at: https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallWinInstall.html Instructions (Linux) \u00b6 https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallUnixInstallBins.html https://github.com/Homebrew/homebrew-cask/issues/74548 \u21a9","title":"Install Wireshark"},{"location":"resources/wireshark-install/#installing-wireshark","text":"Install WiresShark using the instructions linked below and test that you are able to run a packet capture over your current wireless connection.","title":"Installing WireShark"},{"location":"resources/wireshark-install/#instructions-macos","text":"Download the macOS installer from the WireShark download page and proceed with the instructions at: https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallOSXInstall.html Important The latest release of WireShark shipped with a macOS specific bug that appears with a permission denied error every time the user opens a new terminal window. This is a known bug 1 in the latest installer and can be resolved by running sudo chmod 644 /etc/manpaths.d/Wireshark /etc/paths.d/Wireshark from the terminal.","title":"Instructions (macOS)"},{"location":"resources/wireshark-install/#instructions-windows","text":"Download the Windows installer (64-bit) from the Wireshark download page and proceed with the instructions at: https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallWinInstall.html","title":"Instructions (Windows)"},{"location":"resources/wireshark-install/#instructions-linux","text":"https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallUnixInstallBins.html https://github.com/Homebrew/homebrew-cask/issues/74548 \u21a9","title":"Instructions (Linux)"},{"location":"resources/zone-file-format/","text":"BIND Zone Files \u00b6 A DNS zone file is a text file that describes a DNS zone and provides the list of all resource records that are defined in the zone. The zone file for an authoritative DNS server follows is composed of the following elements: Zone File Structure \u00b6 Comments beginning with a semicolon and continuing to the end of the current line. Directives such as $ORIGIN and $TTL keywords that provide default values used when interpreting DNS records. A SOA record positioned at the top of the file that defines global parameters for the zone. Additional Resource Records used to identify service-specific resources such as name servers and email servers or to map hostnames to network addresses. The following simple zone file distributed with BIND9 defines a zone description for the reserved localhost namespace: ; ; BIND data file for local loopback interface ; $TTL 604800 @ IN SOA localhost. root.localhost. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS localhost. @ IN A 127.0.0.1 @ IN AAAA ::1 Record Format \u00b6 Standard Fields \u00b6 Each record in a zone defines a set of parameters associated with a single DNS resource. NAME is the DNS record's alphanumeric identifier (e.g., such as www or mail ). TTL informs DNS clients, such as your your OS or browser, how long they can keep the record in their local cache. The TTL field is optional for individual resource records. BIND9 will default to the value of the global $TTL directive when omitted. CLASS is a namespace identifier defined by the DNS protocol. For our purposes, the value will always be IN . TYPE describes the type of resource, e.g., NS (name server), A (address), or MX (mail server). RDATA specifies the value of the record. The format of this data is based on the record type. A few common types are given later in this document. Names \u00b6 DNS names can be given in absolute or relative form. Absolute names are commonly called fully qualified domain name (FQDN) and include all parts of the name from the the host to the root of the DNS hierarchy. When configuring DNS servers, FQDNs are always terminated with a trailing dot, e.g., www.washington.edu. . Relative names omit the domain portion of the address and the trailing dot, e.g., www . When BIND encounters a hostname without the trailing dot in a zone file, it implicitly inserts the domain portion of the address. Forgetting to terminate an absolute hostname such as www.washington.edu with the trailing period will result in errors since BIND will see the resource as www.washington.edu.washington.edu. . Shorthand \u00b6 The standard zone file format employs a number of shortcuts that allow certain fields to be omitted or shortened. BIND will use the global $TTL value as a default for records that do not specify their own. A hostname of @ is shorthand for the default domain name for the zone. This value will be explicitly defined by the $ORIGIN directive at the start of a zone file or learned implicitly by the server based on the server's configuration. When specifying multiple records in a row with the same name, you can omit the name after the first record. Common Record Types \u00b6 SOA Record Data \u00b6 A valid zone file begins with the Start of Authority record. This record provides information about the primary servers for the domain and defines parameters to control the behavior of secondary servers. RDATA for SOA includes the following fields: MNAME specifies the name server that is the primary source of data about this domain. RNAME is the email address of the administrator for the zone. RFC 2142 recommends that every domain provides a hostmaster mailbox to receive support queries related to the domain. **Special formatting applies for the RNAME (see below). SERIAL is an unsigned 32-bit version number of the zone-file used to detect updates. This number must be incremented every time the zone file is updated. RFC 1912 recommends using the numerically formatted date followed by a 2 digit revision number, i.e., YYYYMMDDnn . REFRESH defines the number of seconds after which secondary name servers should query the master for the SOA record to determine whether there are any updates to the zone. RIPE's recommendation for small and stable zones is 86400 seconds (24 hours). RETRY defines the number of seconds a secondary name server should wait to retry its refresh query if the master does not respond. RIPE's recommendation for small and stable zones is 7200 seconds (2 hours). EXPIRE defines the number of seconds before expiring the current set of records if the master does not respond. RIPE's recommendation for small and stable zones is 3600000 seconds (1000 hours). TTL defines a time to live value that is used by recent servers to determine how long to cache a negative DNS result and by older servers to determine the default TTL for resources that don't specify it explicitly. RIPE's recommendation for small and stable zones is 172800 seconds (2 days). When formatting an email address for the RNAME field, You must escape any period in the username portion of the address with a \\ and replace the @ symbol with an unescaped period. Do not escape periods in the domain portion of the address. An example can be seen in the following SOA record. ; ; Example SOA record for washington.edu ; Primary NS - hanna.cac.washington.edu ; Administrative Email - domainmaster@cac.washington.edu ; washington.edu. 462 IN SOA hanna.cac.washington.edu. domainmaster.cac.washington.edu. 2019021600 3600 1800 3600000 600 ; ; Use parenthesis to split the record across lines for readability ; washington.edu. 462 IN SOA hanna.cac.washington.edu. domainmaster.cac.washington.edu ( 2019021600 ; SERIAL 3600 ; REFRESH (1 hour) 1800 ; RETRY (30 minutes) 3600000 ; EXPIRE (1000 hours) 600 ; TTL (10 minutes) ) NS Record Data \u00b6 Name Server records are used to indicate the servers that host the zone file for a domain. A zone file will normally include its own name servers and the name servers of any subdomains. In a real world scenario, your domains should be hosted by at least two name servers. NS records refer to the hostname of a server. Assigning an IP address to a NS record is a misconfiguration. Rather a zone file can define glue records, A and AAAA address records that tie the name servers' hostnames to IP addresses. Glue records are required when a zone hosts its own authoritative name servers. ; Name Server washington.edu. 86400 IN NS hanna.cac.washington.edu. ; Glue Records hanna.cac.washington.edu. 86400 IN A 140.142.5.5 hanna.cac.washington.edu. 86400 IN AAAA 2607:4000:200:42::5 A and AAAA Record Data \u00b6 Address records map hostnames to IP addresses. The value of an A record in a BIND zone file is simply the IPv4 address in dotted decimal notation. For AAAA records, BIND supports the standard shorthand rules for IPv6. It is legal (and common) for multiple address records to be provided for a given hostname. This feature allows us to support dual stack hosts that can be reached using either IPv4 or IPv6 addresses, but it also enables us to distribute traffic between multiple servers for redundancy and load balancing. This configuration is referred to as round-robin DNS and can be seen in the following example: ; ; Subsequent DNS responses will list records in a random order ; www.washington.edu. IN A 128.95.155.134 www.washington.edu. IN A 128.95.155.197 www.washington.edu. IN A 128.95.155.198 CNAME Record Data \u00b6 Canonical Name records define aliases for hostnames. CNAME records have many uses, including mapping alternate domain registrations to a primary domain (as seen below) or to improve the stability of DNS records when we do not have direct control over the underlying infrastructure. ; ; www.uw.edu can be used as an alias for www.washington.edu ; www.uw.edu. IN CNAME www.washington.edu. While CNAME records can be quite useful, there are several important restrictions to keep in mind: Do not define a CNAME record for the apex domain name , i.e., the name of the domain without any host prefix. Do not define a CNAME as the target of an MX or NS record. The target of an MX or NS must always resolve to an A or AAAA record. Do not define any other records for a hostname that is given a CNAME record. For example, since www.uw.edu has a CNAME, it cannot also be given an A record or a TXT record. MX Record Data \u00b6 Mail Exchanger records are used to specify the servers that will receive mail for a given domain. An individual MX record include an integer priority and a hostname. It is common and recommended to define multiple MX records for a domain. The priority field is used by mail agents to determine the preferred mail server (lower values are given higher priority). ; ; Since the three servers listed here have equal priority, a mail ; agent will choose one at random. ; washington.edu. 10800 IN MX 100 mxe30.s.uw.edu. washington.edu. 10800 IN MX 100 mxe31.s.uw.edu. washington.edu. 10800 IN MX 100 mxe32.s.uw.edu. ; ; The hostnames referred to by MX records must resolve to address ; records are hosted in the zone for uw.edu, e.g., ; mxe30.s.uw.edu. 86400 IN A 173.250.227.19 TXT Record Data \u00b6 Text records hold freeform text that is generally intended for use by external services. TXT records are frequently used to: * Verify ownership of a domain, e.g., required to set up 3 rd party email hosting or obtain a certificate for TLS. * Support SPAM reduction technologies such as the Sender Policy Framework (SPF) and DomainKeys Identfied Mail (DKIM). ; ; SPF uses TXT to indicate which networks or hosts may be used to send ; email on behalf of a domain. Recipients may flag or drop email that ; originated from an alternate server. ; uw.edu. 3600 IN TXT \"v=spf1 ip4:128.95.242.222/32 ip4:128.208.0.5/32 ip4:128.208.181.0/26 ip4:140.142.32.0/24 ip4:140.142.234.128/25 ip4:173.250.227.0/24 ?all\" References \u00b6 RFC 1912: Common DNS Operational and Configuration Errors RFC 2142: Mailbox Names for Common Services, Roles, and Functions RIPE 203: Recommendations for DNS SOA Values","title":"DNS Zone Files"},{"location":"resources/zone-file-format/#bind-zone-files","text":"A DNS zone file is a text file that describes a DNS zone and provides the list of all resource records that are defined in the zone. The zone file for an authoritative DNS server follows is composed of the following elements:","title":"BIND Zone Files"},{"location":"resources/zone-file-format/#zone-file-structure","text":"Comments beginning with a semicolon and continuing to the end of the current line. Directives such as $ORIGIN and $TTL keywords that provide default values used when interpreting DNS records. A SOA record positioned at the top of the file that defines global parameters for the zone. Additional Resource Records used to identify service-specific resources such as name servers and email servers or to map hostnames to network addresses. The following simple zone file distributed with BIND9 defines a zone description for the reserved localhost namespace: ; ; BIND data file for local loopback interface ; $TTL 604800 @ IN SOA localhost. root.localhost. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS localhost. @ IN A 127.0.0.1 @ IN AAAA ::1","title":"Zone File Structure"},{"location":"resources/zone-file-format/#record-format","text":"","title":"Record Format"},{"location":"resources/zone-file-format/#standard-fields","text":"Each record in a zone defines a set of parameters associated with a single DNS resource. NAME is the DNS record's alphanumeric identifier (e.g., such as www or mail ). TTL informs DNS clients, such as your your OS or browser, how long they can keep the record in their local cache. The TTL field is optional for individual resource records. BIND9 will default to the value of the global $TTL directive when omitted. CLASS is a namespace identifier defined by the DNS protocol. For our purposes, the value will always be IN . TYPE describes the type of resource, e.g., NS (name server), A (address), or MX (mail server). RDATA specifies the value of the record. The format of this data is based on the record type. A few common types are given later in this document.","title":"Standard Fields"},{"location":"resources/zone-file-format/#names","text":"DNS names can be given in absolute or relative form. Absolute names are commonly called fully qualified domain name (FQDN) and include all parts of the name from the the host to the root of the DNS hierarchy. When configuring DNS servers, FQDNs are always terminated with a trailing dot, e.g., www.washington.edu. . Relative names omit the domain portion of the address and the trailing dot, e.g., www . When BIND encounters a hostname without the trailing dot in a zone file, it implicitly inserts the domain portion of the address. Forgetting to terminate an absolute hostname such as www.washington.edu with the trailing period will result in errors since BIND will see the resource as www.washington.edu.washington.edu. .","title":"Names"},{"location":"resources/zone-file-format/#shorthand","text":"The standard zone file format employs a number of shortcuts that allow certain fields to be omitted or shortened. BIND will use the global $TTL value as a default for records that do not specify their own. A hostname of @ is shorthand for the default domain name for the zone. This value will be explicitly defined by the $ORIGIN directive at the start of a zone file or learned implicitly by the server based on the server's configuration. When specifying multiple records in a row with the same name, you can omit the name after the first record.","title":"Shorthand"},{"location":"resources/zone-file-format/#common-record-types","text":"","title":"Common Record Types"},{"location":"resources/zone-file-format/#soa-record-data","text":"A valid zone file begins with the Start of Authority record. This record provides information about the primary servers for the domain and defines parameters to control the behavior of secondary servers. RDATA for SOA includes the following fields: MNAME specifies the name server that is the primary source of data about this domain. RNAME is the email address of the administrator for the zone. RFC 2142 recommends that every domain provides a hostmaster mailbox to receive support queries related to the domain. **Special formatting applies for the RNAME (see below). SERIAL is an unsigned 32-bit version number of the zone-file used to detect updates. This number must be incremented every time the zone file is updated. RFC 1912 recommends using the numerically formatted date followed by a 2 digit revision number, i.e., YYYYMMDDnn . REFRESH defines the number of seconds after which secondary name servers should query the master for the SOA record to determine whether there are any updates to the zone. RIPE's recommendation for small and stable zones is 86400 seconds (24 hours). RETRY defines the number of seconds a secondary name server should wait to retry its refresh query if the master does not respond. RIPE's recommendation for small and stable zones is 7200 seconds (2 hours). EXPIRE defines the number of seconds before expiring the current set of records if the master does not respond. RIPE's recommendation for small and stable zones is 3600000 seconds (1000 hours). TTL defines a time to live value that is used by recent servers to determine how long to cache a negative DNS result and by older servers to determine the default TTL for resources that don't specify it explicitly. RIPE's recommendation for small and stable zones is 172800 seconds (2 days). When formatting an email address for the RNAME field, You must escape any period in the username portion of the address with a \\ and replace the @ symbol with an unescaped period. Do not escape periods in the domain portion of the address. An example can be seen in the following SOA record. ; ; Example SOA record for washington.edu ; Primary NS - hanna.cac.washington.edu ; Administrative Email - domainmaster@cac.washington.edu ; washington.edu. 462 IN SOA hanna.cac.washington.edu. domainmaster.cac.washington.edu. 2019021600 3600 1800 3600000 600 ; ; Use parenthesis to split the record across lines for readability ; washington.edu. 462 IN SOA hanna.cac.washington.edu. domainmaster.cac.washington.edu ( 2019021600 ; SERIAL 3600 ; REFRESH (1 hour) 1800 ; RETRY (30 minutes) 3600000 ; EXPIRE (1000 hours) 600 ; TTL (10 minutes) )","title":"SOA Record Data"},{"location":"resources/zone-file-format/#ns-record-data","text":"Name Server records are used to indicate the servers that host the zone file for a domain. A zone file will normally include its own name servers and the name servers of any subdomains. In a real world scenario, your domains should be hosted by at least two name servers. NS records refer to the hostname of a server. Assigning an IP address to a NS record is a misconfiguration. Rather a zone file can define glue records, A and AAAA address records that tie the name servers' hostnames to IP addresses. Glue records are required when a zone hosts its own authoritative name servers. ; Name Server washington.edu. 86400 IN NS hanna.cac.washington.edu. ; Glue Records hanna.cac.washington.edu. 86400 IN A 140.142.5.5 hanna.cac.washington.edu. 86400 IN AAAA 2607:4000:200:42::5","title":"NS Record Data"},{"location":"resources/zone-file-format/#a-and-aaaa-record-data","text":"Address records map hostnames to IP addresses. The value of an A record in a BIND zone file is simply the IPv4 address in dotted decimal notation. For AAAA records, BIND supports the standard shorthand rules for IPv6. It is legal (and common) for multiple address records to be provided for a given hostname. This feature allows us to support dual stack hosts that can be reached using either IPv4 or IPv6 addresses, but it also enables us to distribute traffic between multiple servers for redundancy and load balancing. This configuration is referred to as round-robin DNS and can be seen in the following example: ; ; Subsequent DNS responses will list records in a random order ; www.washington.edu. IN A 128.95.155.134 www.washington.edu. IN A 128.95.155.197 www.washington.edu. IN A 128.95.155.198","title":"A and AAAA Record Data"},{"location":"resources/zone-file-format/#cname-record-data","text":"Canonical Name records define aliases for hostnames. CNAME records have many uses, including mapping alternate domain registrations to a primary domain (as seen below) or to improve the stability of DNS records when we do not have direct control over the underlying infrastructure. ; ; www.uw.edu can be used as an alias for www.washington.edu ; www.uw.edu. IN CNAME www.washington.edu. While CNAME records can be quite useful, there are several important restrictions to keep in mind: Do not define a CNAME record for the apex domain name , i.e., the name of the domain without any host prefix. Do not define a CNAME as the target of an MX or NS record. The target of an MX or NS must always resolve to an A or AAAA record. Do not define any other records for a hostname that is given a CNAME record. For example, since www.uw.edu has a CNAME, it cannot also be given an A record or a TXT record.","title":"CNAME Record Data"},{"location":"resources/zone-file-format/#mx-record-data","text":"Mail Exchanger records are used to specify the servers that will receive mail for a given domain. An individual MX record include an integer priority and a hostname. It is common and recommended to define multiple MX records for a domain. The priority field is used by mail agents to determine the preferred mail server (lower values are given higher priority). ; ; Since the three servers listed here have equal priority, a mail ; agent will choose one at random. ; washington.edu. 10800 IN MX 100 mxe30.s.uw.edu. washington.edu. 10800 IN MX 100 mxe31.s.uw.edu. washington.edu. 10800 IN MX 100 mxe32.s.uw.edu. ; ; The hostnames referred to by MX records must resolve to address ; records are hosted in the zone for uw.edu, e.g., ; mxe30.s.uw.edu. 86400 IN A 173.250.227.19","title":"MX Record Data"},{"location":"resources/zone-file-format/#txt-record-data","text":"Text records hold freeform text that is generally intended for use by external services. TXT records are frequently used to: * Verify ownership of a domain, e.g., required to set up 3 rd party email hosting or obtain a certificate for TLS. * Support SPAM reduction technologies such as the Sender Policy Framework (SPF) and DomainKeys Identfied Mail (DKIM). ; ; SPF uses TXT to indicate which networks or hosts may be used to send ; email on behalf of a domain. Recipients may flag or drop email that ; originated from an alternate server. ; uw.edu. 3600 IN TXT \"v=spf1 ip4:128.95.242.222/32 ip4:128.208.0.5/32 ip4:128.208.181.0/26 ip4:140.142.32.0/24 ip4:140.142.234.128/25 ip4:173.250.227.0/24 ?all\"","title":"TXT Record Data"},{"location":"resources/zone-file-format/#references","text":"RFC 1912: Common DNS Operational and Configuration Errors RFC 2142: Mailbox Names for Common Services, Roles, and Functions RIPE 203: Recommendations for DNS SOA Values","title":"References"}]}